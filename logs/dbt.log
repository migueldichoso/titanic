[0m01:58:39.899730 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102a562a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11007da90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11007d6a0>]}


============================== 01:58:39.903349 | 4cc778bc-27b7-42f8-8b7e-350d7e7f3075 ==============================
[0m01:58:39.903349 [info ] [MainThread]: Running with dbt=1.9.3
[0m01:58:39.903771 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/Users/migueldichoso/Downloads/Titanic', 'log_path': '/Users/migueldichoso/Downloads/Titanic/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt deps', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m01:58:39.979629 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4cc778bc-27b7-42f8-8b7e-350d7e7f3075', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bf8860>]}
[0m01:58:39.991547 [debug] [MainThread]: Set downloads directory='/var/folders/4k/qgw9v5597454dxtzb5g7z3cc0000gq/T/dbt-downloads-rfhukxl2'
[0m01:58:39.992035 [debug] [MainThread]: Executing "git clone --depth 1 https://github.com/estie-inc/dbt_snowflake_ml.git 6736b3dfda89a381ba813a0d56eebc29"
[0m01:58:44.353108 [debug] [MainThread]: STDOUT: "b''"
[0m01:58:44.353944 [debug] [MainThread]: STDERR: "b"Cloning into '6736b3dfda89a381ba813a0d56eebc29'...\n""
[0m01:58:44.354442 [debug] [MainThread]: Pulling new dependency 6736b3dfda89a381ba813a0d56eebc29.
[0m01:58:44.354699 [debug] [MainThread]: Executing "git rev-parse HEAD"
[0m01:58:44.363882 [debug] [MainThread]: STDOUT: "b'bd445d1fd307d42674887868e238eb5835365fd8\n'"
[0m01:58:44.364343 [debug] [MainThread]: STDERR: "b''"
[0m01:58:44.364590 [debug] [MainThread]: Checking out revision main.
[0m01:58:44.364808 [debug] [MainThread]: Executing "git remote set-branches origin main"
[0m01:58:44.371992 [debug] [MainThread]: STDOUT: "b''"
[0m01:58:44.372400 [debug] [MainThread]: STDERR: "b''"
[0m01:58:44.372590 [debug] [MainThread]: Executing "git fetch origin --depth 1 --tags main"
[0m01:58:47.460323 [debug] [MainThread]: STDOUT: "b''"
[0m01:58:47.461110 [debug] [MainThread]: STDERR: "b'From https://github.com/estie-inc/dbt_snowflake_ml\n * branch            main       -> FETCH_HEAD\n'"
[0m01:58:47.461425 [debug] [MainThread]: Executing "git tag --list"
[0m01:58:47.471057 [debug] [MainThread]: STDOUT: "b''"
[0m01:58:47.471481 [debug] [MainThread]: STDERR: "b''"
[0m01:58:47.471685 [debug] [MainThread]: Executing "git reset --hard origin/main"
[0m01:58:47.482473 [debug] [MainThread]: STDOUT: "b'HEAD is now at bd445d1 update package resolution\n'"
[0m01:58:47.482880 [debug] [MainThread]: STDERR: "b''"
[0m01:58:47.483096 [debug] [MainThread]: Executing "git rev-parse HEAD"
[0m01:58:47.489433 [debug] [MainThread]: STDOUT: "b'bd445d1fd307d42674887868e238eb5835365fd8\n'"
[0m01:58:47.489825 [debug] [MainThread]: STDERR: "b''"
[0m01:58:47.490030 [debug] [MainThread]: Checked out at bd445d1.
[0m01:58:47.490251 [warn ] [MainThread]: [33mWARNING: The git package "https://github.com/estie-inc/dbt_snowflake_ml.git" 
	is pinned to the "main" branch.
	This can introduce breaking changes into your project without warning!

See https://docs.getdbt.com/docs/package-management#section-specifying-package-versions[0m
[0m01:58:47.490479 [debug] [MainThread]: Executing "git rev-parse HEAD"
[0m01:58:47.496946 [debug] [MainThread]: STDOUT: "b'bd445d1fd307d42674887868e238eb5835365fd8\n'"
[0m01:58:47.497412 [debug] [MainThread]: STDERR: "b''"
[0m01:58:47.498422 [debug] [MainThread]: Executing "git clone --depth 1 https://github.com/estie-inc/dbt_snowflake_ml.git 6736b3dfda89a381ba813a0d56eebc29"
[0m01:58:47.507252 [debug] [MainThread]: STDOUT: "b''"
[0m01:58:47.507860 [debug] [MainThread]: STDERR: "b"fatal: destination path '6736b3dfda89a381ba813a0d56eebc29' already exists and is not an empty directory.\n""
[0m01:58:47.508050 [debug] [MainThread]: command return code=128
[0m01:58:47.508770 [debug] [MainThread]: Updating existing dependency 6736b3dfda89a381ba813a0d56eebc29.
[0m01:58:47.509001 [debug] [MainThread]: Executing "git rev-parse HEAD"
[0m01:58:47.516990 [debug] [MainThread]: STDOUT: "b'bd445d1fd307d42674887868e238eb5835365fd8\n'"
[0m01:58:47.517442 [debug] [MainThread]: STDERR: "b''"
[0m01:58:47.517647 [debug] [MainThread]: Checking out revision main.
[0m01:58:47.517836 [debug] [MainThread]: Executing "git remote set-branches origin main"
[0m01:58:47.525520 [debug] [MainThread]: STDOUT: "b''"
[0m01:58:47.525989 [debug] [MainThread]: STDERR: "b''"
[0m01:58:47.526172 [debug] [MainThread]: Executing "git fetch origin --depth 1 --tags main"
[0m01:58:50.584536 [debug] [MainThread]: STDOUT: "b''"
[0m01:58:50.585311 [debug] [MainThread]: STDERR: "b'From https://github.com/estie-inc/dbt_snowflake_ml\n * branch            main       -> FETCH_HEAD\n'"
[0m01:58:50.585614 [debug] [MainThread]: Executing "git tag --list"
[0m01:58:50.595053 [debug] [MainThread]: STDOUT: "b''"
[0m01:58:50.595478 [debug] [MainThread]: STDERR: "b''"
[0m01:58:50.595674 [debug] [MainThread]: Executing "git reset --hard origin/main"
[0m01:58:50.605289 [debug] [MainThread]: STDOUT: "b'HEAD is now at bd445d1 update package resolution\n'"
[0m01:58:50.605682 [debug] [MainThread]: STDERR: "b''"
[0m01:58:50.605888 [debug] [MainThread]: Executing "git rev-parse HEAD"
[0m01:58:50.611982 [debug] [MainThread]: STDOUT: "b'bd445d1fd307d42674887868e238eb5835365fd8\n'"
[0m01:58:50.612362 [debug] [MainThread]: STDERR: "b''"
[0m01:58:50.612556 [debug] [MainThread]: Already at bd445d1, nothing to do.
[0m01:58:50.612755 [warn ] [MainThread]: [33mWARNING: The git package "https://github.com/estie-inc/dbt_snowflake_ml.git" 
	is pinned to the "main" branch.
	This can introduce breaking changes into your project without warning!

See https://docs.getdbt.com/docs/package-management#section-specifying-package-versions[0m
[0m01:58:50.612968 [debug] [MainThread]: Executing "git rev-parse HEAD"
[0m01:58:50.619008 [debug] [MainThread]: STDOUT: "b'bd445d1fd307d42674887868e238eb5835365fd8\n'"
[0m01:58:50.619381 [debug] [MainThread]: STDERR: "b''"
[0m01:58:50.629026 [info ] [MainThread]: Updating lock file in file path: /Users/migueldichoso/Downloads/Titanic/package-lock.yml
[0m01:58:50.631034 [debug] [MainThread]: Set downloads directory='/var/folders/4k/qgw9v5597454dxtzb5g7z3cc0000gq/T/dbt-downloads-nj07f5li'
[0m01:58:50.631325 [info ] [MainThread]: Installing https://github.com/estie-inc/dbt_snowflake_ml.git
[0m01:58:50.631540 [debug] [MainThread]: Executing "git clone --depth 1 https://github.com/estie-inc/dbt_snowflake_ml.git 6736b3dfda89a381ba813a0d56eebc29"
[0m01:58:54.404127 [debug] [MainThread]: STDOUT: "b''"
[0m01:58:54.404995 [debug] [MainThread]: STDERR: "b"Cloning into '6736b3dfda89a381ba813a0d56eebc29'...\n""
[0m01:58:54.405298 [debug] [MainThread]: Pulling new dependency 6736b3dfda89a381ba813a0d56eebc29.
[0m01:58:54.405528 [debug] [MainThread]: Executing "git rev-parse HEAD"
[0m01:58:54.415063 [debug] [MainThread]: STDOUT: "b'bd445d1fd307d42674887868e238eb5835365fd8\n'"
[0m01:58:54.415563 [debug] [MainThread]: STDERR: "b''"
[0m01:58:54.415781 [debug] [MainThread]: Checking out revision bd445d1fd307d42674887868e238eb5835365fd8.
[0m01:58:54.415980 [debug] [MainThread]: Executing "git fetch origin --depth 1 bd445d1fd307d42674887868e238eb5835365fd8"
[0m01:58:57.501978 [debug] [MainThread]: STDOUT: "b''"
[0m01:58:57.502558 [debug] [MainThread]: STDERR: "b'From https://github.com/estie-inc/dbt_snowflake_ml\n * branch            bd445d1fd307d42674887868e238eb5835365fd8 -> FETCH_HEAD\n'"
[0m01:58:57.502796 [debug] [MainThread]: Executing "git reset --hard bd445d1fd307d42674887868e238eb5835365fd8"
[0m01:58:57.515233 [debug] [MainThread]: STDOUT: "b'HEAD is now at bd445d1 update package resolution\n'"
[0m01:58:57.515712 [debug] [MainThread]: STDERR: "b''"
[0m01:58:57.515908 [debug] [MainThread]: Executing "git rev-parse HEAD"
[0m01:58:57.522081 [debug] [MainThread]: STDOUT: "b'bd445d1fd307d42674887868e238eb5835365fd8\n'"
[0m01:58:57.522516 [debug] [MainThread]: STDERR: "b''"
[0m01:58:57.522718 [debug] [MainThread]: Checked out at bd445d1.
[0m01:58:57.522899 [debug] [MainThread]: Executing "git rev-parse HEAD"
[0m01:58:57.529015 [debug] [MainThread]: STDOUT: "b'bd445d1fd307d42674887868e238eb5835365fd8\n'"
[0m01:58:57.529405 [debug] [MainThread]: STDERR: "b''"
[0m01:58:57.530166 [debug] [MainThread]: Executing "git clone --depth 1 https://github.com/estie-inc/dbt_snowflake_ml.git 6736b3dfda89a381ba813a0d56eebc29"
[0m01:58:57.536479 [debug] [MainThread]: STDOUT: "b''"
[0m01:58:57.536846 [debug] [MainThread]: STDERR: "b"fatal: destination path '6736b3dfda89a381ba813a0d56eebc29' already exists and is not an empty directory.\n""
[0m01:58:57.536997 [debug] [MainThread]: command return code=128
[0m01:58:57.537465 [debug] [MainThread]: Updating existing dependency 6736b3dfda89a381ba813a0d56eebc29.
[0m01:58:57.537627 [debug] [MainThread]: Executing "git rev-parse HEAD"
[0m01:58:57.543563 [debug] [MainThread]: STDOUT: "b'bd445d1fd307d42674887868e238eb5835365fd8\n'"
[0m01:58:57.543902 [debug] [MainThread]: STDERR: "b''"
[0m01:58:57.544075 [debug] [MainThread]: Checking out revision bd445d1fd307d42674887868e238eb5835365fd8.
[0m01:58:57.544249 [debug] [MainThread]: Executing "git fetch origin --depth 1 bd445d1fd307d42674887868e238eb5835365fd8"
[0m01:59:00.652290 [debug] [MainThread]: STDOUT: "b''"
[0m01:59:00.652818 [debug] [MainThread]: STDERR: "b'From https://github.com/estie-inc/dbt_snowflake_ml\n * branch            bd445d1fd307d42674887868e238eb5835365fd8 -> FETCH_HEAD\n'"
[0m01:59:00.653055 [debug] [MainThread]: Executing "git reset --hard bd445d1fd307d42674887868e238eb5835365fd8"
[0m01:59:00.663879 [debug] [MainThread]: STDOUT: "b'HEAD is now at bd445d1 update package resolution\n'"
[0m01:59:00.664301 [debug] [MainThread]: STDERR: "b''"
[0m01:59:00.664493 [debug] [MainThread]: Executing "git rev-parse HEAD"
[0m01:59:00.670521 [debug] [MainThread]: STDOUT: "b'bd445d1fd307d42674887868e238eb5835365fd8\n'"
[0m01:59:00.670874 [debug] [MainThread]: STDERR: "b''"
[0m01:59:00.671049 [debug] [MainThread]: Already at bd445d1, nothing to do.
[0m01:59:00.671423 [info ] [MainThread]: Installed from revision bd445d1fd307d42674887868e238eb5835365fd8
[0m01:59:00.671745 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '4cc778bc-27b7-42f8-8b7e-350d7e7f3075', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110201f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110202150>]}
[0m01:59:00.694193 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 20.877836, "process_in_blocks": "0", "process_kernel_time": 0.253675, "process_mem_max_rss": "96813056", "process_out_blocks": "0", "process_user_time": 0.954285}
[0m01:59:00.694618 [debug] [MainThread]: Command `dbt deps` succeeded at 01:59:00.694543 after 20.88 seconds
[0m01:59:00.694940 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110155940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11007d820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11007d7c0>]}
[0m01:59:00.695169 [debug] [MainThread]: Flushing usage events
[0m01:59:02.465179 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:08:02.246300 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055652e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105586180>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105585dc0>]}


============================== 02:08:02.250344 | a69f1b00-6cbf-4aee-a4dc-b685447ad697 ==============================
[0m02:08:02.250344 [info ] [MainThread]: Running with dbt=1.9.3
[0m02:08:02.250809 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/migueldichoso/Downloads/Titanic', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/migueldichoso/Downloads/Titanic/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt build', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:08:02.253404 [error] [MainThread]: Encountered an error:
Runtime Error
  The profile 'titanic' does not have a target named 'titanic_dev'. The valid target names for this profile are:
   - profile_name
   - type
   - account
   - warehouse
   - database
   - user
   - password
   - role
   - schema
   - threads
[0m02:08:02.255081 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 0.08325, "process_in_blocks": "0", "process_kernel_time": 0.178189, "process_mem_max_rss": "91340800", "process_out_blocks": "0", "process_user_time": 0.78266}
[0m02:08:02.255403 [debug] [MainThread]: Command `dbt build` failed at 02:08:02.255332 after 0.08 seconds
[0m02:08:02.255628 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052fd7c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052cf1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10542f6e0>]}
[0m02:08:02.255837 [debug] [MainThread]: Flushing usage events
[0m02:08:08.378217 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:08:30.495470 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103b26cc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1044bf7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106385c40>]}


============================== 02:08:30.499503 | 41fa598a-836c-4b0a-9c30-f9c075b58d2b ==============================
[0m02:08:30.499503 [info ] [MainThread]: Running with dbt=1.9.3
[0m02:08:30.500027 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/migueldichoso/Downloads/Titanic', 'debug': 'False', 'warn_error': 'None', 'log_path': '/Users/migueldichoso/Downloads/Titanic/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt build', 'send_anonymous_usage_stats': 'True'}
[0m02:08:30.502546 [error] [MainThread]: Encountered an error:
Runtime Error
  output 'titanic_dev' of profile 'titanic' is misconfigured in profiles.yml
[0m02:08:30.504400 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 0.08332466, "process_in_blocks": "0", "process_kernel_time": 0.181451, "process_mem_max_rss": "92012544", "process_out_blocks": "0", "process_user_time": 0.809776}
[0m02:08:30.504749 [debug] [MainThread]: Command `dbt build` failed at 02:08:30.504681 after 0.08 seconds
[0m02:08:30.504990 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1044bf7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106387bc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106387d40>]}
[0m02:08:30.505225 [debug] [MainThread]: Flushing usage events
[0m02:08:35.775781 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:09:16.951219 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103f04f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103f4e180>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103f4dd60>]}


============================== 02:09:16.955054 | 238c696f-16cd-43db-a9fa-780667ec27ea ==============================
[0m02:09:16.955054 [info ] [MainThread]: Running with dbt=1.9.3
[0m02:09:16.955466 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/Users/migueldichoso/Downloads/Titanic', 'log_path': '/Users/migueldichoso/Downloads/Titanic/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt build', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:09:47.095675 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '238c696f-16cd-43db-a9fa-780667ec27ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1141498e0>]}
[0m02:09:47.129690 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '238c696f-16cd-43db-a9fa-780667ec27ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10605ffb0>]}
[0m02:09:47.130391 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m02:09:47.249343 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m02:09:47.250032 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m02:09:47.250293 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '238c696f-16cd-43db-a9fa-780667ec27ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11420b3b0>]}
[0m02:09:47.928041 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '238c696f-16cd-43db-a9fa-780667ec27ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11472d0d0>]}
[0m02:09:47.967842 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m02:09:47.972356 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m02:09:47.995583 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '238c696f-16cd-43db-a9fa-780667ec27ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115119700>]}
[0m02:09:47.995932 [info ] [MainThread]: Found 1 model, 2 seeds, 480 macros
[0m02:09:47.997167 [info ] [MainThread]: 
[0m02:09:47.997403 [info ] [MainThread]: Concurrency: 10 threads (target='titanic_dev')
[0m02:09:47.997577 [info ] [MainThread]: 
[0m02:09:47.997874 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m02:09:48.000519 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_analytics'
[0m02:09:48.044002 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
[0m02:09:48.044277 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics"} */
show terse schemas in database analytics
    limit 10000
[0m02:09:48.044465 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:09:53.056511 [debug] [ThreadPool]: SQL status: SUCCESS 1756 in 5.012 seconds
[0m02:09:54.935173 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now create_analytics_aaa_titanic_miguel)
[0m02:09:54.936126 [debug] [ThreadPool]: Creating schema "database: "analytics"
schema: "aaa_titanic_miguel"
"
[0m02:09:54.939240 [debug] [ThreadPool]: Using snowflake connection "create_analytics_aaa_titanic_miguel"
[0m02:09:54.939463 [debug] [ThreadPool]: On create_analytics_aaa_titanic_miguel: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "create_analytics_aaa_titanic_miguel"} */
create schema if not exists analytics.aaa_titanic_miguel
[0m02:09:55.302700 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.363 seconds
[0m02:09:55.306983 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_analytics_aaa_titanic_miguel, now list_analytics_aaa_titanic_miguel)
[0m02:09:55.319805 [debug] [ThreadPool]: Using snowflake connection "list_analytics_aaa_titanic_miguel"
[0m02:09:55.320287 [debug] [ThreadPool]: On list_analytics_aaa_titanic_miguel: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics_aaa_titanic_miguel"} */
show objects in analytics.aaa_titanic_miguel limit 10000;
[0m02:09:55.706348 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.385 seconds
[0m02:09:55.709497 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '238c696f-16cd-43db-a9fa-780667ec27ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114126930>]}
[0m02:09:55.714519 [debug] [Thread-1 (]: Began running node model.titanic.train
[0m02:09:55.714933 [debug] [Thread-2 (]: Began running node seed.titanic.predit_data
[0m02:09:55.715252 [debug] [Thread-3 (]: Began running node seed.titanic.train_data
[0m02:09:55.715715 [info ] [Thread-1 (]: 1 of 3 START sql view model aaa_titanic_miguel.train ........................... [RUN]
[0m02:09:55.716160 [info ] [Thread-2 (]: 2 of 3 START seed file aaa_titanic_miguel.predit_data .......................... [RUN]
[0m02:09:55.716588 [info ] [Thread-3 (]: 3 of 3 START seed file aaa_titanic_miguel.train_data ........................... [RUN]
[0m02:09:55.716957 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_analytics_aaa_titanic_miguel, now model.titanic.train)
[0m02:09:55.717336 [debug] [Thread-2 (]: Acquiring new snowflake connection 'seed.titanic.predit_data'
[0m02:09:55.717649 [debug] [Thread-3 (]: Acquiring new snowflake connection 'seed.titanic.train_data'
[0m02:09:55.717910 [debug] [Thread-1 (]: Began compiling node model.titanic.train
[0m02:09:55.718167 [debug] [Thread-2 (]: Began compiling node seed.titanic.predit_data
[0m02:09:55.718401 [debug] [Thread-3 (]: Began compiling node seed.titanic.train_data
[0m02:09:55.723605 [debug] [Thread-1 (]: Writing injected SQL for node "model.titanic.train"
[0m02:09:55.724008 [debug] [Thread-2 (]: Began executing node seed.titanic.predit_data
[0m02:09:55.724312 [debug] [Thread-3 (]: Began executing node seed.titanic.train_data
[0m02:09:55.756636 [debug] [Thread-2 (]: Using snowflake connection "seed.titanic.predit_data"
[0m02:09:55.758474 [debug] [Thread-3 (]: Using snowflake connection "seed.titanic.train_data"
[0m02:09:55.758752 [debug] [Thread-2 (]: On seed.titanic.predit_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.predit_data"} */
create table analytics.aaa_titanic_miguel.predit_data (employee_id integer,age integer,monthly_expenses float8)
[0m02:09:55.758996 [debug] [Thread-3 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
create table analytics.aaa_titanic_miguel.train_data (employee_id integer,age integer,monthly_expenses float8,attrition text)
[0m02:09:55.759235 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m02:09:55.759480 [debug] [Thread-1 (]: Began executing node model.titanic.train
[0m02:09:55.759670 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:09:55.772944 [debug] [Thread-1 (]: Writing runtime sql for node "model.titanic.train"
[0m02:09:55.776341 [debug] [Thread-1 (]: Using snowflake connection "model.titanic.train"
[0m02:09:55.776632 [debug] [Thread-1 (]: On model.titanic.train: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "model.titanic.train"} */
create or replace   view analytics.aaa_titanic_miguel.train
  
   as (
    import datetime
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.svm import SVC
from snowflake.ml.model import model_signature


def preprocess(df: pd.DataFrame) -> pd.DataFrame:
  df = df[["employee_id","age","monthly_expenses"]]
  return pd.get_dummies(df, columns=["employee_id", "age", "monthly_expenses"])


def model(dbt, session):
  dbt.config(
    materialized="model",
    python_version="3.11",
    packages=["snowflake-ml-python", "pandas", "scikit-learn"],
    schema="models",
  )

  dataset = dbt.ref("train_data")

  data = dataset.to_pandas()

  x = preprocess(data)
  y = data["attrition"]

  imputer = SimpleImputer()
  x = imputer.fit_transform(x)

  model = SVC()
  model.fit(x, y)

  return {
    "model": model,
    "signatures": {"predict": model_signature.infer_signature(x, y)},
    "version_name": datetime.datetime.today().strftime("V%Y%m%d"),
    "metrics": {"r2_score": model.score(x, y)},
    "comment": f"r2_score: {model.score(x, y)}",
    "set_default": True,
  }
  );
[0m02:09:56.103329 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01baeb61-0907-ba98-0007-978308d0a90e
[0m02:09:56.103814 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 4 at position 4 unexpected 'import'.
syntax error line 11 at position 33 unexpected '->'.
[0m02:09:56.107010 [debug] [Thread-1 (]: Database Error in model train (models/train.sql)
  001003 (42000): SQL compilation error:
  syntax error line 4 at position 4 unexpected 'import'.
  syntax error line 11 at position 33 unexpected '->'.
  compiled code at target/run/titanic/models/train.sql
[0m02:09:56.108565 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '238c696f-16cd-43db-a9fa-780667ec27ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1159ab740>]}
[0m02:09:56.108978 [error] [Thread-1 (]: 1 of 3 ERROR creating sql view model aaa_titanic_miguel.train .................. [[31mERROR[0m in 0.39s]
[0m02:09:56.109328 [debug] [Thread-1 (]: Finished running node model.titanic.train
[0m02:09:56.109665 [debug] [Thread-13 ]: Marking all children of 'model.titanic.train' to be skipped because of status 'error'.  Reason: Database Error in model train (models/train.sql)
  001003 (42000): SQL compilation error:
  syntax error line 4 at position 4 unexpected 'import'.
  syntax error line 11 at position 33 unexpected '->'.
  compiled code at target/run/titanic/models/train.sql.
[0m02:09:57.377919 [debug] [Thread-3 (]: SQL status: SUCCESS 1 in 1.618 seconds
[0m02:09:57.396746 [debug] [Thread-3 (]: Using snowflake connection "seed.titanic.train_data"
[0m02:09:57.397164 [debug] [Thread-3 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
BEGIN
[0m02:09:57.520280 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1.761 seconds
[0m02:09:57.526997 [debug] [Thread-2 (]: Using snowflake connection "seed.titanic.predit_data"
[0m02:09:57.527644 [debug] [Thread-2 (]: On seed.titanic.predit_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.predit_data"} */
BEGIN
[0m02:09:57.762099 [debug] [Thread-3 (]: SQL status: SUCCESS 1 in 0.364 seconds
[0m02:09:57.774628 [debug] [Thread-3 (]: Using snowflake connection "seed.titanic.train_data"
[0m02:09:57.775039 [debug] [Thread-3 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
insert into analytics.aaa_titanic_miguel.train_data (employee_id, age, monthly_expenses, attrition) values
            (%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(...
[0m02:09:57.941373 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.413 seconds
[0m02:09:57.946697 [debug] [Thread-2 (]: Using snowflake connection "seed.titanic.predit_data"
[0m02:09:57.947335 [debug] [Thread-2 (]: On seed.titanic.predit_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.predit_data"} */
insert into analytics.aaa_titanic_miguel.predit_data (employee_id, age, monthly_expenses) values
            (%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s...
[0m02:09:58.572833 [debug] [Thread-3 (]: SQL status: SUCCESS 405 in 0.797 seconds
[0m02:09:58.574190 [debug] [Thread-3 (]: Using snowflake connection "seed.titanic.train_data"
[0m02:09:58.574744 [debug] [Thread-3 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
COMMIT
[0m02:09:58.584992 [debug] [Thread-2 (]: SQL status: SUCCESS 200 in 0.637 seconds
[0m02:09:58.585791 [debug] [Thread-2 (]: Using snowflake connection "seed.titanic.predit_data"
[0m02:09:58.586243 [debug] [Thread-2 (]: On seed.titanic.predit_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.predit_data"} */
COMMIT
[0m02:09:59.221084 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.634 seconds
[0m02:09:59.231035 [debug] [Thread-2 (]: Writing runtime SQL for node "seed.titanic.predit_data"
[0m02:09:59.251515 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '238c696f-16cd-43db-a9fa-780667ec27ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1159a1610>]}
[0m02:09:59.251945 [info ] [Thread-2 (]: 2 of 3 OK loaded seed file aaa_titanic_miguel.predit_data ...................... [[32mINSERT 200[0m in 3.53s]
[0m02:09:59.252374 [debug] [Thread-2 (]: Finished running node seed.titanic.predit_data
[0m02:09:59.265812 [debug] [Thread-3 (]: SQL status: SUCCESS 1 in 0.691 seconds
[0m02:09:59.266356 [debug] [Thread-3 (]: Writing runtime SQL for node "seed.titanic.train_data"
[0m02:09:59.268497 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '238c696f-16cd-43db-a9fa-780667ec27ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115a710a0>]}
[0m02:09:59.268835 [info ] [Thread-3 (]: 3 of 3 OK loaded seed file aaa_titanic_miguel.train_data ....................... [[32mINSERT 405[0m in 3.55s]
[0m02:09:59.269189 [debug] [Thread-3 (]: Finished running node seed.titanic.train_data
[0m02:09:59.270129 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:09:59.270318 [debug] [MainThread]: Connection 'model.titanic.train' was left open.
[0m02:09:59.270493 [debug] [MainThread]: On model.titanic.train: Close
[0m02:09:59.873773 [debug] [MainThread]: Connection 'seed.titanic.predit_data' was left open.
[0m02:09:59.874349 [debug] [MainThread]: On seed.titanic.predit_data: Close
[0m02:10:00.477425 [debug] [MainThread]: Connection 'seed.titanic.train_data' was left open.
[0m02:10:00.478156 [debug] [MainThread]: On seed.titanic.train_data: Close
[0m02:10:01.091735 [info ] [MainThread]: 
[0m02:10:01.092850 [info ] [MainThread]: Finished running 2 seeds, 1 view model in 0 hours 0 minutes and 13.09 seconds (13.09s).
[0m02:10:01.094173 [debug] [MainThread]: Command end result
[0m02:10:01.118856 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m02:10:01.120405 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m02:10:01.125023 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/migueldichoso/Downloads/Titanic/target/run_results.json
[0m02:10:01.125263 [info ] [MainThread]: 
[0m02:10:01.125529 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m02:10:01.125727 [info ] [MainThread]: 
[0m02:10:01.125981 [error] [MainThread]:   Database Error in model train (models/train.sql)
  001003 (42000): SQL compilation error:
  syntax error line 4 at position 4 unexpected 'import'.
  syntax error line 11 at position 33 unexpected '->'.
  compiled code at target/run/titanic/models/train.sql
[0m02:10:01.126355 [info ] [MainThread]: 
[0m02:10:01.126632 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
[0m02:10:01.129233 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 44.25153, "process_in_blocks": "0", "process_kernel_time": 0.597143, "process_mem_max_rss": "190808064", "process_out_blocks": "0", "process_user_time": 2.931527}
[0m02:10:01.129588 [debug] [MainThread]: Command `dbt build` failed at 02:10:01.129513 after 44.25 seconds
[0m02:10:01.129869 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103f4df10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1144d3a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103cbd220>]}
[0m02:10:01.130239 [debug] [MainThread]: Flushing usage events
[0m02:10:03.862920 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:10:24.918822 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119c97c80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11aa81e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11aa81a60>]}


============================== 02:10:24.922887 | a8693db2-94f0-418a-a882-bc3fd18b1f1b ==============================
[0m02:10:24.922887 [info ] [MainThread]: Running with dbt=1.9.3
[0m02:10:24.923425 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/migueldichoso/Downloads/Titanic', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/migueldichoso/Downloads/Titanic/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt build --full-refresh', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:10:25.548632 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a8693db2-94f0-418a-a882-bc3fd18b1f1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f2c2c60>]}
[0m02:10:25.583759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a8693db2-94f0-418a-a882-bc3fd18b1f1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119ffae70>]}
[0m02:10:25.584597 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m02:10:25.695787 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m02:10:25.770611 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 1 files added, 0 files changed.
[0m02:10:25.771000 [debug] [MainThread]: Partial parsing: added file: titanic://models/train.py
[0m02:10:25.771207 [debug] [MainThread]: Partial parsing: deleted file: titanic://models/train.sql
[0m02:10:25.914913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a8693db2-94f0-418a-a882-bc3fd18b1f1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f436ea0>]}
[0m02:10:25.954041 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m02:10:25.956171 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m02:10:25.979717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a8693db2-94f0-418a-a882-bc3fd18b1f1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128ce15e0>]}
[0m02:10:25.980043 [info ] [MainThread]: Found 2 seeds, 1 model, 480 macros
[0m02:10:25.981426 [info ] [MainThread]: 
[0m02:10:25.981684 [info ] [MainThread]: Concurrency: 10 threads (target='titanic_dev')
[0m02:10:25.981860 [info ] [MainThread]: 
[0m02:10:25.982171 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m02:10:25.984842 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_analytics'
[0m02:10:25.991641 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_analytics'
[0m02:10:26.033702 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
[0m02:10:26.034109 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
[0m02:10:26.034339 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics"} */
show terse schemas in database analytics
    limit 10000
[0m02:10:26.034546 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics"} */
show terse schemas in database analytics
    limit 10000
[0m02:10:26.034742 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:10:26.034923 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:10:28.488892 [debug] [ThreadPool]: SQL status: SUCCESS 1757 in 2.454 seconds
[0m02:10:28.587231 [debug] [ThreadPool]: SQL status: SUCCESS 1757 in 2.552 seconds
[0m02:10:29.943166 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now create_analytics_aaa_titanic_miguel_models)
[0m02:10:29.943804 [debug] [ThreadPool]: Creating schema "database: "analytics"
schema: "aaa_titanic_miguel_models"
"
[0m02:10:29.947017 [debug] [ThreadPool]: Using snowflake connection "create_analytics_aaa_titanic_miguel_models"
[0m02:10:29.947255 [debug] [ThreadPool]: On create_analytics_aaa_titanic_miguel_models: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "create_analytics_aaa_titanic_miguel_models"} */
create schema if not exists analytics.aaa_titanic_miguel_models
[0m02:10:30.346085 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.398 seconds
[0m02:10:30.350672 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_aaa_titanic_miguel_models)
[0m02:10:30.357661 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_analytics_aaa_titanic_miguel_models, now list_analytics_aaa_titanic_miguel)
[0m02:10:30.362633 [debug] [ThreadPool]: Using snowflake connection "list_analytics_aaa_titanic_miguel_models"
[0m02:10:30.364828 [debug] [ThreadPool]: Using snowflake connection "list_analytics_aaa_titanic_miguel"
[0m02:10:30.365138 [debug] [ThreadPool]: On list_analytics_aaa_titanic_miguel_models: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics_aaa_titanic_miguel_models"} */
show objects in analytics.aaa_titanic_miguel_models limit 10000;
[0m02:10:30.365404 [debug] [ThreadPool]: On list_analytics_aaa_titanic_miguel: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics_aaa_titanic_miguel"} */
show objects in analytics.aaa_titanic_miguel limit 10000;
[0m02:10:30.783963 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 0.418 seconds
[0m02:10:30.843365 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.477 seconds
[0m02:10:30.846934 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a8693db2-94f0-418a-a882-bc3fd18b1f1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12991ecf0>]}
[0m02:10:30.853464 [debug] [Thread-1 (]: Began running node seed.titanic.predit_data
[0m02:10:30.853964 [debug] [Thread-2 (]: Began running node seed.titanic.train_data
[0m02:10:30.854494 [info ] [Thread-1 (]: 1 of 3 START seed file aaa_titanic_miguel.predit_data .......................... [RUN]
[0m02:10:30.855068 [info ] [Thread-2 (]: 2 of 3 START seed file aaa_titanic_miguel.train_data ........................... [RUN]
[0m02:10:30.855582 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_analytics_aaa_titanic_miguel_models, now seed.titanic.predit_data)
[0m02:10:30.855961 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_analytics_aaa_titanic_miguel, now seed.titanic.train_data)
[0m02:10:30.856284 [debug] [Thread-1 (]: Began compiling node seed.titanic.predit_data
[0m02:10:30.856605 [debug] [Thread-2 (]: Began compiling node seed.titanic.train_data
[0m02:10:30.856924 [debug] [Thread-1 (]: Began executing node seed.titanic.predit_data
[0m02:10:30.857212 [debug] [Thread-2 (]: Began executing node seed.titanic.train_data
[0m02:10:30.903565 [debug] [Thread-1 (]: Applying DROP to: "ANALYTICS"."AAA_TITANIC_MIGUEL"."PREDIT_DATA"
[0m02:10:30.905566 [debug] [Thread-2 (]: Applying DROP to: "ANALYTICS"."AAA_TITANIC_MIGUEL"."TRAIN_DATA"
[0m02:10:30.909637 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.predit_data"
[0m02:10:30.910183 [debug] [Thread-2 (]: Using snowflake connection "seed.titanic.train_data"
[0m02:10:30.910415 [debug] [Thread-1 (]: On seed.titanic.predit_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.predit_data"} */
drop table if exists "ANALYTICS"."AAA_TITANIC_MIGUEL"."PREDIT_DATA" cascade
[0m02:10:30.910638 [debug] [Thread-2 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
drop table if exists "ANALYTICS"."AAA_TITANIC_MIGUEL"."TRAIN_DATA" cascade
[0m02:10:31.269441 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.358 seconds
[0m02:10:31.278004 [debug] [Thread-2 (]: Using snowflake connection "seed.titanic.train_data"
[0m02:10:31.278400 [debug] [Thread-2 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
create table analytics.aaa_titanic_miguel.train_data (employee_id integer,age integer,monthly_expenses float8,attrition text)
[0m02:10:31.283954 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.373 seconds
[0m02:10:31.285801 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.predit_data"
[0m02:10:31.286064 [debug] [Thread-1 (]: On seed.titanic.predit_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.predit_data"} */
create table analytics.aaa_titanic_miguel.predit_data (employee_id integer,age integer,monthly_expenses float8)
[0m02:10:31.734286 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.448 seconds
[0m02:10:31.736473 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.458 seconds
[0m02:10:31.757546 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.predit_data"
[0m02:10:31.761885 [debug] [Thread-2 (]: Using snowflake connection "seed.titanic.train_data"
[0m02:10:31.762188 [debug] [Thread-1 (]: On seed.titanic.predit_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.predit_data"} */
BEGIN
[0m02:10:31.762457 [debug] [Thread-2 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
BEGIN
[0m02:10:32.100735 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.337 seconds
[0m02:10:32.110689 [debug] [Thread-2 (]: Using snowflake connection "seed.titanic.train_data"
[0m02:10:32.111143 [debug] [Thread-2 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
insert into analytics.aaa_titanic_miguel.train_data (employee_id, age, monthly_expenses, attrition) values
            (%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(...
[0m02:10:32.139086 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.376 seconds
[0m02:10:32.142264 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.predit_data"
[0m02:10:32.142520 [debug] [Thread-1 (]: On seed.titanic.predit_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.predit_data"} */
insert into analytics.aaa_titanic_miguel.predit_data (employee_id, age, monthly_expenses) values
            (%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s...
[0m02:10:32.875693 [debug] [Thread-1 (]: SQL status: SUCCESS 200 in 0.733 seconds
[0m02:10:32.877023 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.predit_data"
[0m02:10:32.877520 [debug] [Thread-1 (]: On seed.titanic.predit_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.predit_data"} */
COMMIT
[0m02:10:32.927327 [debug] [Thread-2 (]: SQL status: SUCCESS 405 in 0.816 seconds
[0m02:10:32.928913 [debug] [Thread-2 (]: Using snowflake connection "seed.titanic.train_data"
[0m02:10:32.929862 [debug] [Thread-2 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
COMMIT
[0m02:10:33.398377 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.520 seconds
[0m02:10:33.404065 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.titanic.predit_data"
[0m02:10:33.425193 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a8693db2-94f0-418a-a882-bc3fd18b1f1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119344350>]}
[0m02:10:33.425590 [info ] [Thread-1 (]: 1 of 3 OK loaded seed file aaa_titanic_miguel.predit_data ...................... [[32mCREATE 200[0m in 2.57s]
[0m02:10:33.425959 [debug] [Thread-1 (]: Finished running node seed.titanic.predit_data
[0m02:10:33.512005 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.581 seconds
[0m02:10:33.512784 [debug] [Thread-2 (]: Writing runtime SQL for node "seed.titanic.train_data"
[0m02:10:33.516654 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a8693db2-94f0-418a-a882-bc3fd18b1f1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12ad4f650>]}
[0m02:10:33.517128 [info ] [Thread-2 (]: 2 of 3 OK loaded seed file aaa_titanic_miguel.train_data ....................... [[32mCREATE 405[0m in 2.66s]
[0m02:10:33.517600 [debug] [Thread-2 (]: Finished running node seed.titanic.train_data
[0m02:10:33.518184 [debug] [Thread-4 (]: Began running node model.titanic.train
[0m02:10:33.518686 [info ] [Thread-4 (]: 3 of 3 START python model model aaa_titanic_miguel_models.train ................ [RUN]
[0m02:10:33.519136 [debug] [Thread-4 (]: Acquiring new snowflake connection 'model.titanic.train'
[0m02:10:33.519434 [debug] [Thread-4 (]: Began compiling node model.titanic.train
[0m02:10:33.587100 [debug] [Thread-4 (]: Writing injected SQL for node "model.titanic.train"
[0m02:10:33.588012 [debug] [Thread-4 (]: Began executing node model.titanic.train
[0m02:10:33.596316 [debug] [Thread-4 (]: Writing runtime python for node "model.titanic.train"
[0m02:10:33.597703 [debug] [Thread-4 (]: Using snowflake connection "model.titanic.train"
[0m02:10:33.598061 [debug] [Thread-4 (]: On model.titanic.train: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "model.titanic.train"} */
WITH train__dbt_sp AS PROCEDURE ()

RETURNS STRING
LANGUAGE PYTHON
RUNTIME_VERSION = '3.11'
PACKAGES = ('snowflake-ml-python', 'pandas', 'scikit-learn', 'snowflake-snowpark-python')



HANDLER = 'main'
EXECUTE AS CALLER
AS
$$

import sys
sys._xoptions['snowflake_partner_attribution'].append("dbtLabs_dbtPython")


        


import importlib.util
if importlib.util.find_spec("snowflake.ml") is None:
    raise ImportError("snowflake.ml is not found. Add snowflake-ml-python to package dependencies.")
from snowflake.ml.registry import Registry
import datetime
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.svm import SVC
from snowflake.ml.model import model_signature


def preprocess(df: pd.DataFrame) -> pd.DataFrame:
  df = df[["employee_id","age","monthly_expenses"]]
  return pd.get_dummies(df, columns=["employee_id", "age", "monthly_expenses"])


def model(dbt, session):
  dbt.config(
    materialized="model",
    python_version="3.11",
    packages=["snowflake-ml-python", "pandas", "scikit-learn"],
    schema="models",
  )

  dataset = dbt.ref("train_data")

  data = dataset.to_pandas()

  x = preprocess(data)
  y = data["attrition"]

  imputer = SimpleImputer()
  x = imputer.fit_transform(x)

  model = SVC()
  model.fit(x, y)

  return {
    "model": model,
    "signatures": {"predict": model_signature.infer_signature(x, y)},
    "version_name": datetime.datetime.today().strftime("V%Y%m%d"),
    "metrics": {"r2_score": model.score(x, y)},
    "comment": f"r2_score: {model.score(x, y)}",
    "set_default": True,
  }


# This part is user provided model code
# you will need to copy the next section to run the code
# COMMAND ----------
# this part is dbt logic for get ref work, do not modify

def ref(*args, **kwargs):
    refs = {"train_data": "analytics.aaa_titanic_miguel.train_data"}
    key = '.'.join(args)
    version = kwargs.get("v") or kwargs.get("version")
    if version:
        key += f".v{version}"
    dbt_load_df_function = kwargs.get("dbt_load_df_function")
    return dbt_load_df_function(refs[key])


def source(*args, dbt_load_df_function):
    sources = {}
    key = '.'.join(args)
    return dbt_load_df_function(sources[key])


config_dict = {}


class config:
    def __init__(self, *args, **kwargs):
        pass

    @staticmethod
    def get(key, default=None):
        return config_dict.get(key, default)

class this:
    """dbt.this() or dbt.this.identifier"""
    database = "analytics"
    schema = "aaa_titanic_miguel_models"
    identifier = "train"
    
    def __repr__(self):
        return 'analytics.aaa_titanic_miguel_models.train'


class dbtObj:
    def __init__(self, load_df_function) -> None:
        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)
        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)
        self.config = config
        self.this = this()
        self.is_incremental = False

# COMMAND ----------



def main(session):
    dbt = dbtObj(session.table)
    model_dict = model(dbt, session)
    reg = Registry(
        session = session,
        database_name = dbt.this.database,
        schema_name = dbt.this.schema
    )
    set_default = model_dict.pop("set_default", False)
    assert "model_name" not in model_dict, "model_name cannot be overridden"
    assert "conda_dependencies" not in model_dict, "conda_dependencies cannot be overridden"
    mv = reg.log_model(
        **model_dict,
        model_name = "analytics.aaa_titanic_miguel_models.train",
        conda_dependencies = ['snowflake-ml-python', 'pandas', 'scikit-learn'],
    )
    if set_default:
        reg.get_model(dbt.this.identifier).default = mv
    return "OK"

$$
CALL train__dbt_sp();
[0m02:10:33.598397 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m02:11:41.320601 [debug] [Thread-4 (]: Snowflake adapter: Snowflake query id: None
[0m02:11:41.321455 [debug] [Thread-4 (]: Snowflake adapter: Snowflake error: 100357 (P0000): Python Interpreter Error:
Traceback (most recent call last):
  File "_udf_code.py", line 113, in main
    model_dict = model(dbt, session)
                 ^^^^^^^^^^^^^^^^^^^
  File "_udf_code.py", line 38, in model
    x = preprocess(data)
        ^^^^^^^^^^^^^^^^
  File "_udf_code.py", line 22, in preprocess
    df = df[["employee_id","age","monthly_expenses"]]
         ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/frame.py", line 4108, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6200, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6249, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['employee_id', 'age', 'monthly_expenses'], dtype='object')] are in the [columns]"
 in function TRAIN__DBT_SP with handler main
[0m02:11:41.325787 [debug] [Thread-4 (]: Database Error in model train (models/train.py)
  100357 (P0000): Python Interpreter Error:
  Traceback (most recent call last):
    File "_udf_code.py", line 113, in main
      model_dict = model(dbt, session)
                   ^^^^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 38, in model
      x = preprocess(data)
          ^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 22, in preprocess
      df = df[["employee_id","age","monthly_expenses"]]
           ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/frame.py", line 4108, in __getitem__
      indexer = self.columns._get_indexer_strict(key, "columns")[1]
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6200, in _get_indexer_strict
      self._raise_if_missing(keyarr, indexer, axis_name)
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6249, in _raise_if_missing
      raise KeyError(f"None of [{key}] are in the [{axis_name}]")
  KeyError: "None of [Index(['employee_id', 'age', 'monthly_expenses'], dtype='object')] are in the [columns]"
   in function TRAIN__DBT_SP with handler main
  compiled code at target/run/titanic/models/train.py
[0m02:11:41.326365 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a8693db2-94f0-418a-a882-bc3fd18b1f1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12ab20260>]}
[0m02:11:41.326991 [error] [Thread-4 (]: 3 of 3 ERROR creating python model model aaa_titanic_miguel_models.train ....... [[31mERROR[0m in 67.81s]
[0m02:11:41.327542 [debug] [Thread-4 (]: Finished running node model.titanic.train
[0m02:11:41.328142 [debug] [Thread-13 ]: Marking all children of 'model.titanic.train' to be skipped because of status 'error'.  Reason: Database Error in model train (models/train.py)
  100357 (P0000): Python Interpreter Error:
  Traceback (most recent call last):
    File "_udf_code.py", line 113, in main
      model_dict = model(dbt, session)
                   ^^^^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 38, in model
      x = preprocess(data)
          ^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 22, in preprocess
      df = df[["employee_id","age","monthly_expenses"]]
           ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/frame.py", line 4108, in __getitem__
      indexer = self.columns._get_indexer_strict(key, "columns")[1]
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6200, in _get_indexer_strict
      self._raise_if_missing(keyarr, indexer, axis_name)
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6249, in _raise_if_missing
      raise KeyError(f"None of [{key}] are in the [{axis_name}]")
  KeyError: "None of [Index(['employee_id', 'age', 'monthly_expenses'], dtype='object')] are in the [columns]"
   in function TRAIN__DBT_SP with handler main
  compiled code at target/run/titanic/models/train.py.
[0m02:11:41.329705 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:11:41.329920 [debug] [MainThread]: Connection 'seed.titanic.predit_data' was left open.
[0m02:11:41.330119 [debug] [MainThread]: On seed.titanic.predit_data: Close
[0m02:11:41.986811 [debug] [MainThread]: Connection 'seed.titanic.train_data' was left open.
[0m02:11:41.987553 [debug] [MainThread]: On seed.titanic.train_data: Close
[0m02:11:42.592485 [debug] [MainThread]: Connection 'model.titanic.train' was left open.
[0m02:11:42.593261 [debug] [MainThread]: On model.titanic.train: Close
[0m02:11:43.477833 [info ] [MainThread]: 
[0m02:11:43.478752 [info ] [MainThread]: Finished running 1 model model, 2 seeds in 0 hours 1 minutes and 17.50 seconds (77.50s).
[0m02:11:43.480084 [debug] [MainThread]: Command end result
[0m02:11:43.503921 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m02:11:43.505811 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m02:11:43.510295 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/migueldichoso/Downloads/Titanic/target/run_results.json
[0m02:11:43.510523 [info ] [MainThread]: 
[0m02:11:43.510796 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m02:11:43.510995 [info ] [MainThread]: 
[0m02:11:43.511275 [error] [MainThread]:   Database Error in model train (models/train.py)
  100357 (P0000): Python Interpreter Error:
  Traceback (most recent call last):
    File "_udf_code.py", line 113, in main
      model_dict = model(dbt, session)
                   ^^^^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 38, in model
      x = preprocess(data)
          ^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 22, in preprocess
      df = df[["employee_id","age","monthly_expenses"]]
           ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/frame.py", line 4108, in __getitem__
      indexer = self.columns._get_indexer_strict(key, "columns")[1]
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6200, in _get_indexer_strict
      self._raise_if_missing(keyarr, indexer, axis_name)
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6249, in _raise_if_missing
      raise KeyError(f"None of [{key}] are in the [{axis_name}]")
  KeyError: "None of [Index(['employee_id', 'age', 'monthly_expenses'], dtype='object')] are in the [columns]"
   in function TRAIN__DBT_SP with handler main
  compiled code at target/run/titanic/models/train.py
[0m02:11:43.511608 [info ] [MainThread]: 
[0m02:11:43.511871 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
[0m02:11:43.514005 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 78.67162, "process_in_blocks": "0", "process_kernel_time": 0.407017, "process_mem_max_rss": "192512000", "process_out_blocks": "0", "process_user_time": 2.186239}
[0m02:11:43.514296 [debug] [MainThread]: Command `dbt build` failed at 02:11:43.514235 after 78.67 seconds
[0m02:11:43.514546 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f768410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f768350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b7ddcd0>]}
[0m02:11:43.514780 [debug] [MainThread]: Flushing usage events
[0m02:11:49.604122 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:13:45.242247 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b92000>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1112814c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111281be0>]}


============================== 02:13:45.246190 | 4ceb846f-2b48-4d5c-8262-883593017634 ==============================
[0m02:13:45.246190 [info ] [MainThread]: Running with dbt=1.9.3
[0m02:13:45.246689 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/migueldichoso/Downloads/Titanic/logs', 'debug': 'False', 'profiles_dir': '/Users/migueldichoso/Downloads/Titanic', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt deps', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:13:45.327906 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4ceb846f-2b48-4d5c-8262-883593017634', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10530ee70>]}
[0m02:13:45.354351 [debug] [MainThread]: Set downloads directory='/var/folders/4k/qgw9v5597454dxtzb5g7z3cc0000gq/T/dbt-downloads-w02n9418'
[0m02:13:45.354748 [info ] [MainThread]: Installing https://github.com/estie-inc/dbt_snowflake_ml.git
[0m02:13:45.355065 [debug] [MainThread]: Executing "git clone --depth 1 https://github.com/estie-inc/dbt_snowflake_ml.git 6736b3dfda89a381ba813a0d56eebc29"
[0m02:13:49.065833 [debug] [MainThread]: STDOUT: "b''"
[0m02:13:49.066693 [debug] [MainThread]: STDERR: "b"Cloning into '6736b3dfda89a381ba813a0d56eebc29'...\n""
[0m02:13:49.067252 [debug] [MainThread]: Pulling new dependency 6736b3dfda89a381ba813a0d56eebc29.
[0m02:13:49.067509 [debug] [MainThread]: Executing "git rev-parse HEAD"
[0m02:13:49.076616 [debug] [MainThread]: STDOUT: "b'bd445d1fd307d42674887868e238eb5835365fd8\n'"
[0m02:13:49.077210 [debug] [MainThread]: STDERR: "b''"
[0m02:13:49.077510 [debug] [MainThread]: Checking out revision bd445d1fd307d42674887868e238eb5835365fd8.
[0m02:13:49.077735 [debug] [MainThread]: Executing "git fetch origin --depth 1 bd445d1fd307d42674887868e238eb5835365fd8"
[0m02:13:52.217429 [debug] [MainThread]: STDOUT: "b''"
[0m02:13:52.218515 [debug] [MainThread]: STDERR: "b'From https://github.com/estie-inc/dbt_snowflake_ml\n * branch            bd445d1fd307d42674887868e238eb5835365fd8 -> FETCH_HEAD\n'"
[0m02:13:52.218923 [debug] [MainThread]: Executing "git reset --hard bd445d1fd307d42674887868e238eb5835365fd8"
[0m02:13:52.236499 [debug] [MainThread]: STDOUT: "b'HEAD is now at bd445d1 update package resolution\n'"
[0m02:13:52.237232 [debug] [MainThread]: STDERR: "b''"
[0m02:13:52.237534 [debug] [MainThread]: Executing "git rev-parse HEAD"
[0m02:13:52.246736 [debug] [MainThread]: STDOUT: "b'bd445d1fd307d42674887868e238eb5835365fd8\n'"
[0m02:13:52.247224 [debug] [MainThread]: STDERR: "b''"
[0m02:13:52.247521 [debug] [MainThread]: Checked out at bd445d1.
[0m02:13:52.247741 [debug] [MainThread]: Executing "git rev-parse HEAD"
[0m02:13:52.254941 [debug] [MainThread]: STDOUT: "b'bd445d1fd307d42674887868e238eb5835365fd8\n'"
[0m02:13:52.255327 [debug] [MainThread]: STDERR: "b''"
[0m02:13:52.256219 [debug] [MainThread]: Executing "git clone --depth 1 https://github.com/estie-inc/dbt_snowflake_ml.git 6736b3dfda89a381ba813a0d56eebc29"
[0m02:13:52.264050 [debug] [MainThread]: STDOUT: "b''"
[0m02:13:52.264467 [debug] [MainThread]: STDERR: "b"fatal: destination path '6736b3dfda89a381ba813a0d56eebc29' already exists and is not an empty directory.\n""
[0m02:13:52.264633 [debug] [MainThread]: command return code=128
[0m02:13:52.265288 [debug] [MainThread]: Updating existing dependency 6736b3dfda89a381ba813a0d56eebc29.
[0m02:13:52.265482 [debug] [MainThread]: Executing "git rev-parse HEAD"
[0m02:13:52.273155 [debug] [MainThread]: STDOUT: "b'bd445d1fd307d42674887868e238eb5835365fd8\n'"
[0m02:13:52.273537 [debug] [MainThread]: STDERR: "b''"
[0m02:13:52.273759 [debug] [MainThread]: Checking out revision bd445d1fd307d42674887868e238eb5835365fd8.
[0m02:13:52.273962 [debug] [MainThread]: Executing "git fetch origin --depth 1 bd445d1fd307d42674887868e238eb5835365fd8"
[0m02:13:55.355885 [debug] [MainThread]: STDOUT: "b''"
[0m02:13:55.356564 [debug] [MainThread]: STDERR: "b'From https://github.com/estie-inc/dbt_snowflake_ml\n * branch            bd445d1fd307d42674887868e238eb5835365fd8 -> FETCH_HEAD\n'"
[0m02:13:55.356821 [debug] [MainThread]: Executing "git reset --hard bd445d1fd307d42674887868e238eb5835365fd8"
[0m02:13:55.367967 [debug] [MainThread]: STDOUT: "b'HEAD is now at bd445d1 update package resolution\n'"
[0m02:13:55.368362 [debug] [MainThread]: STDERR: "b''"
[0m02:13:55.368560 [debug] [MainThread]: Executing "git rev-parse HEAD"
[0m02:13:55.374650 [debug] [MainThread]: STDOUT: "b'bd445d1fd307d42674887868e238eb5835365fd8\n'"
[0m02:13:55.374971 [debug] [MainThread]: STDERR: "b''"
[0m02:13:55.375166 [debug] [MainThread]: Already at bd445d1, nothing to do.
[0m02:13:55.375546 [info ] [MainThread]: Installed from revision bd445d1fd307d42674887868e238eb5835365fd8
[0m02:13:55.375849 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '4ceb846f-2b48-4d5c-8262-883593017634', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116011c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111601730>]}
[0m02:13:55.377838 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 10.210368, "process_in_blocks": "0", "process_kernel_time": 0.228523, "process_mem_max_rss": "95649792", "process_out_blocks": "0", "process_user_time": 0.889913}
[0m02:13:55.378151 [debug] [MainThread]: Command `dbt deps` succeeded at 02:13:55.378088 after 10.21 seconds
[0m02:13:55.378429 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111281bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111282000>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1114d5c70>]}
[0m02:13:55.378628 [debug] [MainThread]: Flushing usage events
[0m02:13:57.200635 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:14:04.800946 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1189ed460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11aa79ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11aa79b20>]}


============================== 02:14:04.805172 | ab8f6ffd-7a54-4f4b-a682-cce6069badda ==============================
[0m02:14:04.805172 [info ] [MainThread]: Running with dbt=1.9.3
[0m02:14:04.805597 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/migueldichoso/Downloads/Titanic', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/Users/migueldichoso/Downloads/Titanic/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m02:14:05.440818 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ab8f6ffd-7a54-4f4b-a682-cce6069badda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11aa786e0>]}
[0m02:14:05.475010 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ab8f6ffd-7a54-4f4b-a682-cce6069badda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fc60a10>]}
[0m02:14:05.476062 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m02:14:05.586808 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m02:14:05.659269 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 1 files added, 0 files changed.
[0m02:14:05.659652 [debug] [MainThread]: Partial parsing: added file: titanic://seeds/predict_data.csv
[0m02:14:05.659849 [debug] [MainThread]: Partial parsing: deleted file: titanic://seeds/predit_data.csv
[0m02:14:05.784025 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ab8f6ffd-7a54-4f4b-a682-cce6069badda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121581820>]}
[0m02:14:05.822445 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m02:14:05.824678 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m02:14:05.836963 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ab8f6ffd-7a54-4f4b-a682-cce6069badda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121538da0>]}
[0m02:14:05.837257 [info ] [MainThread]: Found 2 seeds, 1 model, 480 macros
[0m02:14:05.837471 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ab8f6ffd-7a54-4f4b-a682-cce6069badda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12113dbe0>]}
[0m02:14:05.838510 [info ] [MainThread]: 
[0m02:14:05.838736 [info ] [MainThread]: Concurrency: 10 threads (target='titanic_dev')
[0m02:14:05.838900 [info ] [MainThread]: 
[0m02:14:05.839186 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m02:14:05.839725 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_analytics'
[0m02:14:05.885032 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
[0m02:14:05.885325 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics"} */
show terse schemas in database analytics
    limit 10000
[0m02:14:05.885525 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:14:08.957591 [debug] [ThreadPool]: SQL status: SUCCESS 1758 in 3.072 seconds
[0m02:14:10.324935 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_aaa_titanic_miguel)
[0m02:14:10.325380 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_analytics_aaa_titanic_miguel_models'
[0m02:14:10.331850 [debug] [ThreadPool]: Using snowflake connection "list_analytics_aaa_titanic_miguel"
[0m02:14:10.333182 [debug] [ThreadPool]: Using snowflake connection "list_analytics_aaa_titanic_miguel_models"
[0m02:14:10.333401 [debug] [ThreadPool]: On list_analytics_aaa_titanic_miguel: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics_aaa_titanic_miguel"} */
show objects in analytics.aaa_titanic_miguel limit 10000;
[0m02:14:10.333595 [debug] [ThreadPool]: On list_analytics_aaa_titanic_miguel_models: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics_aaa_titanic_miguel_models"} */
show objects in analytics.aaa_titanic_miguel_models limit 10000;
[0m02:14:10.334029 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:14:10.727852 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 0.394 seconds
[0m02:14:11.789035 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 1.455 seconds
[0m02:14:11.793399 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ab8f6ffd-7a54-4f4b-a682-cce6069badda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12113ebd0>]}
[0m02:14:11.798174 [debug] [Thread-1 (]: Began running node model.titanic.train
[0m02:14:11.798823 [info ] [Thread-1 (]: 1 of 1 START python model model aaa_titanic_miguel_models.train ................ [RUN]
[0m02:14:11.799267 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_analytics_aaa_titanic_miguel, now model.titanic.train)
[0m02:14:11.799581 [debug] [Thread-1 (]: Began compiling node model.titanic.train
[0m02:14:11.822295 [debug] [Thread-1 (]: Writing injected SQL for node "model.titanic.train"
[0m02:14:11.823184 [debug] [Thread-1 (]: Began executing node model.titanic.train
[0m02:14:11.836968 [debug] [Thread-1 (]: Writing runtime python for node "model.titanic.train"
[0m02:14:11.838361 [debug] [Thread-1 (]: Using snowflake connection "model.titanic.train"
[0m02:14:11.838730 [debug] [Thread-1 (]: On model.titanic.train: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "model.titanic.train"} */
WITH train__dbt_sp AS PROCEDURE ()

RETURNS STRING
LANGUAGE PYTHON
RUNTIME_VERSION = '3.11'
PACKAGES = ('snowflake-ml-python', 'pandas', 'scikit-learn', 'snowflake-snowpark-python')



HANDLER = 'main'
EXECUTE AS CALLER
AS
$$

import sys
sys._xoptions['snowflake_partner_attribution'].append("dbtLabs_dbtPython")


        


import importlib.util
if importlib.util.find_spec("snowflake.ml") is None:
    raise ImportError("snowflake.ml is not found. Add snowflake-ml-python to package dependencies.")
from snowflake.ml.registry import Registry
import datetime
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.svm import SVC
from snowflake.ml.model import model_signature


def preprocess(df: pd.DataFrame) -> pd.DataFrame:
  df = df[["employee_id","age","monthly_expenses"]]
  return pd.get_dummies(df, columns=["employee_id", "age", "monthly_expenses"])


def model(dbt, session):
  dbt.config(
    materialized="model",
    python_version="3.11",
    packages=["snowflake-ml-python", "pandas", "scikit-learn"],
    schema="models",
  )

  dataset = dbt.ref("train_data")

  data = dataset.to_pandas()

  x = preprocess(data)
  y = data["attrition"]

  imputer = SimpleImputer()
  x = imputer.fit_transform(x)

  model = SVC()
  model.fit(x, y)

  return {
    "model": model,
    "signatures": {"predict": model_signature.infer_signature(x, y)},
    "version_name": datetime.datetime.today().strftime("V%Y%m%d"),
    "metrics": {"r2_score": model.score(x, y)},
    "comment": f"r2_score: {model.score(x, y)}",
    "set_default": True,
  }


# This part is user provided model code
# you will need to copy the next section to run the code
# COMMAND ----------
# this part is dbt logic for get ref work, do not modify

def ref(*args, **kwargs):
    refs = {"train_data": "analytics.aaa_titanic_miguel.train_data"}
    key = '.'.join(args)
    version = kwargs.get("v") or kwargs.get("version")
    if version:
        key += f".v{version}"
    dbt_load_df_function = kwargs.get("dbt_load_df_function")
    return dbt_load_df_function(refs[key])


def source(*args, dbt_load_df_function):
    sources = {}
    key = '.'.join(args)
    return dbt_load_df_function(sources[key])


config_dict = {}


class config:
    def __init__(self, *args, **kwargs):
        pass

    @staticmethod
    def get(key, default=None):
        return config_dict.get(key, default)

class this:
    """dbt.this() or dbt.this.identifier"""
    database = "analytics"
    schema = "aaa_titanic_miguel_models"
    identifier = "train"
    
    def __repr__(self):
        return 'analytics.aaa_titanic_miguel_models.train'


class dbtObj:
    def __init__(self, load_df_function) -> None:
        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)
        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)
        self.config = config
        self.this = this()
        self.is_incremental = False

# COMMAND ----------



def main(session):
    dbt = dbtObj(session.table)
    model_dict = model(dbt, session)
    reg = Registry(
        session = session,
        database_name = dbt.this.database,
        schema_name = dbt.this.schema
    )
    set_default = model_dict.pop("set_default", False)
    assert "model_name" not in model_dict, "model_name cannot be overridden"
    assert "conda_dependencies" not in model_dict, "conda_dependencies cannot be overridden"
    mv = reg.log_model(
        **model_dict,
        model_name = "analytics.aaa_titanic_miguel_models.train",
        conda_dependencies = ['snowflake-ml-python', 'pandas', 'scikit-learn'],
    )
    if set_default:
        reg.get_model(dbt.this.identifier).default = mv
    return "OK"

$$
CALL train__dbt_sp();
[0m02:15:33.584335 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: None
[0m02:15:33.585298 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 100357 (P0000): Python Interpreter Error:
Traceback (most recent call last):
  File "_udf_code.py", line 113, in main
    model_dict = model(dbt, session)
                 ^^^^^^^^^^^^^^^^^^^
  File "_udf_code.py", line 38, in model
    x = preprocess(data)
        ^^^^^^^^^^^^^^^^
  File "_udf_code.py", line 22, in preprocess
    df = df[["employee_id","age","monthly_expenses"]]
         ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/frame.py", line 4108, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6200, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6249, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['employee_id', 'age', 'monthly_expenses'], dtype='object')] are in the [columns]"
 in function TRAIN__DBT_SP with handler main
[0m02:15:33.590009 [debug] [Thread-1 (]: Database Error in model train (models/train.py)
  100357 (P0000): Python Interpreter Error:
  Traceback (most recent call last):
    File "_udf_code.py", line 113, in main
      model_dict = model(dbt, session)
                   ^^^^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 38, in model
      x = preprocess(data)
          ^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 22, in preprocess
      df = df[["employee_id","age","monthly_expenses"]]
           ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/frame.py", line 4108, in __getitem__
      indexer = self.columns._get_indexer_strict(key, "columns")[1]
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6200, in _get_indexer_strict
      self._raise_if_missing(keyarr, indexer, axis_name)
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6249, in _raise_if_missing
      raise KeyError(f"None of [{key}] are in the [{axis_name}]")
  KeyError: "None of [Index(['employee_id', 'age', 'monthly_expenses'], dtype='object')] are in the [columns]"
   in function TRAIN__DBT_SP with handler main
  compiled code at target/run/titanic/models/train.py
[0m02:15:33.592030 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ab8f6ffd-7a54-4f4b-a682-cce6069badda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1251883e0>]}
[0m02:15:33.592644 [error] [Thread-1 (]: 1 of 1 ERROR creating python model model aaa_titanic_miguel_models.train ....... [[31mERROR[0m in 81.79s]
[0m02:15:33.593234 [debug] [Thread-1 (]: Finished running node model.titanic.train
[0m02:15:33.593765 [debug] [Thread-13 ]: Marking all children of 'model.titanic.train' to be skipped because of status 'error'.  Reason: Database Error in model train (models/train.py)
  100357 (P0000): Python Interpreter Error:
  Traceback (most recent call last):
    File "_udf_code.py", line 113, in main
      model_dict = model(dbt, session)
                   ^^^^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 38, in model
      x = preprocess(data)
          ^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 22, in preprocess
      df = df[["employee_id","age","monthly_expenses"]]
           ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/frame.py", line 4108, in __getitem__
      indexer = self.columns._get_indexer_strict(key, "columns")[1]
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6200, in _get_indexer_strict
      self._raise_if_missing(keyarr, indexer, axis_name)
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6249, in _raise_if_missing
      raise KeyError(f"None of [{key}] are in the [{axis_name}]")
  KeyError: "None of [Index(['employee_id', 'age', 'monthly_expenses'], dtype='object')] are in the [columns]"
   in function TRAIN__DBT_SP with handler main
  compiled code at target/run/titanic/models/train.py.
[0m02:15:33.595593 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:15:33.595812 [debug] [MainThread]: Connection 'model.titanic.train' was left open.
[0m02:15:33.596013 [debug] [MainThread]: On model.titanic.train: Close
[0m02:15:34.227897 [debug] [MainThread]: Connection 'list_analytics_aaa_titanic_miguel_models' was left open.
[0m02:15:34.228412 [debug] [MainThread]: On list_analytics_aaa_titanic_miguel_models: Close
[0m02:15:34.961537 [info ] [MainThread]: 
[0m02:15:34.962826 [info ] [MainThread]: Finished running 1 model model in 0 hours 1 minutes and 29.12 seconds (89.12s).
[0m02:15:34.963895 [debug] [MainThread]: Command end result
[0m02:15:34.985689 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m02:15:34.987482 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m02:15:34.992683 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/migueldichoso/Downloads/Titanic/target/run_results.json
[0m02:15:34.992932 [info ] [MainThread]: 
[0m02:15:34.993224 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m02:15:34.993431 [info ] [MainThread]: 
[0m02:15:34.993720 [error] [MainThread]:   Database Error in model train (models/train.py)
  100357 (P0000): Python Interpreter Error:
  Traceback (most recent call last):
    File "_udf_code.py", line 113, in main
      model_dict = model(dbt, session)
                   ^^^^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 38, in model
      x = preprocess(data)
          ^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 22, in preprocess
      df = df[["employee_id","age","monthly_expenses"]]
           ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/frame.py", line 4108, in __getitem__
      indexer = self.columns._get_indexer_strict(key, "columns")[1]
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6200, in _get_indexer_strict
      self._raise_if_missing(keyarr, indexer, axis_name)
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6249, in _raise_if_missing
      raise KeyError(f"None of [{key}] are in the [{axis_name}]")
  KeyError: "None of [Index(['employee_id', 'age', 'monthly_expenses'], dtype='object')] are in the [columns]"
   in function TRAIN__DBT_SP with handler main
  compiled code at target/run/titanic/models/train.py
[0m02:15:34.993968 [info ] [MainThread]: 
[0m02:15:34.994171 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m02:15:34.996563 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 90.2751, "process_in_blocks": "0", "process_kernel_time": 0.411242, "process_mem_max_rss": "184532992", "process_out_blocks": "0", "process_user_time": 1.850865}
[0m02:15:34.996938 [debug] [MainThread]: Command `dbt run` failed at 02:15:34.996872 after 90.28 seconds
[0m02:15:34.997232 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119c44950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fd4ba40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f91ca10>]}
[0m02:15:34.997482 [debug] [MainThread]: Flushing usage events
[0m02:15:38.774964 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:17:19.937232 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10845b170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10847e000>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10847db20>]}


============================== 02:17:19.941117 | 78b92ebb-2033-4a27-a4cc-3ba63d93a8c4 ==============================
[0m02:17:19.941117 [info ] [MainThread]: Running with dbt=1.9.3
[0m02:17:19.941541 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/migueldichoso/Downloads/Titanic', 'debug': 'False', 'warn_error': 'None', 'log_path': '/Users/migueldichoso/Downloads/Titanic/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m02:17:20.542316 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '78b92ebb-2033-4a27-a4cc-3ba63d93a8c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10865eab0>]}
[0m02:17:20.576615 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '78b92ebb-2033-4a27-a4cc-3ba63d93a8c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b8dd2b0>]}
[0m02:17:20.577338 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m02:17:20.685965 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m02:17:20.756583 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m02:17:20.756958 [debug] [MainThread]: Partial parsing: added file: titanic://models/sklearn_model.py
[0m02:17:20.873479 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.titanic.sklearn_model' (models/sklearn_model.py) depends on a node named 'titanic3' which was not found
[0m02:17:20.876550 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.0112536, "process_in_blocks": "0", "process_kernel_time": 0.340993, "process_mem_max_rss": "159432704", "process_out_blocks": "0", "process_user_time": 1.406318}
[0m02:17:20.876879 [debug] [MainThread]: Command `dbt run` failed at 02:17:20.876810 after 1.01 seconds
[0m02:17:20.877159 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10847dd60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070b2540>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088ad850>]}
[0m02:17:20.877413 [debug] [MainThread]: Flushing usage events
[0m02:17:22.622426 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:17:37.223164 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b13920>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b81d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b818b0>]}


============================== 02:17:37.227203 | 21096619-3fa8-4445-a36e-1addbb27cb13 ==============================
[0m02:17:37.227203 [info ] [MainThread]: Running with dbt=1.9.3
[0m02:17:37.227650 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/migueldichoso/Downloads/Titanic/logs', 'profiles_dir': '/Users/migueldichoso/Downloads/Titanic', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m02:17:37.740714 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '21096619-3fa8-4445-a36e-1addbb27cb13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de889e0>]}
[0m02:17:37.774663 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '21096619-3fa8-4445-a36e-1addbb27cb13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a7f2360>]}
[0m02:17:37.775740 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m02:17:37.883224 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m02:17:37.955166 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 2 files added, 0 files changed.
[0m02:17:37.955583 [debug] [MainThread]: Partial parsing: added file: titanic://seeds/titanic3.csv
[0m02:17:37.955805 [debug] [MainThread]: Partial parsing: added file: titanic://models/sklearn_model.py
[0m02:17:38.169948 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '21096619-3fa8-4445-a36e-1addbb27cb13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df09190>]}
[0m02:17:38.207914 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m02:17:38.210005 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m02:17:38.223663 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '21096619-3fa8-4445-a36e-1addbb27cb13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e590380>]}
[0m02:17:38.223967 [info ] [MainThread]: Found 3 seeds, 2 models, 480 macros
[0m02:17:38.224192 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '21096619-3fa8-4445-a36e-1addbb27cb13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e5b7350>]}
[0m02:17:38.225288 [info ] [MainThread]: 
[0m02:17:38.225512 [info ] [MainThread]: Concurrency: 10 threads (target='titanic_dev')
[0m02:17:38.225680 [info ] [MainThread]: 
[0m02:17:38.225966 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m02:17:38.228607 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_analytics'
[0m02:17:38.235268 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_analytics'
[0m02:17:38.273936 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
[0m02:17:38.274308 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
[0m02:17:38.274532 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics"} */
show terse schemas in database analytics
    limit 10000
[0m02:17:38.274745 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics"} */
show terse schemas in database analytics
    limit 10000
[0m02:17:38.274946 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:17:38.275137 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:17:41.421316 [debug] [ThreadPool]: SQL status: SUCCESS 1758 in 3.146 seconds
[0m02:17:41.423374 [debug] [ThreadPool]: SQL status: SUCCESS 1758 in 3.148 seconds
[0m02:17:42.844815 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_aaa_titanic_miguel_models)
[0m02:17:42.851083 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_aaa_titanic_miguel)
[0m02:17:42.851564 [debug] [ThreadPool]: Using snowflake connection "list_analytics_aaa_titanic_miguel_models"
[0m02:17:42.852885 [debug] [ThreadPool]: Using snowflake connection "list_analytics_aaa_titanic_miguel"
[0m02:17:42.853116 [debug] [ThreadPool]: On list_analytics_aaa_titanic_miguel_models: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics_aaa_titanic_miguel_models"} */
show objects in analytics.aaa_titanic_miguel_models limit 10000;
[0m02:17:42.853316 [debug] [ThreadPool]: On list_analytics_aaa_titanic_miguel: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics_aaa_titanic_miguel"} */
show objects in analytics.aaa_titanic_miguel limit 10000;
[0m02:17:43.179365 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.326 seconds
[0m02:17:43.244376 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 0.390 seconds
[0m02:17:43.248453 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '21096619-3fa8-4445-a36e-1addbb27cb13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118e15310>]}
[0m02:17:43.253897 [debug] [Thread-1 (]: Began running node model.titanic.sklearn_model
[0m02:17:43.254356 [debug] [Thread-2 (]: Began running node model.titanic.train
[0m02:17:43.254926 [info ] [Thread-1 (]: 1 of 2 START python model model aaa_titanic_miguel.sklearn_model ............... [RUN]
[0m02:17:43.255532 [info ] [Thread-2 (]: 2 of 2 START python model model aaa_titanic_miguel_models.train ................ [RUN]
[0m02:17:43.256030 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_analytics_aaa_titanic_miguel_models, now model.titanic.sklearn_model)
[0m02:17:43.256415 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_analytics_aaa_titanic_miguel, now model.titanic.train)
[0m02:17:43.256770 [debug] [Thread-1 (]: Began compiling node model.titanic.sklearn_model
[0m02:17:43.257088 [debug] [Thread-2 (]: Began compiling node model.titanic.train
[0m02:17:43.281365 [debug] [Thread-2 (]: Writing injected SQL for node "model.titanic.train"
[0m02:17:43.281947 [debug] [Thread-1 (]: Writing injected SQL for node "model.titanic.sklearn_model"
[0m02:17:43.282576 [debug] [Thread-2 (]: Began executing node model.titanic.train
[0m02:17:43.282860 [debug] [Thread-1 (]: Began executing node model.titanic.sklearn_model
[0m02:17:43.297818 [debug] [Thread-1 (]: Writing runtime python for node "model.titanic.sklearn_model"
[0m02:17:43.299354 [debug] [Thread-2 (]: Writing runtime python for node "model.titanic.train"
[0m02:17:43.300728 [debug] [Thread-2 (]: Using snowflake connection "model.titanic.train"
[0m02:17:43.301113 [debug] [Thread-2 (]: On model.titanic.train: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "model.titanic.train"} */
WITH train__dbt_sp AS PROCEDURE ()

RETURNS STRING
LANGUAGE PYTHON
RUNTIME_VERSION = '3.11'
PACKAGES = ('snowflake-ml-python', 'pandas', 'scikit-learn', 'snowflake-snowpark-python')



HANDLER = 'main'
EXECUTE AS CALLER
AS
$$

import sys
sys._xoptions['snowflake_partner_attribution'].append("dbtLabs_dbtPython")


        


import importlib.util
if importlib.util.find_spec("snowflake.ml") is None:
    raise ImportError("snowflake.ml is not found. Add snowflake-ml-python to package dependencies.")
from snowflake.ml.registry import Registry
import datetime
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.svm import SVC
from snowflake.ml.model import model_signature


def preprocess(df: pd.DataFrame) -> pd.DataFrame:
  df = df[["employee_id","age","monthly_expenses"]]
  return pd.get_dummies(df, columns=["employee_id", "age", "monthly_expenses"])


def model(dbt, session):
  dbt.config(
    materialized="model",
    python_version="3.11",
    packages=["snowflake-ml-python", "pandas", "scikit-learn"],
    schema="models",
  )

  dataset = dbt.ref("train_data")

  data = dataset.to_pandas()

  x = preprocess(data)
  y = data["attrition"]

  imputer = SimpleImputer()
  x = imputer.fit_transform(x)

  model = SVC()
  model.fit(x, y)

  return {
    "model": model,
    "signatures": {"predict": model_signature.infer_signature(x, y)},
    "version_name": datetime.datetime.today().strftime("V%Y%m%d"),
    "metrics": {"r2_score": model.score(x, y)},
    "comment": f"r2_score: {model.score(x, y)}",
    "set_default": True,
  }


# This part is user provided model code
# you will need to copy the next section to run the code
# COMMAND ----------
# this part is dbt logic for get ref work, do not modify

def ref(*args, **kwargs):
    refs = {"train_data": "analytics.aaa_titanic_miguel.train_data"}
    key = '.'.join(args)
    version = kwargs.get("v") or kwargs.get("version")
    if version:
        key += f".v{version}"
    dbt_load_df_function = kwargs.get("dbt_load_df_function")
    return dbt_load_df_function(refs[key])


def source(*args, dbt_load_df_function):
    sources = {}
    key = '.'.join(args)
    return dbt_load_df_function(sources[key])


config_dict = {}


class config:
    def __init__(self, *args, **kwargs):
        pass

    @staticmethod
    def get(key, default=None):
        return config_dict.get(key, default)

class this:
    """dbt.this() or dbt.this.identifier"""
    database = "analytics"
    schema = "aaa_titanic_miguel_models"
    identifier = "train"
    
    def __repr__(self):
        return 'analytics.aaa_titanic_miguel_models.train'


class dbtObj:
    def __init__(self, load_df_function) -> None:
        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)
        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)
        self.config = config
        self.this = this()
        self.is_incremental = False

# COMMAND ----------



def main(session):
    dbt = dbtObj(session.table)
    model_dict = model(dbt, session)
    reg = Registry(
        session = session,
        database_name = dbt.this.database,
        schema_name = dbt.this.schema
    )
    set_default = model_dict.pop("set_default", False)
    assert "model_name" not in model_dict, "model_name cannot be overridden"
    assert "conda_dependencies" not in model_dict, "conda_dependencies cannot be overridden"
    mv = reg.log_model(
        **model_dict,
        model_name = "analytics.aaa_titanic_miguel_models.train",
        conda_dependencies = ['snowflake-ml-python', 'pandas', 'scikit-learn'],
    )
    if set_default:
        reg.get_model(dbt.this.identifier).default = mv
    return "OK"

$$
CALL train__dbt_sp();
[0m02:17:43.302329 [debug] [Thread-1 (]: Using snowflake connection "model.titanic.sklearn_model"
[0m02:17:43.302770 [debug] [Thread-1 (]: On model.titanic.sklearn_model: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "model.titanic.sklearn_model"} */
WITH sklearn_model__dbt_sp AS PROCEDURE ()

RETURNS STRING
LANGUAGE PYTHON
RUNTIME_VERSION = '3.11'
PACKAGES = ('snowflake-ml-python', 'pandas', 'scikit-learn', 'snowflake-snowpark-python')



HANDLER = 'main'
EXECUTE AS CALLER
AS
$$

import sys
sys._xoptions['snowflake_partner_attribution'].append("dbtLabs_dbtPython")


        


import importlib.util
if importlib.util.find_spec("snowflake.ml") is None:
    raise ImportError("snowflake.ml is not found. Add snowflake-ml-python to package dependencies.")
from snowflake.ml.registry import Registry
import datetime
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.svm import SVC
from snowflake.ml.model import model_signature


def preprocess(df: pd.DataFrame) -> pd.DataFrame:
  df = df[["PCLASS", "SEX", "AGE", "SIBSP", "PARCH", "FARE", "EMBARKED"]]
  df["PCLASS"] = pd.Categorical(df["PCLASS"], categories=[1, 2, 3])
  df["SEX"] = pd.Categorical(df["SEX"], categories=["male", "female"])
  df["EMBARKED"] = pd.Categorical(df["EMBARKED"], categories=["C", "Q", "S"])
  return pd.get_dummies(df, columns=["PCLASS", "SEX", "EMBARKED"])


def model(dbt, session):
  dbt.config(
    materialized="model",
    python_version="3.11",
    packages=["snowflake-ml-python", "pandas", "scikit-learn"],
  )

  dataset = dbt.ref("titanic3")

  data = dataset.to_pandas()

  x = preprocess(data)
  y = data["SURVIVED"]

  imputer = SimpleImputer()
  x = imputer.fit_transform(x)

  model = SVC()
  model.fit(x, y)

  return {
    "model": model,
    "signatures": {"predict": model_signature.infer_signature(x, y)},
    "version_name": datetime.datetime.today().strftime("V%Y%m%d"),
    "metrics": {"r2_score": model.score(x, y)},
    "comment": f"r2_score: {model.score(x, y)}",
    "set_default": True,
  }


# This part is user provided model code
# you will need to copy the next section to run the code
# COMMAND ----------
# this part is dbt logic for get ref work, do not modify

def ref(*args, **kwargs):
    refs = {"titanic3": "analytics.aaa_titanic_miguel.titanic3"}
    key = '.'.join(args)
    version = kwargs.get("v") or kwargs.get("version")
    if version:
        key += f".v{version}"
    dbt_load_df_function = kwargs.get("dbt_load_df_function")
    return dbt_load_df_function(refs[key])


def source(*args, dbt_load_df_function):
    sources = {}
    key = '.'.join(args)
    return dbt_load_df_function(sources[key])


config_dict = {}


class config:
    def __init__(self, *args, **kwargs):
        pass

    @staticmethod
    def get(key, default=None):
        return config_dict.get(key, default)

class this:
    """dbt.this() or dbt.this.identifier"""
    database = "analytics"
    schema = "aaa_titanic_miguel"
    identifier = "sklearn_model"
    
    def __repr__(self):
        return 'analytics.aaa_titanic_miguel.sklearn_model'


class dbtObj:
    def __init__(self, load_df_function) -> None:
        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)
        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)
        self.config = config
        self.this = this()
        self.is_incremental = False

# COMMAND ----------



def main(session):
    dbt = dbtObj(session.table)
    model_dict = model(dbt, session)
    reg = Registry(
        session = session,
        database_name = dbt.this.database,
        schema_name = dbt.this.schema
    )
    set_default = model_dict.pop("set_default", False)
    assert "model_name" not in model_dict, "model_name cannot be overridden"
    assert "conda_dependencies" not in model_dict, "conda_dependencies cannot be overridden"
    mv = reg.log_model(
        **model_dict,
        model_name = "analytics.aaa_titanic_miguel.sklearn_model",
        conda_dependencies = ['snowflake-ml-python', 'pandas', 'scikit-learn'],
    )
    if set_default:
        reg.get_model(dbt.this.identifier).default = mv
    return "OK"

$$
CALL sklearn_model__dbt_sp();
[0m02:18:46.131876 [debug] [Thread-2 (]: Snowflake adapter: Snowflake query id: None
[0m02:18:46.132638 [debug] [Thread-2 (]: Snowflake adapter: Snowflake error: 100357 (P0000): Python Interpreter Error:
Traceback (most recent call last):
  File "_udf_code.py", line 113, in main
    model_dict = model(dbt, session)
                 ^^^^^^^^^^^^^^^^^^^
  File "_udf_code.py", line 38, in model
    x = preprocess(data)
        ^^^^^^^^^^^^^^^^
  File "_udf_code.py", line 22, in preprocess
    df = df[["employee_id","age","monthly_expenses"]]
         ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/frame.py", line 4108, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6200, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6249, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['employee_id', 'age', 'monthly_expenses'], dtype='object')] are in the [columns]"
 in function TRAIN__DBT_SP with handler main
[0m02:18:46.134825 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: None
[0m02:18:46.135246 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 100357 (P0000): Python Interpreter Error:
Traceback (most recent call last):
  File "_udf_code.py", line 115, in main
    model_dict = model(dbt, session)
                 ^^^^^^^^^^^^^^^^^^^
  File "_udf_code.py", line 38, in model
    data = dataset.to_pandas()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/telemetry.py", line 179, in wrap
    result = func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/utils.py", line 1047, in call_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/dataframe.py", line 1011, in to_pandas
    result = self._session._conn.execute(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py", line 624, in execute
    result_set, result_meta = self.get_result_set(
                              ^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py", line 205, in wrap
    raise ne.with_traceback(tb) from None
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py", line 136, in wrap
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py", line 746, in get_result_set
    result = self.run_query(
             ^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py", line 133, in wrap
    raise ex
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py", line 127, in wrap
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py", line 520, in run_query
    raise ex
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py", line 505, in run_query
    results_cursor = self.execute_and_notify_query_listener(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py", line 446, in execute_and_notify_query_listener
    raise ex
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py", line 437, in execute_and_notify_query_listener
    results_cursor = self._cursor.execute(query, **kwargs)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/connector/cursor.py", line 1098, in execute
    Error.errorhandler_wrapper(
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/connector/errors.py", line 232, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/connector/errors.py", line 287, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/connector/errors.py", line 165, in default_errorhandler
    raise error_class(
snowflake.snowpark.exceptions.SnowparkSQLException: (1304): 01baeb6a-0907-ba98-0007-978308d0a9b2: 002003 (42S02): SQL compilation error:
Object 'ANALYTICS.AAA_TITANIC_MIGUEL.TITANIC3' does not exist or not authorized.
 in function SKLEARN_MODEL__DBT_SP with handler main
[0m02:18:46.139192 [debug] [Thread-2 (]: Database Error in model train (models/train.py)
  100357 (P0000): Python Interpreter Error:
  Traceback (most recent call last):
    File "_udf_code.py", line 113, in main
      model_dict = model(dbt, session)
                   ^^^^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 38, in model
      x = preprocess(data)
          ^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 22, in preprocess
      df = df[["employee_id","age","monthly_expenses"]]
           ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/frame.py", line 4108, in __getitem__
      indexer = self.columns._get_indexer_strict(key, "columns")[1]
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6200, in _get_indexer_strict
      self._raise_if_missing(keyarr, indexer, axis_name)
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6249, in _raise_if_missing
      raise KeyError(f"None of [{key}] are in the [{axis_name}]")
  KeyError: "None of [Index(['employee_id', 'age', 'monthly_expenses'], dtype='object')] are in the [columns]"
   in function TRAIN__DBT_SP with handler main
  compiled code at target/run/titanic/models/train.py
[0m02:18:46.141633 [debug] [Thread-1 (]: Database Error in model sklearn_model (models/sklearn_model.py)
  100357 (P0000): Python Interpreter Error:
  Traceback (most recent call last):
    File "_udf_code.py", line 115, in main
      model_dict = model(dbt, session)
                   ^^^^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 38, in model
      data = dataset.to_pandas()
             ^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/telemetry.py", line 179, in wrap
      result = func(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/utils.py", line 1047, in call_wrapper
      return func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/dataframe.py", line 1011, in to_pandas
      result = self._session._conn.execute(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py", line 624, in execute
      result_set, result_meta = self.get_result_set(
                                ^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py", line 205, in wrap
      raise ne.with_traceback(tb) from None
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py", line 136, in wrap
      return func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py", line 746, in get_result_set
      result = self.run_query(
               ^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py", line 133, in wrap
      raise ex
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py", line 127, in wrap
      return func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py", line 520, in run_query
      raise ex
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py", line 505, in run_query
      results_cursor = self.execute_and_notify_query_listener(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py", line 446, in execute_and_notify_query_listener
      raise ex
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py", line 437, in execute_and_notify_query_listener
      results_cursor = self._cursor.execute(query, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/connector/cursor.py", line 1098, in execute
      Error.errorhandler_wrapper(
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/connector/errors.py", line 232, in errorhandler_wrapper
      handed_over = Error.hand_to_other_handler(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/connector/errors.py", line 287, in hand_to_other_handler
      cursor.errorhandler(connection, cursor, error_class, error_value)
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/connector/errors.py", line 165, in default_errorhandler
      raise error_class(
  snowflake.snowpark.exceptions.SnowparkSQLException: (1304): 01baeb6a-0907-ba98-0007-978308d0a9b2: 002003 (42S02): SQL compilation error:
  Object 'ANALYTICS.AAA_TITANIC_MIGUEL.TITANIC3' does not exist or not authorized.
   in function SKLEARN_MODEL__DBT_SP with handler main
  compiled code at target/run/titanic/models/sklearn_model.py
[0m02:18:46.142710 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '21096619-3fa8-4445-a36e-1addbb27cb13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c44980>]}
[0m02:18:46.142933 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '21096619-3fa8-4445-a36e-1addbb27cb13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f2f08f0>]}
[0m02:18:46.143346 [error] [Thread-2 (]: 2 of 2 ERROR creating python model model aaa_titanic_miguel_models.train ....... [[31mERROR[0m in 62.88s]
[0m02:18:46.143735 [error] [Thread-1 (]: 1 of 2 ERROR creating python model model aaa_titanic_miguel.sklearn_model ...... [[31mERROR[0m in 62.89s]
[0m02:18:46.144110 [debug] [Thread-2 (]: Finished running node model.titanic.train
[0m02:18:46.144567 [debug] [Thread-1 (]: Finished running node model.titanic.sklearn_model
[0m02:18:46.144912 [debug] [Thread-13 ]: Marking all children of 'model.titanic.train' to be skipped because of status 'error'.  Reason: Database Error in model train (models/train.py)
  100357 (P0000): Python Interpreter Error:
  Traceback (most recent call last):
    File "_udf_code.py", line 113, in main
      model_dict = model(dbt, session)
                   ^^^^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 38, in model
      x = preprocess(data)
          ^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 22, in preprocess
      df = df[["employee_id","age","monthly_expenses"]]
           ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/frame.py", line 4108, in __getitem__
      indexer = self.columns._get_indexer_strict(key, "columns")[1]
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6200, in _get_indexer_strict
      self._raise_if_missing(keyarr, indexer, axis_name)
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6249, in _raise_if_missing
      raise KeyError(f"None of [{key}] are in the [{axis_name}]")
  KeyError: "None of [Index(['employee_id', 'age', 'monthly_expenses'], dtype='object')] are in the [columns]"
   in function TRAIN__DBT_SP with handler main
  compiled code at target/run/titanic/models/train.py.
[0m02:18:46.145798 [debug] [Thread-13 ]: Marking all children of 'model.titanic.sklearn_model' to be skipped because of status 'error'.  Reason: Database Error in model sklearn_model (models/sklearn_model.py)
  100357 (P0000): Python Interpreter Error:
  Traceback (most recent call last):
    File "_udf_code.py", line 115, in main
      model_dict = model(dbt, session)
                   ^^^^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 38, in model
      data = dataset.to_pandas()
             ^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/telemetry.py", line 179, in wrap
      result = func(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/utils.py", line 1047, in call_wrapper
      return func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/dataframe.py", line 1011, in to_pandas
      result = self._session._conn.execute(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py", line 624, in execute
      result_set, result_meta = self.get_result_set(
                                ^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py", line 205, in wrap
      raise ne.with_traceback(tb) from None
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py", line 136, in wrap
      return func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py", line 746, in get_result_set
      result = self.run_query(
               ^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py", line 133, in wrap
      raise ex
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py", line 127, in wrap
      return func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py", line 520, in run_query
      raise ex
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py", line 505, in run_query
      results_cursor = self.execute_and_notify_query_listener(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py", line 446, in execute_and_notify_query_listener
      raise ex
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py", line 437, in execute_and_notify_query_listener
      results_cursor = self._cursor.execute(query, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/connector/cursor.py", line 1098, in execute
      Error.errorhandler_wrapper(
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/connector/errors.py", line 232, in errorhandler_wrapper
      handed_over = Error.hand_to_other_handler(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/connector/errors.py", line 287, in hand_to_other_handler
      cursor.errorhandler(connection, cursor, error_class, error_value)
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/connector/errors.py", line 165, in default_errorhandler
      raise error_class(
  snowflake.snowpark.exceptions.SnowparkSQLException: (1304): 01baeb6a-0907-ba98-0007-978308d0a9b2: 002003 (42S02): SQL compilation error:
  Object 'ANALYTICS.AAA_TITANIC_MIGUEL.TITANIC3' does not exist or not authorized.
   in function SKLEARN_MODEL__DBT_SP with handler main
  compiled code at target/run/titanic/models/sklearn_model.py.
[0m02:18:46.146882 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:18:46.147111 [debug] [MainThread]: Connection 'model.titanic.sklearn_model' was left open.
[0m02:18:46.147294 [debug] [MainThread]: On model.titanic.sklearn_model: Close
[0m02:18:46.755825 [debug] [MainThread]: Connection 'model.titanic.train' was left open.
[0m02:18:46.756761 [debug] [MainThread]: On model.titanic.train: Close
[0m02:18:47.373564 [info ] [MainThread]: 
[0m02:18:47.374242 [info ] [MainThread]: Finished running 2 model models in 0 hours 1 minutes and 9.15 seconds (69.15s).
[0m02:18:47.375511 [debug] [MainThread]: Command end result
[0m02:18:47.471894 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m02:18:47.473690 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m02:18:47.477575 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/migueldichoso/Downloads/Titanic/target/run_results.json
[0m02:18:47.477795 [info ] [MainThread]: 
[0m02:18:47.478040 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m02:18:47.478222 [info ] [MainThread]: 
[0m02:18:47.478487 [error] [MainThread]:   Database Error in model train (models/train.py)
  100357 (P0000): Python Interpreter Error:
  Traceback (most recent call last):
    File "_udf_code.py", line 113, in main
      model_dict = model(dbt, session)
                   ^^^^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 38, in model
      x = preprocess(data)
          ^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 22, in preprocess
      df = df[["employee_id","age","monthly_expenses"]]
           ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/frame.py", line 4108, in __getitem__
      indexer = self.columns._get_indexer_strict(key, "columns")[1]
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6200, in _get_indexer_strict
      self._raise_if_missing(keyarr, indexer, axis_name)
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6249, in _raise_if_missing
      raise KeyError(f"None of [{key}] are in the [{axis_name}]")
  KeyError: "None of [Index(['employee_id', 'age', 'monthly_expenses'], dtype='object')] are in the [columns]"
   in function TRAIN__DBT_SP with handler main
  compiled code at target/run/titanic/models/train.py
[0m02:18:47.478812 [info ] [MainThread]: 
[0m02:18:47.479246 [error] [MainThread]:   Database Error in model sklearn_model (models/sklearn_model.py)
  100357 (P0000): Python Interpreter Error:
  Traceback (most recent call last):
    File "_udf_code.py", line 115, in main
      model_dict = model(dbt, session)
                   ^^^^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 38, in model
      data = dataset.to_pandas()
             ^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/telemetry.py", line 179, in wrap
      result = func(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/utils.py", line 1047, in call_wrapper
      return func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/dataframe.py", line 1011, in to_pandas
      result = self._session._conn.execute(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py", line 624, in execute
      result_set, result_meta = self.get_result_set(
                                ^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py", line 205, in wrap
      raise ne.with_traceback(tb) from None
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py", line 136, in wrap
      return func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py", line 746, in get_result_set
      result = self.run_query(
               ^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py", line 133, in wrap
      raise ex
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py", line 127, in wrap
      return func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py", line 520, in run_query
      raise ex
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py", line 505, in run_query
      results_cursor = self.execute_and_notify_query_listener(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py", line 446, in execute_and_notify_query_listener
      raise ex
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py", line 437, in execute_and_notify_query_listener
      results_cursor = self._cursor.execute(query, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/connector/cursor.py", line 1098, in execute
      Error.errorhandler_wrapper(
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/connector/errors.py", line 232, in errorhandler_wrapper
      handed_over = Error.hand_to_other_handler(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/connector/errors.py", line 287, in hand_to_other_handler
      cursor.errorhandler(connection, cursor, error_class, error_value)
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/connector/errors.py", line 165, in default_errorhandler
      raise error_class(
  snowflake.snowpark.exceptions.SnowparkSQLException: (1304): 01baeb6a-0907-ba98-0007-978308d0a9b2: 002003 (42S02): SQL compilation error:
  Object 'ANALYTICS.AAA_TITANIC_MIGUEL.TITANIC3' does not exist or not authorized.
   in function SKLEARN_MODEL__DBT_SP with handler main
  compiled code at target/run/titanic/models/sklearn_model.py
[0m02:18:47.479725 [info ] [MainThread]: 
[0m02:18:47.479920 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=2 SKIP=0 TOTAL=2
[0m02:18:47.481817 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 70.333046, "process_in_blocks": "0", "process_kernel_time": 0.387567, "process_mem_max_rss": "186761216", "process_out_blocks": "0", "process_user_time": 2.06991}
[0m02:18:47.482102 [debug] [MainThread]: Command `dbt run` failed at 02:18:47.482018 after 70.33 seconds
[0m02:18:47.482358 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10437ec30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118df8590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118df9fa0>]}
[0m02:18:47.482596 [debug] [MainThread]: Flushing usage events
[0m02:18:49.444090 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:19:00.055864 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b83e30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108bf9b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108bf9790>]}


============================== 02:19:00.060133 | 38be85b1-fb02-4407-9d59-f21840527974 ==============================
[0m02:19:00.060133 [info ] [MainThread]: Running with dbt=1.9.3
[0m02:19:00.060572 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/migueldichoso/Downloads/Titanic/logs', 'version_check': 'True', 'profiles_dir': '/Users/migueldichoso/Downloads/Titanic', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt seed', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:19:00.668908 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '38be85b1-fb02-4407-9d59-f21840527974', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098ff650>]}
[0m02:19:00.704001 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '38be85b1-fb02-4407-9d59-f21840527974', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c64ffb0>]}
[0m02:19:00.704996 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m02:19:00.814871 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m02:19:00.886228 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 0 files added, 0 files changed.
[0m02:19:00.886572 [debug] [MainThread]: Partial parsing: deleted file: titanic://models/train.py
[0m02:19:00.925131 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '38be85b1-fb02-4407-9d59-f21840527974', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cb83590>]}
[0m02:19:00.964482 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m02:19:00.966651 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m02:19:00.980066 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '38be85b1-fb02-4407-9d59-f21840527974', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c85bad0>]}
[0m02:19:00.980393 [info ] [MainThread]: Found 3 seeds, 1 model, 480 macros
[0m02:19:00.980652 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '38be85b1-fb02-4407-9d59-f21840527974', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cb7dc10>]}
[0m02:19:00.981819 [info ] [MainThread]: 
[0m02:19:00.982073 [info ] [MainThread]: Concurrency: 10 threads (target='titanic_dev')
[0m02:19:00.982257 [info ] [MainThread]: 
[0m02:19:00.982571 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m02:19:00.985372 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_analytics'
[0m02:19:01.031355 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
[0m02:19:01.031677 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics"} */
show terse schemas in database analytics
    limit 10000
[0m02:19:01.031881 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:19:04.048096 [debug] [ThreadPool]: SQL status: SUCCESS 1758 in 3.016 seconds
[0m02:19:05.431455 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_aaa_titanic_miguel)
[0m02:19:05.438230 [debug] [ThreadPool]: Using snowflake connection "list_analytics_aaa_titanic_miguel"
[0m02:19:05.438472 [debug] [ThreadPool]: On list_analytics_aaa_titanic_miguel: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics_aaa_titanic_miguel"} */
show objects in analytics.aaa_titanic_miguel limit 10000;
[0m02:19:05.814434 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 0.375 seconds
[0m02:19:05.820050 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '38be85b1-fb02-4407-9d59-f21840527974', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce60f80>]}
[0m02:19:05.825267 [debug] [Thread-1 (]: Began running node seed.titanic.predict_data
[0m02:19:05.825675 [debug] [Thread-2 (]: Began running node seed.titanic.titanic3
[0m02:19:05.825998 [debug] [Thread-3 (]: Began running node seed.titanic.train_data
[0m02:19:05.826446 [info ] [Thread-1 (]: 1 of 3 START seed file aaa_titanic_miguel.predict_data ......................... [RUN]
[0m02:19:05.826878 [info ] [Thread-2 (]: 2 of 3 START seed file aaa_titanic_miguel.titanic3 ............................. [RUN]
[0m02:19:05.827261 [info ] [Thread-3 (]: 3 of 3 START seed file aaa_titanic_miguel.train_data ........................... [RUN]
[0m02:19:05.827692 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_analytics_aaa_titanic_miguel, now seed.titanic.predict_data)
[0m02:19:05.828118 [debug] [Thread-2 (]: Acquiring new snowflake connection 'seed.titanic.titanic3'
[0m02:19:05.828456 [debug] [Thread-3 (]: Acquiring new snowflake connection 'seed.titanic.train_data'
[0m02:19:05.828731 [debug] [Thread-1 (]: Began compiling node seed.titanic.predict_data
[0m02:19:05.828979 [debug] [Thread-2 (]: Began compiling node seed.titanic.titanic3
[0m02:19:05.829211 [debug] [Thread-3 (]: Began compiling node seed.titanic.train_data
[0m02:19:05.829473 [debug] [Thread-1 (]: Began executing node seed.titanic.predict_data
[0m02:19:05.829700 [debug] [Thread-2 (]: Began executing node seed.titanic.titanic3
[0m02:19:05.829929 [debug] [Thread-3 (]: Began executing node seed.titanic.train_data
[0m02:19:05.902532 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.predict_data"
[0m02:19:05.907243 [debug] [Thread-2 (]: Using snowflake connection "seed.titanic.titanic3"
[0m02:19:05.908221 [debug] [Thread-3 (]: Using snowflake connection "seed.titanic.train_data"
[0m02:19:05.908452 [debug] [Thread-1 (]: On seed.titanic.predict_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.predict_data"} */
create table analytics.aaa_titanic_miguel.predict_data (employee_id integer,age integer,monthly_expenses float8)
[0m02:19:05.908693 [debug] [Thread-2 (]: On seed.titanic.titanic3: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.titanic3"} */
create table analytics.aaa_titanic_miguel.titanic3 (pclass integer,survived integer,name text,sex text,age float8,sibsp integer,parch integer,ticket text,fare float8,cabin text,embarked text,boat text,body integer,home_dest text)
[0m02:19:05.908911 [debug] [Thread-3 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
BEGIN
[0m02:19:05.909324 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m02:19:05.909543 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:19:06.367143 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.458 seconds
[0m02:19:06.387037 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.predict_data"
[0m02:19:06.387520 [debug] [Thread-1 (]: On seed.titanic.predict_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.predict_data"} */
BEGIN
[0m02:19:07.060947 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.673 seconds
[0m02:19:07.066981 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.predict_data"
[0m02:19:07.067489 [debug] [Thread-1 (]: On seed.titanic.predict_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.predict_data"} */
insert into analytics.aaa_titanic_miguel.predict_data (employee_id, age, monthly_expenses) values
            (%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,...
[0m02:19:07.448378 [debug] [Thread-3 (]: SQL status: SUCCESS 1 in 1.538 seconds
[0m02:19:07.449463 [debug] [Thread-3 (]: Using snowflake connection "seed.titanic.train_data"
[0m02:19:07.449907 [debug] [Thread-3 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
truncate table "ANALYTICS"."AAA_TITANIC_MIGUEL"."TRAIN_DATA"
  ;
[0m02:19:07.541444 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1.632 seconds
[0m02:19:07.573884 [debug] [Thread-2 (]: Using snowflake connection "seed.titanic.titanic3"
[0m02:19:07.574142 [debug] [Thread-2 (]: On seed.titanic.titanic3: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.titanic3"} */
BEGIN
[0m02:19:07.731026 [debug] [Thread-1 (]: SQL status: SUCCESS 200 in 0.663 seconds
[0m02:19:07.732069 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.predict_data"
[0m02:19:07.732586 [debug] [Thread-1 (]: On seed.titanic.predict_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.predict_data"} */
COMMIT
[0m02:19:07.969085 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.394 seconds
[0m02:19:08.006337 [debug] [Thread-3 (]: SQL status: SUCCESS 1 in 0.556 seconds
[0m02:19:08.012315 [debug] [Thread-3 (]: Using snowflake connection "seed.titanic.train_data"
[0m02:19:08.018882 [debug] [Thread-3 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
COMMIT
[0m02:19:08.166610 [debug] [Thread-2 (]: Using snowflake connection "seed.titanic.titanic3"
[0m02:19:08.166898 [debug] [Thread-2 (]: On seed.titanic.titanic3: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.titanic3"} */
insert into analytics.aaa_titanic_miguel.titanic3 (pclass, survived, name, sex, age, sibsp, parch, ticket, fare, cabin, embarked, boat, body, home_dest) values
            (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%...
[0m02:19:08.403671 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.670 seconds
[0m02:19:08.412553 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.titanic.predict_data"
[0m02:19:08.436059 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38be85b1-fb02-4407-9d59-f21840527974', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f2df40>]}
[0m02:19:08.436492 [info ] [Thread-1 (]: 1 of 3 OK loaded seed file aaa_titanic_miguel.predict_data ..................... [[32mINSERT 200[0m in 2.61s]
[0m02:19:08.436891 [debug] [Thread-1 (]: Finished running node seed.titanic.predict_data
[0m02:19:08.773395 [debug] [Thread-3 (]: SQL status: SUCCESS 1 in 0.748 seconds
[0m02:19:08.784823 [debug] [Thread-3 (]: Using snowflake connection "seed.titanic.train_data"
[0m02:19:08.785466 [debug] [Thread-3 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
BEGIN
[0m02:19:09.336583 [debug] [Thread-3 (]: SQL status: SUCCESS 1 in 0.550 seconds
[0m02:19:09.348531 [debug] [Thread-3 (]: Using snowflake connection "seed.titanic.train_data"
[0m02:19:09.349170 [debug] [Thread-3 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
insert into analytics.aaa_titanic_miguel.train_data (employee_id, age, monthly_expenses, attrition) values
            (%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(...
[0m02:19:09.687879 [debug] [Thread-2 (]: SQL status: SUCCESS 1309 in 1.521 seconds
[0m02:19:09.688705 [debug] [Thread-2 (]: Using snowflake connection "seed.titanic.titanic3"
[0m02:19:09.689004 [debug] [Thread-2 (]: On seed.titanic.titanic3: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.titanic3"} */
COMMIT
[0m02:19:10.079243 [debug] [Thread-3 (]: SQL status: SUCCESS 405 in 0.729 seconds
[0m02:19:10.080491 [debug] [Thread-3 (]: Using snowflake connection "seed.titanic.train_data"
[0m02:19:10.080959 [debug] [Thread-3 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
COMMIT
[0m02:19:10.375471 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.686 seconds
[0m02:19:10.377550 [debug] [Thread-2 (]: Writing runtime SQL for node "seed.titanic.titanic3"
[0m02:19:10.382435 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38be85b1-fb02-4407-9d59-f21840527974', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d1d77a0>]}
[0m02:19:10.383226 [info ] [Thread-2 (]: 2 of 3 OK loaded seed file aaa_titanic_miguel.titanic3 ......................... [[32mINSERT 1309[0m in 4.55s]
[0m02:19:10.384349 [debug] [Thread-2 (]: Finished running node seed.titanic.titanic3
[0m02:19:10.720206 [debug] [Thread-3 (]: SQL status: SUCCESS 1 in 0.638 seconds
[0m02:19:10.722214 [debug] [Thread-3 (]: Writing runtime SQL for node "seed.titanic.train_data"
[0m02:19:10.727181 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38be85b1-fb02-4407-9d59-f21840527974', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fb7b30>]}
[0m02:19:10.727985 [info ] [Thread-3 (]: 3 of 3 OK loaded seed file aaa_titanic_miguel.train_data ....................... [[32mINSERT 405[0m in 4.90s]
[0m02:19:10.728676 [debug] [Thread-3 (]: Finished running node seed.titanic.train_data
[0m02:19:10.730334 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:19:10.730633 [debug] [MainThread]: Connection 'seed.titanic.predict_data' was left open.
[0m02:19:10.730925 [debug] [MainThread]: On seed.titanic.predict_data: Close
[0m02:19:11.351831 [debug] [MainThread]: Connection 'seed.titanic.titanic3' was left open.
[0m02:19:11.352626 [debug] [MainThread]: On seed.titanic.titanic3: Close
[0m02:19:11.948857 [debug] [MainThread]: Connection 'seed.titanic.train_data' was left open.
[0m02:19:11.949763 [debug] [MainThread]: On seed.titanic.train_data: Close
[0m02:19:12.556654 [info ] [MainThread]: 
[0m02:19:12.558023 [info ] [MainThread]: Finished running 3 seeds in 0 hours 0 minutes and 11.57 seconds (11.57s).
[0m02:19:12.559443 [debug] [MainThread]: Command end result
[0m02:19:12.581106 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m02:19:12.582603 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m02:19:12.586974 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/migueldichoso/Downloads/Titanic/target/run_results.json
[0m02:19:12.587209 [info ] [MainThread]: 
[0m02:19:12.587522 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:19:12.587829 [info ] [MainThread]: 
[0m02:19:12.588078 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m02:19:12.590076 [debug] [MainThread]: Resource report: {"command_name": "seed", "command_success": true, "command_wall_clock_time": 12.609321, "process_in_blocks": "0", "process_kernel_time": 0.415298, "process_mem_max_rss": "184188928", "process_out_blocks": "0", "process_user_time": 2.30353}
[0m02:19:12.590383 [debug] [MainThread]: Command `dbt seed` succeeded at 02:19:12.590323 after 12.61 seconds
[0m02:19:12.590647 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108bf9760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108bf9b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108bf9790>]}
[0m02:19:12.590889 [debug] [MainThread]: Flushing usage events
[0m02:19:13.452987 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:19:16.509560 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047e5b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110285c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110285790>]}


============================== 02:19:16.512945 | 8eff8a13-7448-4c60-9142-3f4345e2a18c ==============================
[0m02:19:16.512945 [info ] [MainThread]: Running with dbt=1.9.3
[0m02:19:16.513388 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/migueldichoso/Downloads/Titanic/logs', 'version_check': 'True', 'profiles_dir': '/Users/migueldichoso/Downloads/Titanic', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m02:19:16.954981 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8eff8a13-7448-4c60-9142-3f4345e2a18c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115328f20>]}
[0m02:19:16.989029 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8eff8a13-7448-4c60-9142-3f4345e2a18c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121544a0>]}
[0m02:19:16.989614 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m02:19:17.096362 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m02:19:17.159635 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m02:19:17.159898 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m02:19:17.181509 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8eff8a13-7448-4c60-9142-3f4345e2a18c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115735ee0>]}
[0m02:19:17.221039 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m02:19:17.223104 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m02:19:17.231925 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8eff8a13-7448-4c60-9142-3f4345e2a18c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116250920>]}
[0m02:19:17.232236 [info ] [MainThread]: Found 3 seeds, 1 model, 480 macros
[0m02:19:17.232460 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8eff8a13-7448-4c60-9142-3f4345e2a18c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116247b30>]}
[0m02:19:17.233493 [info ] [MainThread]: 
[0m02:19:17.233716 [info ] [MainThread]: Concurrency: 10 threads (target='titanic_dev')
[0m02:19:17.233877 [info ] [MainThread]: 
[0m02:19:17.234178 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m02:19:17.234738 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_analytics'
[0m02:19:17.271611 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
[0m02:19:17.271921 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics"} */
show terse schemas in database analytics
    limit 10000
[0m02:19:17.272127 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:19:19.311472 [debug] [ThreadPool]: SQL status: SUCCESS 1758 in 2.039 seconds
[0m02:19:20.270032 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_aaa_titanic_miguel)
[0m02:19:20.276733 [debug] [ThreadPool]: Using snowflake connection "list_analytics_aaa_titanic_miguel"
[0m02:19:20.276973 [debug] [ThreadPool]: On list_analytics_aaa_titanic_miguel: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics_aaa_titanic_miguel"} */
show objects in analytics.aaa_titanic_miguel limit 10000;
[0m02:19:20.626992 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.349 seconds
[0m02:19:20.632315 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8eff8a13-7448-4c60-9142-3f4345e2a18c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112154560>]}
[0m02:19:20.635663 [debug] [Thread-1 (]: Began running node model.titanic.sklearn_model
[0m02:19:20.636211 [info ] [Thread-1 (]: 1 of 1 START python model model aaa_titanic_miguel.sklearn_model ............... [RUN]
[0m02:19:20.636673 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_analytics_aaa_titanic_miguel, now model.titanic.sklearn_model)
[0m02:19:20.637033 [debug] [Thread-1 (]: Began compiling node model.titanic.sklearn_model
[0m02:19:20.660587 [debug] [Thread-1 (]: Writing injected SQL for node "model.titanic.sklearn_model"
[0m02:19:20.661332 [debug] [Thread-1 (]: Began executing node model.titanic.sklearn_model
[0m02:19:20.674997 [debug] [Thread-1 (]: Writing runtime python for node "model.titanic.sklearn_model"
[0m02:19:20.676418 [debug] [Thread-1 (]: Using snowflake connection "model.titanic.sklearn_model"
[0m02:19:20.676803 [debug] [Thread-1 (]: On model.titanic.sklearn_model: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "model.titanic.sklearn_model"} */
WITH sklearn_model__dbt_sp AS PROCEDURE ()

RETURNS STRING
LANGUAGE PYTHON
RUNTIME_VERSION = '3.11'
PACKAGES = ('snowflake-ml-python', 'pandas', 'scikit-learn', 'snowflake-snowpark-python')



HANDLER = 'main'
EXECUTE AS CALLER
AS
$$

import sys
sys._xoptions['snowflake_partner_attribution'].append("dbtLabs_dbtPython")


        


import importlib.util
if importlib.util.find_spec("snowflake.ml") is None:
    raise ImportError("snowflake.ml is not found. Add snowflake-ml-python to package dependencies.")
from snowflake.ml.registry import Registry
import datetime
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.svm import SVC
from snowflake.ml.model import model_signature


def preprocess(df: pd.DataFrame) -> pd.DataFrame:
  df = df[["PCLASS", "SEX", "AGE", "SIBSP", "PARCH", "FARE", "EMBARKED"]]
  df["PCLASS"] = pd.Categorical(df["PCLASS"], categories=[1, 2, 3])
  df["SEX"] = pd.Categorical(df["SEX"], categories=["male", "female"])
  df["EMBARKED"] = pd.Categorical(df["EMBARKED"], categories=["C", "Q", "S"])
  return pd.get_dummies(df, columns=["PCLASS", "SEX", "EMBARKED"])


def model(dbt, session):
  dbt.config(
    materialized="model",
    python_version="3.11",
    packages=["snowflake-ml-python", "pandas", "scikit-learn"],
  )

  dataset = dbt.ref("titanic3")

  data = dataset.to_pandas()

  x = preprocess(data)
  y = data["SURVIVED"]

  imputer = SimpleImputer()
  x = imputer.fit_transform(x)

  model = SVC()
  model.fit(x, y)

  return {
    "model": model,
    "signatures": {"predict": model_signature.infer_signature(x, y)},
    "version_name": datetime.datetime.today().strftime("V%Y%m%d"),
    "metrics": {"r2_score": model.score(x, y)},
    "comment": f"r2_score: {model.score(x, y)}",
    "set_default": True,
  }


# This part is user provided model code
# you will need to copy the next section to run the code
# COMMAND ----------
# this part is dbt logic for get ref work, do not modify

def ref(*args, **kwargs):
    refs = {"titanic3": "analytics.aaa_titanic_miguel.titanic3"}
    key = '.'.join(args)
    version = kwargs.get("v") or kwargs.get("version")
    if version:
        key += f".v{version}"
    dbt_load_df_function = kwargs.get("dbt_load_df_function")
    return dbt_load_df_function(refs[key])


def source(*args, dbt_load_df_function):
    sources = {}
    key = '.'.join(args)
    return dbt_load_df_function(sources[key])


config_dict = {}


class config:
    def __init__(self, *args, **kwargs):
        pass

    @staticmethod
    def get(key, default=None):
        return config_dict.get(key, default)

class this:
    """dbt.this() or dbt.this.identifier"""
    database = "analytics"
    schema = "aaa_titanic_miguel"
    identifier = "sklearn_model"
    
    def __repr__(self):
        return 'analytics.aaa_titanic_miguel.sklearn_model'


class dbtObj:
    def __init__(self, load_df_function) -> None:
        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)
        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)
        self.config = config
        self.this = this()
        self.is_incremental = False

# COMMAND ----------



def main(session):
    dbt = dbtObj(session.table)
    model_dict = model(dbt, session)
    reg = Registry(
        session = session,
        database_name = dbt.this.database,
        schema_name = dbt.this.schema
    )
    set_default = model_dict.pop("set_default", False)
    assert "model_name" not in model_dict, "model_name cannot be overridden"
    assert "conda_dependencies" not in model_dict, "conda_dependencies cannot be overridden"
    mv = reg.log_model(
        **model_dict,
        model_name = "analytics.aaa_titanic_miguel.sklearn_model",
        conda_dependencies = ['snowflake-ml-python', 'pandas', 'scikit-learn'],
    )
    if set_default:
        reg.get_model(dbt.this.identifier).default = mv
    return "OK"

$$
CALL sklearn_model__dbt_sp();
[0m02:21:24.913236 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 124.237 seconds
[0m02:21:24.939908 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8eff8a13-7448-4c60-9142-3f4345e2a18c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a44980>]}
[0m02:21:24.940638 [info ] [Thread-1 (]: 1 of 1 OK created python model model aaa_titanic_miguel.sklearn_model .......... [[32mSUCCESS 1[0m in 124.30s]
[0m02:21:24.941113 [debug] [Thread-1 (]: Finished running node model.titanic.sklearn_model
[0m02:21:24.942445 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:21:24.942739 [debug] [MainThread]: Connection 'model.titanic.sklearn_model' was left open.
[0m02:21:24.942972 [debug] [MainThread]: On model.titanic.sklearn_model: Close
[0m02:21:25.582596 [info ] [MainThread]: 
[0m02:21:25.583218 [info ] [MainThread]: Finished running 1 model model in 0 hours 2 minutes and 8.35 seconds (128.35s).
[0m02:21:25.583867 [debug] [MainThread]: Command end result
[0m02:21:25.602528 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m02:21:25.604379 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m02:21:25.609066 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/migueldichoso/Downloads/Titanic/target/run_results.json
[0m02:21:25.609323 [info ] [MainThread]: 
[0m02:21:25.609614 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:21:25.609830 [info ] [MainThread]: 
[0m02:21:25.610036 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m02:21:25.611852 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 129.17775, "process_in_blocks": "0", "process_kernel_time": 0.33159, "process_mem_max_rss": "181649408", "process_out_blocks": "0", "process_user_time": 1.708776}
[0m02:21:25.612140 [debug] [MainThread]: Command `dbt run` succeeded at 02:21:25.612082 after 129.18 seconds
[0m02:21:25.612398 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e66b70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110213890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115489100>]}
[0m02:21:25.612635 [debug] [MainThread]: Flushing usage events
[0m02:21:27.453674 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:29:26.410419 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112813e30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112885ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1128857f0>]}


============================== 02:29:26.414381 | 8ea69ef7-6d52-407e-bc4d-6b37dc86d52c ==============================
[0m02:29:26.414381 [info ] [MainThread]: Running with dbt=1.9.3
[0m02:29:26.414841 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/migueldichoso/Downloads/Titanic', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/migueldichoso/Downloads/Titanic/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run -s train', 'send_anonymous_usage_stats': 'True'}
[0m02:29:27.044481 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8ea69ef7-6d52-407e-bc4d-6b37dc86d52c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11709dca0>]}
[0m02:29:27.079552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8ea69ef7-6d52-407e-bc4d-6b37dc86d52c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1106ce5a0>]}
[0m02:29:27.080392 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m02:29:27.184587 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m02:29:27.262542 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m02:29:27.262958 [debug] [MainThread]: Partial parsing: added file: titanic://models/train.py
[0m02:29:27.410589 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8ea69ef7-6d52-407e-bc4d-6b37dc86d52c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120a5f2c0>]}
[0m02:29:27.449766 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m02:29:27.452083 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m02:29:27.466317 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8ea69ef7-6d52-407e-bc4d-6b37dc86d52c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120abbbf0>]}
[0m02:29:27.466670 [info ] [MainThread]: Found 3 seeds, 2 models, 480 macros
[0m02:29:27.466957 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8ea69ef7-6d52-407e-bc4d-6b37dc86d52c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117335c70>]}
[0m02:29:27.468026 [info ] [MainThread]: 
[0m02:29:27.468274 [info ] [MainThread]: Concurrency: 10 threads (target='titanic_dev')
[0m02:29:27.468453 [info ] [MainThread]: 
[0m02:29:27.468795 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m02:29:27.469355 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_analytics'
[0m02:29:27.513983 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
[0m02:29:27.514296 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics"} */
show terse schemas in database analytics
    limit 10000
[0m02:29:27.514496 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:29:30.667208 [debug] [ThreadPool]: SQL status: SUCCESS 1758 in 3.153 seconds
[0m02:29:32.544627 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_aaa_titanic_miguel)
[0m02:29:32.551346 [debug] [ThreadPool]: Using snowflake connection "list_analytics_aaa_titanic_miguel"
[0m02:29:32.551589 [debug] [ThreadPool]: On list_analytics_aaa_titanic_miguel: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics_aaa_titanic_miguel"} */
show objects in analytics.aaa_titanic_miguel limit 10000;
[0m02:29:32.937639 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.386 seconds
[0m02:29:32.939911 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8ea69ef7-6d52-407e-bc4d-6b37dc86d52c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120de3e60>]}
[0m02:29:32.942719 [debug] [Thread-1 (]: Began running node model.titanic.train
[0m02:29:32.943084 [info ] [Thread-1 (]: 1 of 1 START python model model aaa_titanic_miguel.train ....................... [RUN]
[0m02:29:32.943366 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_analytics_aaa_titanic_miguel, now model.titanic.train)
[0m02:29:32.943572 [debug] [Thread-1 (]: Began compiling node model.titanic.train
[0m02:29:32.961420 [debug] [Thread-1 (]: Writing injected SQL for node "model.titanic.train"
[0m02:29:32.962780 [debug] [Thread-1 (]: Began executing node model.titanic.train
[0m02:29:32.976747 [debug] [Thread-1 (]: Writing runtime python for node "model.titanic.train"
[0m02:29:32.978205 [debug] [Thread-1 (]: Using snowflake connection "model.titanic.train"
[0m02:29:32.978576 [debug] [Thread-1 (]: On model.titanic.train: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "model.titanic.train"} */
WITH train__dbt_sp AS PROCEDURE ()

RETURNS STRING
LANGUAGE PYTHON
RUNTIME_VERSION = '3.11'
PACKAGES = ('snowflake-ml-python', 'pandas', 'scikit-learn', 'snowflake-snowpark-python')



HANDLER = 'main'
EXECUTE AS CALLER
AS
$$

import sys
sys._xoptions['snowflake_partner_attribution'].append("dbtLabs_dbtPython")


        


import importlib.util
if importlib.util.find_spec("snowflake.ml") is None:
    raise ImportError("snowflake.ml is not found. Add snowflake-ml-python to package dependencies.")
from snowflake.ml.registry import Registry
import datetime
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.svm import SVC
from snowflake.ml.model import model_signature


def preprocess(df: pd.DataFrame) -> pd.DataFrame:
  df = df[["employee_id", "age", "AGE", "SIBSP", "PARCH", "FARE", "EMBARKED"]]
  df["employee_id"] = pd.Categorical(df["employee_id"])
  df["age"] = pd.Categorical(df["age"])
  df["monthly_expenses"] = pd.Categorical(df["monthly_expenses"])
  return pd.get_dummies(df, columns=["employee_id", "age", "monthly_expenses"])


def model(dbt, session):
  dbt.config(
    materialized="model",
    python_version="3.11",
    packages=["snowflake-ml-python", "pandas", "scikit-learn"],
  )

  dataset = dbt.ref("train_data")

  data = dataset.to_pandas()

  x = preprocess(data)
  y = data["attrition"]

  imputer = SimpleImputer()
  x = imputer.fit_transform(x)

  model = SVC()
  model.fit(x, y)

  return {
    "model": model,
    "signatures": {"predict": model_signature.infer_signature(x, y)},
    "version_name": datetime.datetime.today().strftime("V%Y%m%d"),
    "metrics": {"r2_score": model.score(x, y)},
    "comment": f"r2_score: {model.score(x, y)}",
    "set_default": True,
  }


# This part is user provided model code
# you will need to copy the next section to run the code
# COMMAND ----------
# this part is dbt logic for get ref work, do not modify

def ref(*args, **kwargs):
    refs = {"train_data": "analytics.aaa_titanic_miguel.train_data"}
    key = '.'.join(args)
    version = kwargs.get("v") or kwargs.get("version")
    if version:
        key += f".v{version}"
    dbt_load_df_function = kwargs.get("dbt_load_df_function")
    return dbt_load_df_function(refs[key])


def source(*args, dbt_load_df_function):
    sources = {}
    key = '.'.join(args)
    return dbt_load_df_function(sources[key])


config_dict = {}


class config:
    def __init__(self, *args, **kwargs):
        pass

    @staticmethod
    def get(key, default=None):
        return config_dict.get(key, default)

class this:
    """dbt.this() or dbt.this.identifier"""
    database = "analytics"
    schema = "aaa_titanic_miguel"
    identifier = "train"
    
    def __repr__(self):
        return 'analytics.aaa_titanic_miguel.train'


class dbtObj:
    def __init__(self, load_df_function) -> None:
        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)
        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)
        self.config = config
        self.this = this()
        self.is_incremental = False

# COMMAND ----------



def main(session):
    dbt = dbtObj(session.table)
    model_dict = model(dbt, session)
    reg = Registry(
        session = session,
        database_name = dbt.this.database,
        schema_name = dbt.this.schema
    )
    set_default = model_dict.pop("set_default", False)
    assert "model_name" not in model_dict, "model_name cannot be overridden"
    assert "conda_dependencies" not in model_dict, "conda_dependencies cannot be overridden"
    mv = reg.log_model(
        **model_dict,
        model_name = "analytics.aaa_titanic_miguel.train",
        conda_dependencies = ['snowflake-ml-python', 'pandas', 'scikit-learn'],
    )
    if set_default:
        reg.get_model(dbt.this.identifier).default = mv
    return "OK"

$$
CALL train__dbt_sp();
[0m02:29:41.667449 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01baeb75-0907-baa2-0007-978308d09fa2
[0m02:29:41.668152 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 100357 (P0000): Python Interpreter Error:
Traceback (most recent call last):
  File "_udf_code.py", line 115, in main
    model_dict = model(dbt, session)
                 ^^^^^^^^^^^^^^^^^^^
  File "_udf_code.py", line 40, in model
    x = preprocess(data)
        ^^^^^^^^^^^^^^^^
  File "_udf_code.py", line 22, in preprocess
    df = df[["employee_id", "age", "AGE", "SIBSP", "PARCH", "FARE", "EMBARKED"]]
         ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/frame.py", line 4108, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6200, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6252, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['employee_id', 'age', 'SIBSP', 'PARCH', 'FARE', 'EMBARKED'] not in index"
 in function TRAIN__DBT_SP with handler main
[0m02:29:41.672848 [debug] [Thread-1 (]: Database Error in model train (models/train.py)
  100357 (P0000): Python Interpreter Error:
  Traceback (most recent call last):
    File "_udf_code.py", line 115, in main
      model_dict = model(dbt, session)
                   ^^^^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 40, in model
      x = preprocess(data)
          ^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 22, in preprocess
      df = df[["employee_id", "age", "AGE", "SIBSP", "PARCH", "FARE", "EMBARKED"]]
           ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/frame.py", line 4108, in __getitem__
      indexer = self.columns._get_indexer_strict(key, "columns")[1]
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6200, in _get_indexer_strict
      self._raise_if_missing(keyarr, indexer, axis_name)
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6252, in _raise_if_missing
      raise KeyError(f"{not_found} not in index")
  KeyError: "['employee_id', 'age', 'SIBSP', 'PARCH', 'FARE', 'EMBARKED'] not in index"
   in function TRAIN__DBT_SP with handler main
  compiled code at target/run/titanic/models/train.py
[0m02:29:41.674805 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8ea69ef7-6d52-407e-bc4d-6b37dc86d52c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122d21250>]}
[0m02:29:41.675456 [error] [Thread-1 (]: 1 of 1 ERROR creating python model model aaa_titanic_miguel.train .............. [[31mERROR[0m in 8.73s]
[0m02:29:41.676034 [debug] [Thread-1 (]: Finished running node model.titanic.train
[0m02:29:41.676556 [debug] [Thread-13 ]: Marking all children of 'model.titanic.train' to be skipped because of status 'error'.  Reason: Database Error in model train (models/train.py)
  100357 (P0000): Python Interpreter Error:
  Traceback (most recent call last):
    File "_udf_code.py", line 115, in main
      model_dict = model(dbt, session)
                   ^^^^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 40, in model
      x = preprocess(data)
          ^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 22, in preprocess
      df = df[["employee_id", "age", "AGE", "SIBSP", "PARCH", "FARE", "EMBARKED"]]
           ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/frame.py", line 4108, in __getitem__
      indexer = self.columns._get_indexer_strict(key, "columns")[1]
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6200, in _get_indexer_strict
      self._raise_if_missing(keyarr, indexer, axis_name)
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6252, in _raise_if_missing
      raise KeyError(f"{not_found} not in index")
  KeyError: "['employee_id', 'age', 'SIBSP', 'PARCH', 'FARE', 'EMBARKED'] not in index"
   in function TRAIN__DBT_SP with handler main
  compiled code at target/run/titanic/models/train.py.
[0m02:29:41.678537 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:29:41.678799 [debug] [MainThread]: Connection 'model.titanic.train' was left open.
[0m02:29:41.679029 [debug] [MainThread]: On model.titanic.train: Close
[0m02:29:42.344778 [info ] [MainThread]: 
[0m02:29:42.345544 [info ] [MainThread]: Finished running 1 model model in 0 hours 0 minutes and 14.88 seconds (14.88s).
[0m02:29:42.346425 [debug] [MainThread]: Command end result
[0m02:29:42.367556 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m02:29:42.369007 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m02:29:42.373590 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/migueldichoso/Downloads/Titanic/target/run_results.json
[0m02:29:42.373840 [info ] [MainThread]: 
[0m02:29:42.374120 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m02:29:42.374321 [info ] [MainThread]: 
[0m02:29:42.374609 [error] [MainThread]:   Database Error in model train (models/train.py)
  100357 (P0000): Python Interpreter Error:
  Traceback (most recent call last):
    File "_udf_code.py", line 115, in main
      model_dict = model(dbt, session)
                   ^^^^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 40, in model
      x = preprocess(data)
          ^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 22, in preprocess
      df = df[["employee_id", "age", "AGE", "SIBSP", "PARCH", "FARE", "EMBARKED"]]
           ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/frame.py", line 4108, in __getitem__
      indexer = self.columns._get_indexer_strict(key, "columns")[1]
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6200, in _get_indexer_strict
      self._raise_if_missing(keyarr, indexer, axis_name)
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6252, in _raise_if_missing
      raise KeyError(f"{not_found} not in index")
  KeyError: "['employee_id', 'age', 'SIBSP', 'PARCH', 'FARE', 'EMBARKED'] not in index"
   in function TRAIN__DBT_SP with handler main
  compiled code at target/run/titanic/models/train.py
[0m02:29:42.374916 [info ] [MainThread]: 
[0m02:29:42.375158 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m02:29:42.376919 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 16.039352, "process_in_blocks": "0", "process_kernel_time": 0.429756, "process_mem_max_rss": "185188352", "process_out_blocks": "0", "process_user_time": 1.798945}
[0m02:29:42.377196 [debug] [MainThread]: Command `dbt run` failed at 02:29:42.377142 after 16.04 seconds
[0m02:29:42.377442 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1128853d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120e1e480>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120e1c2f0>]}
[0m02:29:42.377658 [debug] [MainThread]: Flushing usage events
[0m02:29:44.196485 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:30:50.722780 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b62900>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b85fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b85af0>]}


============================== 02:30:50.726793 | d7b38211-404f-4fd4-8218-25252b694b63 ==============================
[0m02:30:50.726793 [info ] [MainThread]: Running with dbt=1.9.3
[0m02:30:50.727216 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/migueldichoso/Downloads/Titanic/logs', 'fail_fast': 'False', 'profiles_dir': '/Users/migueldichoso/Downloads/Titanic', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run -s train', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:30:51.349713 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd7b38211-404f-4fd4-8218-25252b694b63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f68ef0>]}
[0m02:30:51.383768 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd7b38211-404f-4fd4-8218-25252b694b63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10901d2b0>]}
[0m02:30:51.384519 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m02:30:51.501546 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m02:30:51.575873 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:30:51.576294 [debug] [MainThread]: Partial parsing: updated file: titanic://models/train.py
[0m02:30:51.720404 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd7b38211-404f-4fd4-8218-25252b694b63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b5f320>]}
[0m02:30:51.758589 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m02:30:51.760938 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m02:30:51.775265 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd7b38211-404f-4fd4-8218-25252b694b63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1097c09e0>]}
[0m02:30:51.775588 [info ] [MainThread]: Found 3 seeds, 2 models, 480 macros
[0m02:30:51.775807 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd7b38211-404f-4fd4-8218-25252b694b63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109bbc830>]}
[0m02:30:51.776798 [info ] [MainThread]: 
[0m02:30:51.777021 [info ] [MainThread]: Concurrency: 10 threads (target='titanic_dev')
[0m02:30:51.777180 [info ] [MainThread]: 
[0m02:30:51.777479 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m02:30:51.778023 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_analytics'
[0m02:30:51.822683 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
[0m02:30:51.823000 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics"} */
show terse schemas in database analytics
    limit 10000
[0m02:30:51.823204 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:30:54.841765 [debug] [ThreadPool]: SQL status: SUCCESS 1758 in 3.018 seconds
[0m02:30:56.260375 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_aaa_titanic_miguel)
[0m02:30:56.267355 [debug] [ThreadPool]: Using snowflake connection "list_analytics_aaa_titanic_miguel"
[0m02:30:56.267597 [debug] [ThreadPool]: On list_analytics_aaa_titanic_miguel: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics_aaa_titanic_miguel"} */
show objects in analytics.aaa_titanic_miguel limit 10000;
[0m02:30:56.668593 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.400 seconds
[0m02:30:56.673928 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd7b38211-404f-4fd4-8218-25252b694b63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1095378f0>]}
[0m02:30:56.678370 [debug] [Thread-1 (]: Began running node model.titanic.train
[0m02:30:56.678915 [info ] [Thread-1 (]: 1 of 1 START python model model aaa_titanic_miguel.train ....................... [RUN]
[0m02:30:56.679395 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_analytics_aaa_titanic_miguel, now model.titanic.train)
[0m02:30:56.679766 [debug] [Thread-1 (]: Began compiling node model.titanic.train
[0m02:30:56.702273 [debug] [Thread-1 (]: Writing injected SQL for node "model.titanic.train"
[0m02:30:56.703206 [debug] [Thread-1 (]: Began executing node model.titanic.train
[0m02:30:56.717244 [debug] [Thread-1 (]: Writing runtime python for node "model.titanic.train"
[0m02:30:56.718625 [debug] [Thread-1 (]: Using snowflake connection "model.titanic.train"
[0m02:30:56.719009 [debug] [Thread-1 (]: On model.titanic.train: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "model.titanic.train"} */
WITH train__dbt_sp AS PROCEDURE ()

RETURNS STRING
LANGUAGE PYTHON
RUNTIME_VERSION = '3.11'
PACKAGES = ('snowflake-ml-python', 'pandas', 'scikit-learn', 'snowflake-snowpark-python')



HANDLER = 'main'
EXECUTE AS CALLER
AS
$$

import sys
sys._xoptions['snowflake_partner_attribution'].append("dbtLabs_dbtPython")


        


import importlib.util
if importlib.util.find_spec("snowflake.ml") is None:
    raise ImportError("snowflake.ml is not found. Add snowflake-ml-python to package dependencies.")
from snowflake.ml.registry import Registry
import datetime
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.svm import SVC
from snowflake.ml.model import model_signature


def preprocess(df: pd.DataFrame) -> pd.DataFrame:
  df = df[["employee_id", "age", "monthly_expenses"]]
  df["employee_id"] = pd.Categorical(df["employee_id"])
  df["age"] = pd.Categorical(df["age"])
  df["monthly_expenses"] = pd.Categorical(df["monthly_expenses"])
  return pd.get_dummies(df, columns=["employee_id", "age", "monthly_expenses"])


def model(dbt, session):
  dbt.config(
    materialized="model",
    python_version="3.11",
    packages=["snowflake-ml-python", "pandas", "scikit-learn"],
  )

  dataset = dbt.ref("train_data")

  data = dataset.to_pandas()

  x = preprocess(data)
  y = data["attrition"]

  imputer = SimpleImputer()
  x = imputer.fit_transform(x)

  model = SVC()
  model.fit(x, y)

  return {
    "model": model,
    "signatures": {"predict": model_signature.infer_signature(x, y)},
    "version_name": datetime.datetime.today().strftime("V%Y%m%d"),
    "metrics": {"r2_score": model.score(x, y)},
    "comment": f"r2_score: {model.score(x, y)}",
    "set_default": True,
  }


# This part is user provided model code
# you will need to copy the next section to run the code
# COMMAND ----------
# this part is dbt logic for get ref work, do not modify

def ref(*args, **kwargs):
    refs = {"train_data": "analytics.aaa_titanic_miguel.train_data"}
    key = '.'.join(args)
    version = kwargs.get("v") or kwargs.get("version")
    if version:
        key += f".v{version}"
    dbt_load_df_function = kwargs.get("dbt_load_df_function")
    return dbt_load_df_function(refs[key])


def source(*args, dbt_load_df_function):
    sources = {}
    key = '.'.join(args)
    return dbt_load_df_function(sources[key])


config_dict = {}


class config:
    def __init__(self, *args, **kwargs):
        pass

    @staticmethod
    def get(key, default=None):
        return config_dict.get(key, default)

class this:
    """dbt.this() or dbt.this.identifier"""
    database = "analytics"
    schema = "aaa_titanic_miguel"
    identifier = "train"
    
    def __repr__(self):
        return 'analytics.aaa_titanic_miguel.train'


class dbtObj:
    def __init__(self, load_df_function) -> None:
        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)
        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)
        self.config = config
        self.this = this()
        self.is_incremental = False

# COMMAND ----------



def main(session):
    dbt = dbtObj(session.table)
    model_dict = model(dbt, session)
    reg = Registry(
        session = session,
        database_name = dbt.this.database,
        schema_name = dbt.this.schema
    )
    set_default = model_dict.pop("set_default", False)
    assert "model_name" not in model_dict, "model_name cannot be overridden"
    assert "conda_dependencies" not in model_dict, "conda_dependencies cannot be overridden"
    mv = reg.log_model(
        **model_dict,
        model_name = "analytics.aaa_titanic_miguel.train",
        conda_dependencies = ['snowflake-ml-python', 'pandas', 'scikit-learn'],
    )
    if set_default:
        reg.get_model(dbt.this.identifier).default = mv
    return "OK"

$$
CALL train__dbt_sp();
[0m02:31:28.628431 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01baeb76-0907-baa2-0007-978308d09fd2
[0m02:31:28.629134 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 100357 (P0000): Python Interpreter Error:
Traceback (most recent call last):
  File "_udf_code.py", line 115, in main
    model_dict = model(dbt, session)
                 ^^^^^^^^^^^^^^^^^^^
  File "_udf_code.py", line 40, in model
    x = preprocess(data)
        ^^^^^^^^^^^^^^^^
  File "_udf_code.py", line 22, in preprocess
    df = df[["employee_id", "age", "monthly_expenses"]]
         ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/frame.py", line 4108, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6200, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6249, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['employee_id', 'age', 'monthly_expenses'], dtype='object')] are in the [columns]"
 in function TRAIN__DBT_SP with handler main
[0m02:31:28.633841 [debug] [Thread-1 (]: Database Error in model train (models/train.py)
  100357 (P0000): Python Interpreter Error:
  Traceback (most recent call last):
    File "_udf_code.py", line 115, in main
      model_dict = model(dbt, session)
                   ^^^^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 40, in model
      x = preprocess(data)
          ^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 22, in preprocess
      df = df[["employee_id", "age", "monthly_expenses"]]
           ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/frame.py", line 4108, in __getitem__
      indexer = self.columns._get_indexer_strict(key, "columns")[1]
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6200, in _get_indexer_strict
      self._raise_if_missing(keyarr, indexer, axis_name)
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6249, in _raise_if_missing
      raise KeyError(f"None of [{key}] are in the [{axis_name}]")
  KeyError: "None of [Index(['employee_id', 'age', 'monthly_expenses'], dtype='object')] are in the [columns]"
   in function TRAIN__DBT_SP with handler main
  compiled code at target/run/titanic/models/train.py
[0m02:31:28.635843 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd7b38211-404f-4fd4-8218-25252b694b63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b807ad0>]}
[0m02:31:28.636507 [error] [Thread-1 (]: 1 of 1 ERROR creating python model model aaa_titanic_miguel.train .............. [[31mERROR[0m in 31.95s]
[0m02:31:28.637098 [debug] [Thread-1 (]: Finished running node model.titanic.train
[0m02:31:28.637685 [debug] [Thread-13 ]: Marking all children of 'model.titanic.train' to be skipped because of status 'error'.  Reason: Database Error in model train (models/train.py)
  100357 (P0000): Python Interpreter Error:
  Traceback (most recent call last):
    File "_udf_code.py", line 115, in main
      model_dict = model(dbt, session)
                   ^^^^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 40, in model
      x = preprocess(data)
          ^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 22, in preprocess
      df = df[["employee_id", "age", "monthly_expenses"]]
           ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/frame.py", line 4108, in __getitem__
      indexer = self.columns._get_indexer_strict(key, "columns")[1]
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6200, in _get_indexer_strict
      self._raise_if_missing(keyarr, indexer, axis_name)
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6249, in _raise_if_missing
      raise KeyError(f"None of [{key}] are in the [{axis_name}]")
  KeyError: "None of [Index(['employee_id', 'age', 'monthly_expenses'], dtype='object')] are in the [columns]"
   in function TRAIN__DBT_SP with handler main
  compiled code at target/run/titanic/models/train.py.
[0m02:31:28.639644 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:31:28.639842 [debug] [MainThread]: Connection 'model.titanic.train' was left open.
[0m02:31:28.640015 [debug] [MainThread]: On model.titanic.train: Close
[0m02:31:29.254319 [info ] [MainThread]: 
[0m02:31:29.255176 [info ] [MainThread]: Finished running 1 model model in 0 hours 0 minutes and 37.48 seconds (37.48s).
[0m02:31:29.256266 [debug] [MainThread]: Command end result
[0m02:31:29.275952 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m02:31:29.277505 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m02:31:29.281814 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/migueldichoso/Downloads/Titanic/target/run_results.json
[0m02:31:29.282029 [info ] [MainThread]: 
[0m02:31:29.282266 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m02:31:29.282454 [info ] [MainThread]: 
[0m02:31:29.282727 [error] [MainThread]:   Database Error in model train (models/train.py)
  100357 (P0000): Python Interpreter Error:
  Traceback (most recent call last):
    File "_udf_code.py", line 115, in main
      model_dict = model(dbt, session)
                   ^^^^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 40, in model
      x = preprocess(data)
          ^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 22, in preprocess
      df = df[["employee_id", "age", "monthly_expenses"]]
           ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/frame.py", line 4108, in __getitem__
      indexer = self.columns._get_indexer_strict(key, "columns")[1]
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6200, in _get_indexer_strict
      self._raise_if_missing(keyarr, indexer, axis_name)
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6249, in _raise_if_missing
      raise KeyError(f"None of [{key}] are in the [{axis_name}]")
  KeyError: "None of [Index(['employee_id', 'age', 'monthly_expenses'], dtype='object')] are in the [columns]"
   in function TRAIN__DBT_SP with handler main
  compiled code at target/run/titanic/models/train.py
[0m02:31:29.282961 [info ] [MainThread]: 
[0m02:31:29.283146 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m02:31:29.284801 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 38.636433, "process_in_blocks": "0", "process_kernel_time": 0.435664, "process_mem_max_rss": "183648256", "process_out_blocks": "0", "process_user_time": 1.789693}
[0m02:31:29.285135 [debug] [MainThread]: Command `dbt run` failed at 02:31:29.285067 after 38.64 seconds
[0m02:31:29.285404 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b13b60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104632fc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103d7d550>]}
[0m02:31:29.285636 [debug] [MainThread]: Flushing usage events
[0m02:31:35.500238 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:32:04.806843 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e07920>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103e896d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e15af0>]}


============================== 02:32:04.811061 | 9528a695-965c-42ed-ba30-431f82fc01d9 ==============================
[0m02:32:04.811061 [info ] [MainThread]: Running with dbt=1.9.3
[0m02:32:04.811522 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/migueldichoso/Downloads/Titanic', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/migueldichoso/Downloads/Titanic/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run -s train', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:32:05.315678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9528a695-965c-42ed-ba30-431f82fc01d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104332720>]}
[0m02:32:05.349498 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9528a695-965c-42ed-ba30-431f82fc01d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105cd5190>]}
[0m02:32:05.350560 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m02:32:05.458437 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m02:32:05.529132 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:32:05.529566 [debug] [MainThread]: Partial parsing: updated file: titanic://models/train.py
[0m02:32:05.643127 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.titanic.train' (models/train.py) depends on a node named 'seeds/train_data.csv' which was not found
[0m02:32:05.644735 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.9113617, "process_in_blocks": "0", "process_kernel_time": 0.284941, "process_mem_max_rss": "158990336", "process_out_blocks": "0", "process_user_time": 1.397266}
[0m02:32:05.645045 [debug] [MainThread]: Command `dbt run` failed at 02:32:05.644972 after 0.91 seconds
[0m02:32:05.645314 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e15c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d426ea0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d069220>]}
[0m02:32:05.645552 [debug] [MainThread]: Flushing usage events
[0m02:32:09.577731 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:32:27.715613 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b60980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b82030>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b81b50>]}


============================== 02:32:27.719304 | 79e639a3-fcc7-4e45-8bc5-b038ef6923ba ==============================
[0m02:32:27.719304 [info ] [MainThread]: Running with dbt=1.9.3
[0m02:32:27.719775 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/migueldichoso/Downloads/Titanic/logs', 'version_check': 'True', 'profiles_dir': '/Users/migueldichoso/Downloads/Titanic', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run -s train', 'send_anonymous_usage_stats': 'True'}
[0m02:32:28.148588 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '79e639a3-fcc7-4e45-8bc5-b038ef6923ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114b1ea20>]}
[0m02:32:28.183135 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '79e639a3-fcc7-4e45-8bc5-b038ef6923ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114d008c0>]}
[0m02:32:28.183688 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m02:32:28.289066 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m02:32:28.354162 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m02:32:28.354454 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m02:32:28.376374 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '79e639a3-fcc7-4e45-8bc5-b038ef6923ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115037f50>]}
[0m02:32:28.417304 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m02:32:28.419283 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m02:32:28.432189 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '79e639a3-fcc7-4e45-8bc5-b038ef6923ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1150082c0>]}
[0m02:32:28.432504 [info ] [MainThread]: Found 3 seeds, 2 models, 480 macros
[0m02:32:28.432735 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '79e639a3-fcc7-4e45-8bc5-b038ef6923ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115317140>]}
[0m02:32:28.433669 [info ] [MainThread]: 
[0m02:32:28.433907 [info ] [MainThread]: Concurrency: 10 threads (target='titanic_dev')
[0m02:32:28.434070 [info ] [MainThread]: 
[0m02:32:28.434367 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m02:32:28.434911 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_analytics'
[0m02:32:28.481230 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
[0m02:32:28.481540 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics"} */
show terse schemas in database analytics
    limit 10000
[0m02:32:28.481734 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:32:31.423670 [debug] [ThreadPool]: SQL status: SUCCESS 1758 in 2.942 seconds
[0m02:32:32.806139 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_aaa_titanic_miguel)
[0m02:32:32.812718 [debug] [ThreadPool]: Using snowflake connection "list_analytics_aaa_titanic_miguel"
[0m02:32:32.812951 [debug] [ThreadPool]: On list_analytics_aaa_titanic_miguel: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics_aaa_titanic_miguel"} */
show objects in analytics.aaa_titanic_miguel limit 10000;
[0m02:32:33.246066 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.433 seconds
[0m02:32:33.251633 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '79e639a3-fcc7-4e45-8bc5-b038ef6923ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114c6d760>]}
[0m02:32:33.256190 [debug] [Thread-1 (]: Began running node model.titanic.train
[0m02:32:33.256656 [info ] [Thread-1 (]: 1 of 1 START python model model aaa_titanic_miguel.train ....................... [RUN]
[0m02:32:33.257039 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_analytics_aaa_titanic_miguel, now model.titanic.train)
[0m02:32:33.257331 [debug] [Thread-1 (]: Began compiling node model.titanic.train
[0m02:32:33.278185 [debug] [Thread-1 (]: Writing injected SQL for node "model.titanic.train"
[0m02:32:33.278935 [debug] [Thread-1 (]: Began executing node model.titanic.train
[0m02:32:33.293137 [debug] [Thread-1 (]: Writing runtime python for node "model.titanic.train"
[0m02:32:33.294540 [debug] [Thread-1 (]: Using snowflake connection "model.titanic.train"
[0m02:32:33.294901 [debug] [Thread-1 (]: On model.titanic.train: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "model.titanic.train"} */
WITH train__dbt_sp AS PROCEDURE ()

RETURNS STRING
LANGUAGE PYTHON
RUNTIME_VERSION = '3.11'
PACKAGES = ('snowflake-ml-python', 'pandas', 'scikit-learn', 'snowflake-snowpark-python')



HANDLER = 'main'
EXECUTE AS CALLER
AS
$$

import sys
sys._xoptions['snowflake_partner_attribution'].append("dbtLabs_dbtPython")


        


import importlib.util
if importlib.util.find_spec("snowflake.ml") is None:
    raise ImportError("snowflake.ml is not found. Add snowflake-ml-python to package dependencies.")
from snowflake.ml.registry import Registry
import datetime
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.svm import SVC
from snowflake.ml.model import model_signature


def preprocess(df: pd.DataFrame) -> pd.DataFrame:
  df = df[["employee_id", "age", "monthly_expenses"]]
  df["employee_id"] = pd.Categorical(df["employee_id"])
  df["age"] = pd.Categorical(df["age"])
  df["monthly_expenses"] = pd.Categorical(df["monthly_expenses"])
  return pd.get_dummies(df, columns=["employee_id", "age", "monthly_expenses"])


def model(dbt, session):
  dbt.config(
    materialized="model",
    python_version="3.11",
    packages=["snowflake-ml-python", "pandas", "scikit-learn"],
  )

  dataset = dbt.ref("train_data")

  data = dataset.to_pandas()

  x = preprocess(data)
  y = data["attrition"]

  imputer = SimpleImputer()
  x = imputer.fit_transform(x)

  model = SVC()
  model.fit(x, y)

  return {
    "model": model,
    "signatures": {"predict": model_signature.infer_signature(x, y)},
    "version_name": datetime.datetime.today().strftime("V%Y%m%d"),
    "metrics": {"r2_score": model.score(x, y)},
    "comment": f"r2_score: {model.score(x, y)}",
    "set_default": True,
  }


# This part is user provided model code
# you will need to copy the next section to run the code
# COMMAND ----------
# this part is dbt logic for get ref work, do not modify

def ref(*args, **kwargs):
    refs = {"train_data": "analytics.aaa_titanic_miguel.train_data"}
    key = '.'.join(args)
    version = kwargs.get("v") or kwargs.get("version")
    if version:
        key += f".v{version}"
    dbt_load_df_function = kwargs.get("dbt_load_df_function")
    return dbt_load_df_function(refs[key])


def source(*args, dbt_load_df_function):
    sources = {}
    key = '.'.join(args)
    return dbt_load_df_function(sources[key])


config_dict = {}


class config:
    def __init__(self, *args, **kwargs):
        pass

    @staticmethod
    def get(key, default=None):
        return config_dict.get(key, default)

class this:
    """dbt.this() or dbt.this.identifier"""
    database = "analytics"
    schema = "aaa_titanic_miguel"
    identifier = "train"
    
    def __repr__(self):
        return 'analytics.aaa_titanic_miguel.train'


class dbtObj:
    def __init__(self, load_df_function) -> None:
        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)
        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)
        self.config = config
        self.this = this()
        self.is_incremental = False

# COMMAND ----------



def main(session):
    dbt = dbtObj(session.table)
    model_dict = model(dbt, session)
    reg = Registry(
        session = session,
        database_name = dbt.this.database,
        schema_name = dbt.this.schema
    )
    set_default = model_dict.pop("set_default", False)
    assert "model_name" not in model_dict, "model_name cannot be overridden"
    assert "conda_dependencies" not in model_dict, "conda_dependencies cannot be overridden"
    mv = reg.log_model(
        **model_dict,
        model_name = "analytics.aaa_titanic_miguel.train",
        conda_dependencies = ['snowflake-ml-python', 'pandas', 'scikit-learn'],
    )
    if set_default:
        reg.get_model(dbt.this.identifier).default = mv
    return "OK"

$$
CALL train__dbt_sp();
[0m02:32:41.134461 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01baeb78-0907-baa2-0007-978308d09fde
[0m02:32:41.135656 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 100357 (P0000): Python Interpreter Error:
Traceback (most recent call last):
  File "_udf_code.py", line 115, in main
    model_dict = model(dbt, session)
                 ^^^^^^^^^^^^^^^^^^^
  File "_udf_code.py", line 40, in model
    x = preprocess(data)
        ^^^^^^^^^^^^^^^^
  File "_udf_code.py", line 22, in preprocess
    df = df[["employee_id", "age", "monthly_expenses"]]
         ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/frame.py", line 4108, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6200, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6249, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['employee_id', 'age', 'monthly_expenses'], dtype='object')] are in the [columns]"
 in function TRAIN__DBT_SP with handler main
[0m02:32:41.141258 [debug] [Thread-1 (]: Database Error in model train (models/train.py)
  100357 (P0000): Python Interpreter Error:
  Traceback (most recent call last):
    File "_udf_code.py", line 115, in main
      model_dict = model(dbt, session)
                   ^^^^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 40, in model
      x = preprocess(data)
          ^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 22, in preprocess
      df = df[["employee_id", "age", "monthly_expenses"]]
           ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/frame.py", line 4108, in __getitem__
      indexer = self.columns._get_indexer_strict(key, "columns")[1]
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6200, in _get_indexer_strict
      self._raise_if_missing(keyarr, indexer, axis_name)
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6249, in _raise_if_missing
      raise KeyError(f"None of [{key}] are in the [{axis_name}]")
  KeyError: "None of [Index(['employee_id', 'age', 'monthly_expenses'], dtype='object')] are in the [columns]"
   in function TRAIN__DBT_SP with handler main
  compiled code at target/run/titanic/models/train.py
[0m02:32:41.143321 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '79e639a3-fcc7-4e45-8bc5-b038ef6923ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116856660>]}
[0m02:32:41.144054 [error] [Thread-1 (]: 1 of 1 ERROR creating python model model aaa_titanic_miguel.train .............. [[31mERROR[0m in 7.88s]
[0m02:32:41.144743 [debug] [Thread-1 (]: Finished running node model.titanic.train
[0m02:32:41.145369 [debug] [Thread-13 ]: Marking all children of 'model.titanic.train' to be skipped because of status 'error'.  Reason: Database Error in model train (models/train.py)
  100357 (P0000): Python Interpreter Error:
  Traceback (most recent call last):
    File "_udf_code.py", line 115, in main
      model_dict = model(dbt, session)
                   ^^^^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 40, in model
      x = preprocess(data)
          ^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 22, in preprocess
      df = df[["employee_id", "age", "monthly_expenses"]]
           ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/frame.py", line 4108, in __getitem__
      indexer = self.columns._get_indexer_strict(key, "columns")[1]
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6200, in _get_indexer_strict
      self._raise_if_missing(keyarr, indexer, axis_name)
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6249, in _raise_if_missing
      raise KeyError(f"None of [{key}] are in the [{axis_name}]")
  KeyError: "None of [Index(['employee_id', 'age', 'monthly_expenses'], dtype='object')] are in the [columns]"
   in function TRAIN__DBT_SP with handler main
  compiled code at target/run/titanic/models/train.py.
[0m02:32:41.147477 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:32:41.147771 [debug] [MainThread]: Connection 'model.titanic.train' was left open.
[0m02:32:41.148031 [debug] [MainThread]: On model.titanic.train: Close
[0m02:32:41.760028 [info ] [MainThread]: 
[0m02:32:41.760865 [info ] [MainThread]: Finished running 1 model model in 0 hours 0 minutes and 13.33 seconds (13.33s).
[0m02:32:41.761884 [debug] [MainThread]: Command end result
[0m02:32:41.783598 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m02:32:41.785352 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m02:32:41.790796 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/migueldichoso/Downloads/Titanic/target/run_results.json
[0m02:32:41.791159 [info ] [MainThread]: 
[0m02:32:41.791482 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m02:32:41.791709 [info ] [MainThread]: 
[0m02:32:41.792021 [error] [MainThread]:   Database Error in model train (models/train.py)
  100357 (P0000): Python Interpreter Error:
  Traceback (most recent call last):
    File "_udf_code.py", line 115, in main
      model_dict = model(dbt, session)
                   ^^^^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 40, in model
      x = preprocess(data)
          ^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 22, in preprocess
      df = df[["employee_id", "age", "monthly_expenses"]]
           ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/frame.py", line 4108, in __getitem__
      indexer = self.columns._get_indexer_strict(key, "columns")[1]
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6200, in _get_indexer_strict
      self._raise_if_missing(keyarr, indexer, axis_name)
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6249, in _raise_if_missing
      raise KeyError(f"None of [{key}] are in the [{axis_name}]")
  KeyError: "None of [Index(['employee_id', 'age', 'monthly_expenses'], dtype='object')] are in the [columns]"
   in function TRAIN__DBT_SP with handler main
  compiled code at target/run/titanic/models/train.py
[0m02:32:41.792300 [info ] [MainThread]: 
[0m02:32:41.792528 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m02:32:41.794524 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 14.151734, "process_in_blocks": "0", "process_kernel_time": 0.323592, "process_mem_max_rss": "182452224", "process_out_blocks": "0", "process_user_time": 1.670139}
[0m02:32:41.794868 [debug] [MainThread]: Command `dbt run` failed at 02:32:41.794797 after 14.15 seconds
[0m02:32:41.795190 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114f89610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b81b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b81760>]}
[0m02:32:41.795425 [debug] [MainThread]: Flushing usage events
[0m02:32:47.018487 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:33:06.429259 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106360140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1063a5d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1063a5880>]}


============================== 02:33:06.433180 | 5949931b-7bd4-4717-993f-257ac8f77d84 ==============================
[0m02:33:06.433180 [info ] [MainThread]: Running with dbt=1.9.3
[0m02:33:06.433639 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/migueldichoso/Downloads/Titanic', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/migueldichoso/Downloads/Titanic/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run -s train --log-level debug', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:33:06.935181 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5949931b-7bd4-4717-993f-257ac8f77d84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10468ade0>]}
[0m02:33:06.973412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5949931b-7bd4-4717-993f-257ac8f77d84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc6ddf0>]}
[0m02:33:06.974249 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m02:33:07.080811 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m02:33:07.154586 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m02:33:07.154933 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m02:33:07.199800 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5949931b-7bd4-4717-993f-257ac8f77d84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c135670>]}
[0m02:33:07.243969 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m02:33:07.246486 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m02:33:07.259933 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5949931b-7bd4-4717-993f-257ac8f77d84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c363260>]}
[0m02:33:07.260340 [info ] [MainThread]: Found 3 seeds, 2 models, 480 macros
[0m02:33:07.260557 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5949931b-7bd4-4717-993f-257ac8f77d84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c525520>]}
[0m02:33:07.261571 [info ] [MainThread]: 
[0m02:33:07.261847 [info ] [MainThread]: Concurrency: 10 threads (target='titanic_dev')
[0m02:33:07.262120 [info ] [MainThread]: 
[0m02:33:07.262492 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m02:33:07.263094 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_analytics'
[0m02:33:07.303251 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
[0m02:33:07.303605 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics"} */
show terse schemas in database analytics
    limit 10000
[0m02:33:07.303815 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:33:09.895496 [debug] [ThreadPool]: SQL status: SUCCESS 1758 in 2.592 seconds
[0m02:33:11.290823 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_aaa_titanic_miguel)
[0m02:33:11.297527 [debug] [ThreadPool]: Using snowflake connection "list_analytics_aaa_titanic_miguel"
[0m02:33:11.297831 [debug] [ThreadPool]: On list_analytics_aaa_titanic_miguel: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics_aaa_titanic_miguel"} */
show objects in analytics.aaa_titanic_miguel limit 10000;
[0m02:33:11.663807 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.365 seconds
[0m02:33:11.669408 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5949931b-7bd4-4717-993f-257ac8f77d84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd6cad0>]}
[0m02:33:11.675084 [debug] [Thread-1 (]: Began running node model.titanic.train
[0m02:33:11.675803 [info ] [Thread-1 (]: 1 of 1 START python model model aaa_titanic_miguel.train ....................... [RUN]
[0m02:33:11.676282 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_analytics_aaa_titanic_miguel, now model.titanic.train)
[0m02:33:11.676781 [debug] [Thread-1 (]: Began compiling node model.titanic.train
[0m02:33:11.699992 [debug] [Thread-1 (]: Writing injected SQL for node "model.titanic.train"
[0m02:33:11.700649 [debug] [Thread-1 (]: Began executing node model.titanic.train
[0m02:33:11.714918 [debug] [Thread-1 (]: Writing runtime python for node "model.titanic.train"
[0m02:33:11.716311 [debug] [Thread-1 (]: Using snowflake connection "model.titanic.train"
[0m02:33:11.716712 [debug] [Thread-1 (]: On model.titanic.train: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "model.titanic.train"} */
WITH train__dbt_sp AS PROCEDURE ()

RETURNS STRING
LANGUAGE PYTHON
RUNTIME_VERSION = '3.11'
PACKAGES = ('snowflake-ml-python', 'pandas', 'scikit-learn', 'snowflake-snowpark-python')



HANDLER = 'main'
EXECUTE AS CALLER
AS
$$

import sys
sys._xoptions['snowflake_partner_attribution'].append("dbtLabs_dbtPython")


        


import importlib.util
if importlib.util.find_spec("snowflake.ml") is None:
    raise ImportError("snowflake.ml is not found. Add snowflake-ml-python to package dependencies.")
from snowflake.ml.registry import Registry
import datetime
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.svm import SVC
from snowflake.ml.model import model_signature


def preprocess(df: pd.DataFrame) -> pd.DataFrame:
  df = df[["employee_id", "age", "monthly_expenses"]]
  df["employee_id"] = pd.Categorical(df["employee_id"])
  df["age"] = pd.Categorical(df["age"])
  df["monthly_expenses"] = pd.Categorical(df["monthly_expenses"])
  return pd.get_dummies(df, columns=["employee_id", "age", "monthly_expenses"])


def model(dbt, session):
  dbt.config(
    materialized="model",
    python_version="3.11",
    packages=["snowflake-ml-python", "pandas", "scikit-learn"],
  )

  dataset = dbt.ref("train_data")

  data = dataset.to_pandas()

  x = preprocess(data)
  y = data["attrition"]

  imputer = SimpleImputer()
  x = imputer.fit_transform(x)

  model = SVC()
  model.fit(x, y)

  return {
    "model": model,
    "signatures": {"predict": model_signature.infer_signature(x, y)},
    "version_name": datetime.datetime.today().strftime("V%Y%m%d"),
    "metrics": {"r2_score": model.score(x, y)},
    "comment": f"r2_score: {model.score(x, y)}",
    "set_default": True,
  }


# This part is user provided model code
# you will need to copy the next section to run the code
# COMMAND ----------
# this part is dbt logic for get ref work, do not modify

def ref(*args, **kwargs):
    refs = {"train_data": "analytics.aaa_titanic_miguel.train_data"}
    key = '.'.join(args)
    version = kwargs.get("v") or kwargs.get("version")
    if version:
        key += f".v{version}"
    dbt_load_df_function = kwargs.get("dbt_load_df_function")
    return dbt_load_df_function(refs[key])


def source(*args, dbt_load_df_function):
    sources = {}
    key = '.'.join(args)
    return dbt_load_df_function(sources[key])


config_dict = {}


class config:
    def __init__(self, *args, **kwargs):
        pass

    @staticmethod
    def get(key, default=None):
        return config_dict.get(key, default)

class this:
    """dbt.this() or dbt.this.identifier"""
    database = "analytics"
    schema = "aaa_titanic_miguel"
    identifier = "train"
    
    def __repr__(self):
        return 'analytics.aaa_titanic_miguel.train'


class dbtObj:
    def __init__(self, load_df_function) -> None:
        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)
        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)
        self.config = config
        self.this = this()
        self.is_incremental = False

# COMMAND ----------



def main(session):
    dbt = dbtObj(session.table)
    model_dict = model(dbt, session)
    reg = Registry(
        session = session,
        database_name = dbt.this.database,
        schema_name = dbt.this.schema
    )
    set_default = model_dict.pop("set_default", False)
    assert "model_name" not in model_dict, "model_name cannot be overridden"
    assert "conda_dependencies" not in model_dict, "conda_dependencies cannot be overridden"
    mv = reg.log_model(
        **model_dict,
        model_name = "analytics.aaa_titanic_miguel.train",
        conda_dependencies = ['snowflake-ml-python', 'pandas', 'scikit-learn'],
    )
    if set_default:
        reg.get_model(dbt.this.identifier).default = mv
    return "OK"

$$
CALL train__dbt_sp();
[0m02:33:15.255982 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01baeb79-0907-ba98-0007-978308d0aab2
[0m02:33:15.256756 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 100357 (P0000): Python Interpreter Error:
Traceback (most recent call last):
  File "_udf_code.py", line 115, in main
    model_dict = model(dbt, session)
                 ^^^^^^^^^^^^^^^^^^^
  File "_udf_code.py", line 40, in model
    x = preprocess(data)
        ^^^^^^^^^^^^^^^^
  File "_udf_code.py", line 22, in preprocess
    df = df[["employee_id", "age", "monthly_expenses"]]
         ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/frame.py", line 4108, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6200, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6249, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['employee_id', 'age', 'monthly_expenses'], dtype='object')] are in the [columns]"
 in function TRAIN__DBT_SP with handler main
[0m02:33:15.261684 [debug] [Thread-1 (]: Database Error in model train (models/train.py)
  100357 (P0000): Python Interpreter Error:
  Traceback (most recent call last):
    File "_udf_code.py", line 115, in main
      model_dict = model(dbt, session)
                   ^^^^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 40, in model
      x = preprocess(data)
          ^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 22, in preprocess
      df = df[["employee_id", "age", "monthly_expenses"]]
           ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/frame.py", line 4108, in __getitem__
      indexer = self.columns._get_indexer_strict(key, "columns")[1]
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6200, in _get_indexer_strict
      self._raise_if_missing(keyarr, indexer, axis_name)
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6249, in _raise_if_missing
      raise KeyError(f"None of [{key}] are in the [{axis_name}]")
  KeyError: "None of [Index(['employee_id', 'age', 'monthly_expenses'], dtype='object')] are in the [columns]"
   in function TRAIN__DBT_SP with handler main
  compiled code at target/run/titanic/models/train.py
[0m02:33:15.264650 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5949931b-7bd4-4717-993f-257ac8f77d84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128c6d340>]}
[0m02:33:15.265470 [error] [Thread-1 (]: 1 of 1 ERROR creating python model model aaa_titanic_miguel.train .............. [[31mERROR[0m in 3.59s]
[0m02:33:15.266070 [debug] [Thread-1 (]: Finished running node model.titanic.train
[0m02:33:15.266889 [debug] [Thread-13 ]: Marking all children of 'model.titanic.train' to be skipped because of status 'error'.  Reason: Database Error in model train (models/train.py)
  100357 (P0000): Python Interpreter Error:
  Traceback (most recent call last):
    File "_udf_code.py", line 115, in main
      model_dict = model(dbt, session)
                   ^^^^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 40, in model
      x = preprocess(data)
          ^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 22, in preprocess
      df = df[["employee_id", "age", "monthly_expenses"]]
           ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/frame.py", line 4108, in __getitem__
      indexer = self.columns._get_indexer_strict(key, "columns")[1]
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6200, in _get_indexer_strict
      self._raise_if_missing(keyarr, indexer, axis_name)
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6249, in _raise_if_missing
      raise KeyError(f"None of [{key}] are in the [{axis_name}]")
  KeyError: "None of [Index(['employee_id', 'age', 'monthly_expenses'], dtype='object')] are in the [columns]"
   in function TRAIN__DBT_SP with handler main
  compiled code at target/run/titanic/models/train.py.
[0m02:33:15.269699 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:33:15.270075 [debug] [MainThread]: Connection 'model.titanic.train' was left open.
[0m02:33:15.270329 [debug] [MainThread]: On model.titanic.train: Close
[0m02:33:15.939283 [info ] [MainThread]: 
[0m02:33:15.939991 [info ] [MainThread]: Finished running 1 model model in 0 hours 0 minutes and 8.68 seconds (8.68s).
[0m02:33:15.940872 [debug] [MainThread]: Command end result
[0m02:33:15.961701 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m02:33:15.963212 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m02:33:15.967661 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/migueldichoso/Downloads/Titanic/target/run_results.json
[0m02:33:15.967924 [info ] [MainThread]: 
[0m02:33:15.968331 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m02:33:15.968592 [info ] [MainThread]: 
[0m02:33:15.968888 [error] [MainThread]:   Database Error in model train (models/train.py)
  100357 (P0000): Python Interpreter Error:
  Traceback (most recent call last):
    File "_udf_code.py", line 115, in main
      model_dict = model(dbt, session)
                   ^^^^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 40, in model
      x = preprocess(data)
          ^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 22, in preprocess
      df = df[["employee_id", "age", "monthly_expenses"]]
           ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/frame.py", line 4108, in __getitem__
      indexer = self.columns._get_indexer_strict(key, "columns")[1]
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6200, in _get_indexer_strict
      self._raise_if_missing(keyarr, indexer, axis_name)
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6249, in _raise_if_missing
      raise KeyError(f"None of [{key}] are in the [{axis_name}]")
  KeyError: "None of [Index(['employee_id', 'age', 'monthly_expenses'], dtype='object')] are in the [columns]"
   in function TRAIN__DBT_SP with handler main
  compiled code at target/run/titanic/models/train.py
[0m02:33:15.969312 [info ] [MainThread]: 
[0m02:33:15.969580 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m02:33:15.971442 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 9.614667, "process_in_blocks": "0", "process_kernel_time": 0.334254, "process_mem_max_rss": "179929088", "process_out_blocks": "0", "process_user_time": 1.70094}
[0m02:33:15.971800 [debug] [MainThread]: Command `dbt run` failed at 02:33:15.971739 after 9.62 seconds
[0m02:33:15.972070 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106223890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10712ec60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c108e90>]}
[0m02:33:15.972325 [debug] [MainThread]: Flushing usage events
[0m02:33:17.801621 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:37:22.348071 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a5a7e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106cfa1e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106cf9d00>]}


============================== 02:37:22.352358 | 20493e59-8120-4705-8aa3-7ab3c524efe2 ==============================
[0m02:37:22.352358 [info ] [MainThread]: Running with dbt=1.9.3
[0m02:37:22.352826 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/migueldichoso/Downloads/Titanic/logs', 'fail_fast': 'False', 'profiles_dir': '/Users/migueldichoso/Downloads/Titanic', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt build --full-refresh', 'send_anonymous_usage_stats': 'True'}
[0m02:37:23.012618 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '20493e59-8120-4705-8aa3-7ab3c524efe2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105052cc0>]}
[0m02:37:23.050459 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '20493e59-8120-4705-8aa3-7ab3c524efe2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066082c0>]}
[0m02:37:23.051370 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m02:37:23.161014 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m02:37:23.235184 [debug] [MainThread]: Partial parsing enabled: 3 files deleted, 1 files added, 0 files changed.
[0m02:37:23.235570 [debug] [MainThread]: Partial parsing: added file: titanic://models/sklearn_predict.py
[0m02:37:23.235773 [debug] [MainThread]: Partial parsing: deleted file: titanic://seeds/train_data.csv
[0m02:37:23.235951 [debug] [MainThread]: Partial parsing: deleted file: titanic://models/train.py
[0m02:37:23.236126 [debug] [MainThread]: Partial parsing: deleted file: titanic://seeds/predict_data.csv
[0m02:37:23.380551 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '20493e59-8120-4705-8aa3-7ab3c524efe2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac4af60>]}
[0m02:37:23.419060 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m02:37:23.421249 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m02:37:23.444412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '20493e59-8120-4705-8aa3-7ab3c524efe2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af096d0>]}
[0m02:37:23.444725 [info ] [MainThread]: Found 2 models, 1 seed, 480 macros
[0m02:37:23.446081 [info ] [MainThread]: 
[0m02:37:23.446331 [info ] [MainThread]: Concurrency: 10 threads (target='titanic_dev')
[0m02:37:23.446517 [info ] [MainThread]: 
[0m02:37:23.446816 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m02:37:23.449468 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_analytics'
[0m02:37:23.506683 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
[0m02:37:23.507043 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics"} */
show terse schemas in database analytics
    limit 10000
[0m02:37:23.507268 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:37:26.391194 [debug] [ThreadPool]: SQL status: SUCCESS 1758 in 2.884 seconds
[0m02:37:28.306879 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_aaa_titanic_miguel)
[0m02:37:28.313899 [debug] [ThreadPool]: Using snowflake connection "list_analytics_aaa_titanic_miguel"
[0m02:37:28.314152 [debug] [ThreadPool]: On list_analytics_aaa_titanic_miguel: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics_aaa_titanic_miguel"} */
show objects in analytics.aaa_titanic_miguel limit 10000;
[0m02:37:28.729286 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.415 seconds
[0m02:37:28.734644 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '20493e59-8120-4705-8aa3-7ab3c524efe2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b2fea20>]}
[0m02:37:28.739777 [debug] [Thread-1 (]: Began running node seed.titanic.titanic3
[0m02:37:28.740426 [info ] [Thread-1 (]: 1 of 3 START seed file aaa_titanic_miguel.titanic3 ............................. [RUN]
[0m02:37:28.740939 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_analytics_aaa_titanic_miguel, now seed.titanic.titanic3)
[0m02:37:28.741302 [debug] [Thread-1 (]: Began compiling node seed.titanic.titanic3
[0m02:37:28.741651 [debug] [Thread-1 (]: Began executing node seed.titanic.titanic3
[0m02:37:28.799278 [debug] [Thread-1 (]: Applying DROP to: "ANALYTICS"."AAA_TITANIC_MIGUEL"."TITANIC3"
[0m02:37:28.803265 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.titanic3"
[0m02:37:28.803523 [debug] [Thread-1 (]: On seed.titanic.titanic3: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.titanic3"} */
drop table if exists "ANALYTICS"."AAA_TITANIC_MIGUEL"."TITANIC3" cascade
[0m02:37:29.293657 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.489 seconds
[0m02:37:29.313488 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.titanic3"
[0m02:37:29.313846 [debug] [Thread-1 (]: On seed.titanic.titanic3: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.titanic3"} */
create table analytics.aaa_titanic_miguel.titanic3 (pclass integer,survived integer,name text,sex text,age float8,sibsp integer,parch integer,ticket text,fare float8,cabin text,embarked text,boat text,body integer,home_dest text)
[0m02:37:29.804919 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.490 seconds
[0m02:37:29.848417 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.titanic3"
[0m02:37:29.848730 [debug] [Thread-1 (]: On seed.titanic.titanic3: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.titanic3"} */
BEGIN
[0m02:37:30.265625 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.416 seconds
[0m02:37:30.429230 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.titanic3"
[0m02:37:30.429615 [debug] [Thread-1 (]: On seed.titanic.titanic3: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.titanic3"} */
insert into analytics.aaa_titanic_miguel.titanic3 (pclass, survived, name, sex, age, sibsp, parch, ticket, fare, cabin, embarked, boat, body, home_dest) values
            (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%...
[0m02:37:32.350901 [debug] [Thread-1 (]: SQL status: SUCCESS 1309 in 1.921 seconds
[0m02:37:32.351927 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.titanic3"
[0m02:37:32.352382 [debug] [Thread-1 (]: On seed.titanic.titanic3: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.titanic3"} */
COMMIT
[0m02:37:32.890651 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.537 seconds
[0m02:37:32.899534 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.titanic.titanic3"
[0m02:37:32.924437 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '20493e59-8120-4705-8aa3-7ab3c524efe2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105051dc0>]}
[0m02:37:32.924834 [info ] [Thread-1 (]: 1 of 3 OK loaded seed file aaa_titanic_miguel.titanic3 ......................... [[32mCREATE 1309[0m in 4.18s]
[0m02:37:32.925209 [debug] [Thread-1 (]: Finished running node seed.titanic.titanic3
[0m02:37:32.925721 [debug] [Thread-3 (]: Began running node model.titanic.sklearn_model
[0m02:37:32.926123 [info ] [Thread-3 (]: 2 of 3 START python model model aaa_titanic_miguel.sklearn_model ............... [RUN]
[0m02:37:32.926474 [debug] [Thread-3 (]: Acquiring new snowflake connection 'model.titanic.sklearn_model'
[0m02:37:32.926706 [debug] [Thread-3 (]: Began compiling node model.titanic.sklearn_model
[0m02:37:32.944393 [debug] [Thread-3 (]: Writing injected SQL for node "model.titanic.sklearn_model"
[0m02:37:32.945016 [debug] [Thread-3 (]: Began executing node model.titanic.sklearn_model
[0m02:37:32.954064 [debug] [Thread-3 (]: Writing runtime python for node "model.titanic.sklearn_model"
[0m02:37:32.955579 [debug] [Thread-3 (]: Using snowflake connection "model.titanic.sklearn_model"
[0m02:37:32.955967 [debug] [Thread-3 (]: On model.titanic.sklearn_model: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "model.titanic.sklearn_model"} */
WITH sklearn_model__dbt_sp AS PROCEDURE ()

RETURNS STRING
LANGUAGE PYTHON
RUNTIME_VERSION = '3.11'
PACKAGES = ('snowflake-ml-python', 'pandas', 'scikit-learn', 'snowflake-snowpark-python')



HANDLER = 'main'
EXECUTE AS CALLER
AS
$$

import sys
sys._xoptions['snowflake_partner_attribution'].append("dbtLabs_dbtPython")


        


import importlib.util
if importlib.util.find_spec("snowflake.ml") is None:
    raise ImportError("snowflake.ml is not found. Add snowflake-ml-python to package dependencies.")
from snowflake.ml.registry import Registry
import datetime
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.svm import SVC
from snowflake.ml.model import model_signature


def preprocess(df: pd.DataFrame) -> pd.DataFrame:
  df = df[["PCLASS", "SEX", "AGE", "SIBSP", "PARCH", "FARE", "EMBARKED"]]
  df["PCLASS"] = pd.Categorical(df["PCLASS"], categories=[1, 2, 3])
  df["SEX"] = pd.Categorical(df["SEX"], categories=["male", "female"])
  df["EMBARKED"] = pd.Categorical(df["EMBARKED"], categories=["C", "Q", "S"])
  return pd.get_dummies(df, columns=["PCLASS", "SEX", "EMBARKED"])


def model(dbt, session):
  dbt.config(
    materialized="model",
    python_version="3.11",
    packages=["snowflake-ml-python", "pandas", "scikit-learn"],
  )

  dataset = dbt.ref("titanic3")

  data = dataset.to_pandas()

  x = preprocess(data)
  y = data["SURVIVED"]

  imputer = SimpleImputer()
  x = imputer.fit_transform(x)

  model = SVC()
  model.fit(x, y)

  return {
    "model": model,
    "signatures": {"predict": model_signature.infer_signature(x, y)},
    "version_name": datetime.datetime.today().strftime("V%Y%m%d"),
    "metrics": {"r2_score": model.score(x, y)},
    "comment": f"r2_score: {model.score(x, y)}",
    "set_default": True,
  }


# This part is user provided model code
# you will need to copy the next section to run the code
# COMMAND ----------
# this part is dbt logic for get ref work, do not modify

def ref(*args, **kwargs):
    refs = {"titanic3": "analytics.aaa_titanic_miguel.titanic3"}
    key = '.'.join(args)
    version = kwargs.get("v") or kwargs.get("version")
    if version:
        key += f".v{version}"
    dbt_load_df_function = kwargs.get("dbt_load_df_function")
    return dbt_load_df_function(refs[key])


def source(*args, dbt_load_df_function):
    sources = {}
    key = '.'.join(args)
    return dbt_load_df_function(sources[key])


config_dict = {}


class config:
    def __init__(self, *args, **kwargs):
        pass

    @staticmethod
    def get(key, default=None):
        return config_dict.get(key, default)

class this:
    """dbt.this() or dbt.this.identifier"""
    database = "analytics"
    schema = "aaa_titanic_miguel"
    identifier = "sklearn_model"
    
    def __repr__(self):
        return 'analytics.aaa_titanic_miguel.sklearn_model'


class dbtObj:
    def __init__(self, load_df_function) -> None:
        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)
        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)
        self.config = config
        self.this = this()
        self.is_incremental = False

# COMMAND ----------



def main(session):
    dbt = dbtObj(session.table)
    model_dict = model(dbt, session)
    reg = Registry(
        session = session,
        database_name = dbt.this.database,
        schema_name = dbt.this.schema
    )
    set_default = model_dict.pop("set_default", False)
    assert "model_name" not in model_dict, "model_name cannot be overridden"
    assert "conda_dependencies" not in model_dict, "conda_dependencies cannot be overridden"
    mv = reg.log_model(
        **model_dict,
        model_name = "analytics.aaa_titanic_miguel.sklearn_model",
        conda_dependencies = ['snowflake-ml-python', 'pandas', 'scikit-learn'],
    )
    if set_default:
        reg.get_model(dbt.this.identifier).default = mv
    return "OK"

$$
CALL sklearn_model__dbt_sp();
[0m02:37:32.956329 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:37:43.072504 [debug] [Thread-3 (]: Snowflake adapter: Snowflake query id: 01baeb7d-0907-ba98-0007-978308d0aad6
[0m02:37:43.073000 [debug] [Thread-3 (]: Snowflake adapter: Snowflake error: 100357 (P0000): Python Interpreter Error:
Traceback (most recent call last):
  File "_udf_code.py", line 124, in main
    mv = reg.log_model(
         ^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py", line 527, in wrap
    return ctx.run(execute_func_with_statement_params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py", line 503, in execute_func_with_statement_params
    result = func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/registry/registry.py", line 310, in log_model
    return self._model_manager.log_model(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/registry/_manager/model_manager.py", line 117, in log_model
    raise ValueError(
ValueError: Model analytics.aaa_titanic_miguel.sklearn_model version V20250310 already existed. To auto-generate `version_name`, skip that argument.
 in function SKLEARN_MODEL__DBT_SP with handler main
[0m02:37:43.076388 [debug] [Thread-3 (]: Database Error in model sklearn_model (models/sklearn_model.py)
  100357 (P0000): Python Interpreter Error:
  Traceback (most recent call last):
    File "_udf_code.py", line 124, in main
      mv = reg.log_model(
           ^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py", line 527, in wrap
      return ctx.run(execute_func_with_statement_params)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py", line 503, in execute_func_with_statement_params
      result = func(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/registry/registry.py", line 310, in log_model
      return self._model_manager.log_model(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/registry/_manager/model_manager.py", line 117, in log_model
      raise ValueError(
  ValueError: Model analytics.aaa_titanic_miguel.sklearn_model version V20250310 already existed. To auto-generate `version_name`, skip that argument.
   in function SKLEARN_MODEL__DBT_SP with handler main
  compiled code at target/run/titanic/models/sklearn_model.py
[0m02:37:43.076895 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '20493e59-8120-4705-8aa3-7ab3c524efe2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c38e030>]}
[0m02:37:43.077407 [error] [Thread-3 (]: 2 of 3 ERROR creating python model model aaa_titanic_miguel.sklearn_model ...... [[31mERROR[0m in 10.15s]
[0m02:37:43.077845 [debug] [Thread-3 (]: Finished running node model.titanic.sklearn_model
[0m02:37:43.078291 [debug] [Thread-13 ]: Marking all children of 'model.titanic.sklearn_model' to be skipped because of status 'error'.  Reason: Database Error in model sklearn_model (models/sklearn_model.py)
  100357 (P0000): Python Interpreter Error:
  Traceback (most recent call last):
    File "_udf_code.py", line 124, in main
      mv = reg.log_model(
           ^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py", line 527, in wrap
      return ctx.run(execute_func_with_statement_params)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py", line 503, in execute_func_with_statement_params
      result = func(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/registry/registry.py", line 310, in log_model
      return self._model_manager.log_model(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/registry/_manager/model_manager.py", line 117, in log_model
      raise ValueError(
  ValueError: Model analytics.aaa_titanic_miguel.sklearn_model version V20250310 already existed. To auto-generate `version_name`, skip that argument.
   in function SKLEARN_MODEL__DBT_SP with handler main
  compiled code at target/run/titanic/models/sklearn_model.py.
[0m02:37:43.079120 [debug] [Thread-5 (]: Began running node model.titanic.sklearn_predict
[0m02:37:43.079442 [info ] [Thread-5 (]: 3 of 3 SKIP relation aaa_titanic_miguel.sklearn_predict ........................ [[33mSKIP[0m]
[0m02:37:43.079766 [debug] [Thread-5 (]: Finished running node model.titanic.sklearn_predict
[0m02:37:43.079971 [debug] [Thread-13 ]: Marking all children of 'model.titanic.sklearn_predict' to be skipped because of status 'skipped'. 
[0m02:37:43.081014 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:37:43.081245 [debug] [MainThread]: Connection 'seed.titanic.titanic3' was left open.
[0m02:37:43.081445 [debug] [MainThread]: On seed.titanic.titanic3: Close
[0m02:37:43.707163 [debug] [MainThread]: Connection 'model.titanic.sklearn_model' was left open.
[0m02:37:43.707697 [debug] [MainThread]: On model.titanic.sklearn_model: Close
[0m02:37:44.388875 [info ] [MainThread]: 
[0m02:37:44.390497 [info ] [MainThread]: Finished running 1 model model, 1 seed, 1 table model in 0 hours 0 minutes and 20.94 seconds (20.94s).
[0m02:37:44.392079 [debug] [MainThread]: Command end result
[0m02:37:44.415202 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m02:37:44.417234 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m02:37:44.422842 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/migueldichoso/Downloads/Titanic/target/run_results.json
[0m02:37:44.423118 [info ] [MainThread]: 
[0m02:37:44.423416 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m02:37:44.423650 [info ] [MainThread]: 
[0m02:37:44.423958 [error] [MainThread]:   Database Error in model sklearn_model (models/sklearn_model.py)
  100357 (P0000): Python Interpreter Error:
  Traceback (most recent call last):
    File "_udf_code.py", line 124, in main
      mv = reg.log_model(
           ^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py", line 527, in wrap
      return ctx.run(execute_func_with_statement_params)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py", line 503, in execute_func_with_statement_params
      result = func(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/registry/registry.py", line 310, in log_model
      return self._model_manager.log_model(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/registry/_manager/model_manager.py", line 117, in log_model
      raise ValueError(
  ValueError: Model analytics.aaa_titanic_miguel.sklearn_model version V20250310 already existed. To auto-generate `version_name`, skip that argument.
   in function SKLEARN_MODEL__DBT_SP with handler main
  compiled code at target/run/titanic/models/sklearn_model.py
[0m02:37:44.424240 [info ] [MainThread]: 
[0m02:37:44.424446 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=1 SKIP=1 TOTAL=3
[0m02:37:44.426306 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 22.159044, "process_in_blocks": "0", "process_kernel_time": 0.463673, "process_mem_max_rss": "188661760", "process_out_blocks": "0", "process_user_time": 2.301221}
[0m02:37:44.426588 [debug] [MainThread]: Command `dbt build` failed at 02:37:44.426525 after 22.16 seconds
[0m02:37:44.426849 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106cfa1e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102feec90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ad49af0>]}
[0m02:37:44.427087 [debug] [MainThread]: Flushing usage events
[0m02:37:46.168002 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:42:50.237595 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047943b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047b6120>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047b5d60>]}


============================== 02:42:50.241306 | dc96bb07-9cbc-4e94-8feb-7ddcbc5dba22 ==============================
[0m02:42:50.241306 [info ] [MainThread]: Running with dbt=1.9.3
[0m02:42:50.241765 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/migueldichoso/Downloads/Titanic/logs', 'profiles_dir': '/Users/migueldichoso/Downloads/Titanic', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt build --full-refresh', 'send_anonymous_usage_stats': 'True'}
[0m02:42:50.858027 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dc96bb07-9cbc-4e94-8feb-7ddcbc5dba22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102a97080>]}
[0m02:42:50.892890 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'dc96bb07-9cbc-4e94-8feb-7ddcbc5dba22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082812b0>]}
[0m02:42:50.893646 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m02:42:51.004501 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m02:42:51.083759 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:42:51.084180 [debug] [MainThread]: Partial parsing: updated file: titanic://models/sklearn_model.py
[0m02:42:51.225632 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dc96bb07-9cbc-4e94-8feb-7ddcbc5dba22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10876ce00>]}
[0m02:42:51.263775 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m02:42:51.265893 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m02:42:51.289805 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dc96bb07-9cbc-4e94-8feb-7ddcbc5dba22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089c1640>]}
[0m02:42:51.290203 [info ] [MainThread]: Found 1 seed, 2 models, 480 macros
[0m02:42:51.291599 [info ] [MainThread]: 
[0m02:42:51.291871 [info ] [MainThread]: Concurrency: 10 threads (target='titanic_dev')
[0m02:42:51.292052 [info ] [MainThread]: 
[0m02:42:51.292375 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m02:42:51.295165 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_analytics'
[0m02:42:51.340725 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
[0m02:42:51.341059 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics"} */
show terse schemas in database analytics
    limit 10000
[0m02:42:51.341257 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:42:54.471621 [debug] [ThreadPool]: SQL status: SUCCESS 1757 in 3.130 seconds
[0m02:42:56.288598 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_aaa_titanic_miguel)
[0m02:42:56.295304 [debug] [ThreadPool]: Using snowflake connection "list_analytics_aaa_titanic_miguel"
[0m02:42:56.295559 [debug] [ThreadPool]: On list_analytics_aaa_titanic_miguel: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics_aaa_titanic_miguel"} */
show objects in analytics.aaa_titanic_miguel limit 10000;
[0m02:42:56.674642 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.379 seconds
[0m02:42:56.678952 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dc96bb07-9cbc-4e94-8feb-7ddcbc5dba22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085a9d60>]}
[0m02:42:56.684067 [debug] [Thread-1 (]: Began running node seed.titanic.titanic3
[0m02:42:56.684654 [info ] [Thread-1 (]: 1 of 3 START seed file aaa_titanic_miguel.titanic3 ............................. [RUN]
[0m02:42:56.685144 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_analytics_aaa_titanic_miguel, now seed.titanic.titanic3)
[0m02:42:56.685499 [debug] [Thread-1 (]: Began compiling node seed.titanic.titanic3
[0m02:42:56.685837 [debug] [Thread-1 (]: Began executing node seed.titanic.titanic3
[0m02:42:56.743604 [debug] [Thread-1 (]: Applying DROP to: "ANALYTICS"."AAA_TITANIC_MIGUEL"."TITANIC3"
[0m02:42:56.747830 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.titanic3"
[0m02:42:56.748103 [debug] [Thread-1 (]: On seed.titanic.titanic3: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.titanic3"} */
drop table if exists "ANALYTICS"."AAA_TITANIC_MIGUEL"."TITANIC3" cascade
[0m02:42:57.228584 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.480 seconds
[0m02:42:57.249711 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.titanic3"
[0m02:42:57.250109 [debug] [Thread-1 (]: On seed.titanic.titanic3: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.titanic3"} */
create table analytics.aaa_titanic_miguel.titanic3 (pclass integer,survived integer,name text,sex text,age float8,sibsp integer,parch integer,ticket text,fare float8,cabin text,embarked text,boat text,body integer,home_dest text)
[0m02:42:57.751884 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.501 seconds
[0m02:42:57.803761 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.titanic3"
[0m02:42:57.804093 [debug] [Thread-1 (]: On seed.titanic.titanic3: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.titanic3"} */
BEGIN
[0m02:42:58.161650 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.357 seconds
[0m02:42:58.397881 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.titanic3"
[0m02:42:58.398203 [debug] [Thread-1 (]: On seed.titanic.titanic3: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.titanic3"} */
insert into analytics.aaa_titanic_miguel.titanic3 (pclass, survived, name, sex, age, sibsp, parch, ticket, fare, cabin, embarked, boat, body, home_dest) values
            (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%...
[0m02:43:00.205602 [debug] [Thread-1 (]: SQL status: SUCCESS 1309 in 1.807 seconds
[0m02:43:00.207070 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.titanic3"
[0m02:43:00.207538 [debug] [Thread-1 (]: On seed.titanic.titanic3: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.titanic3"} */
COMMIT
[0m02:43:00.745192 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.537 seconds
[0m02:43:00.752368 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.titanic.titanic3"
[0m02:43:00.775266 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dc96bb07-9cbc-4e94-8feb-7ddcbc5dba22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108390e30>]}
[0m02:43:00.775683 [info ] [Thread-1 (]: 1 of 3 OK loaded seed file aaa_titanic_miguel.titanic3 ......................... [[32mCREATE 1309[0m in 4.09s]
[0m02:43:00.776063 [debug] [Thread-1 (]: Finished running node seed.titanic.titanic3
[0m02:43:00.776569 [debug] [Thread-3 (]: Began running node model.titanic.sklearn_model
[0m02:43:00.776923 [info ] [Thread-3 (]: 2 of 3 START python model model aaa_titanic_miguel.sklearn_model ............... [RUN]
[0m02:43:00.777305 [debug] [Thread-3 (]: Acquiring new snowflake connection 'model.titanic.sklearn_model'
[0m02:43:00.777526 [debug] [Thread-3 (]: Began compiling node model.titanic.sklearn_model
[0m02:43:00.794687 [debug] [Thread-3 (]: Writing injected SQL for node "model.titanic.sklearn_model"
[0m02:43:00.795288 [debug] [Thread-3 (]: Began executing node model.titanic.sklearn_model
[0m02:43:00.803920 [debug] [Thread-3 (]: Writing runtime python for node "model.titanic.sklearn_model"
[0m02:43:00.805312 [debug] [Thread-3 (]: Using snowflake connection "model.titanic.sklearn_model"
[0m02:43:00.805687 [debug] [Thread-3 (]: On model.titanic.sklearn_model: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "model.titanic.sklearn_model"} */
WITH sklearn_model__dbt_sp AS PROCEDURE ()

RETURNS STRING
LANGUAGE PYTHON
RUNTIME_VERSION = '3.11'
PACKAGES = ('snowflake-ml-python', 'pandas', 'scikit-learn', 'snowflake-snowpark-python')



HANDLER = 'main'
EXECUTE AS CALLER
AS
$$

import sys
sys._xoptions['snowflake_partner_attribution'].append("dbtLabs_dbtPython")


        


import importlib.util
if importlib.util.find_spec("snowflake.ml") is None:
    raise ImportError("snowflake.ml is not found. Add snowflake-ml-python to package dependencies.")
from snowflake.ml.registry import Registry
import datetime
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.svm import SVC
from snowflake.ml.model import model_signature


def preprocess(df: pd.DataFrame) -> pd.DataFrame:
  df = df[["PCLASS", "SEX", "AGE", "SIBSP", "PARCH", "FARE", "EMBARKED"]]
  df["PCLASS"] = pd.Categorical(df["PCLASS"], categories=[1, 2, 3])
  df["SEX"] = pd.Categorical(df["SEX"], categories=["male", "female"])
  df["EMBARKED"] = pd.Categorical(df["EMBARKED"], categories=["C", "Q", "S"])
  return pd.get_dummies(df, columns=["PCLASS", "SEX", "EMBARKED"])


def model(dbt, session):
  dbt.config(
    materialized="model",
    python_version="3.11",
    packages=["snowflake-ml-python", "pandas", "scikit-learn"],
  )

  dataset = dbt.ref("titanic3")

  data = dataset.to_pandas()

  x = preprocess(data)
  y = data["SURVIVED"]

  imputer = SimpleImputer()
  x = imputer.fit_transform(x)

  model = SVC()
  model.fit(x, y)

  return {
    "model": model,
    "signatures": {"predict": model_signature.infer_signature(x, y)},
    "version_name": datetime.datetime.today().strftime("V%Y%m%d%s"),
    "metrics": {"r2_score": model.score(x, y)},
    "comment": f"r2_score: {model.score(x, y)}",
    "set_default": True,
  }


# This part is user provided model code
# you will need to copy the next section to run the code
# COMMAND ----------
# this part is dbt logic for get ref work, do not modify

def ref(*args, **kwargs):
    refs = {"titanic3": "analytics.aaa_titanic_miguel.titanic3"}
    key = '.'.join(args)
    version = kwargs.get("v") or kwargs.get("version")
    if version:
        key += f".v{version}"
    dbt_load_df_function = kwargs.get("dbt_load_df_function")
    return dbt_load_df_function(refs[key])


def source(*args, dbt_load_df_function):
    sources = {}
    key = '.'.join(args)
    return dbt_load_df_function(sources[key])


config_dict = {}


class config:
    def __init__(self, *args, **kwargs):
        pass

    @staticmethod
    def get(key, default=None):
        return config_dict.get(key, default)

class this:
    """dbt.this() or dbt.this.identifier"""
    database = "analytics"
    schema = "aaa_titanic_miguel"
    identifier = "sklearn_model"
    
    def __repr__(self):
        return 'analytics.aaa_titanic_miguel.sklearn_model'


class dbtObj:
    def __init__(self, load_df_function) -> None:
        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)
        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)
        self.config = config
        self.this = this()
        self.is_incremental = False

# COMMAND ----------



def main(session):
    dbt = dbtObj(session.table)
    model_dict = model(dbt, session)
    reg = Registry(
        session = session,
        database_name = dbt.this.database,
        schema_name = dbt.this.schema
    )
    set_default = model_dict.pop("set_default", False)
    assert "model_name" not in model_dict, "model_name cannot be overridden"
    assert "conda_dependencies" not in model_dict, "conda_dependencies cannot be overridden"
    mv = reg.log_model(
        **model_dict,
        model_name = "analytics.aaa_titanic_miguel.sklearn_model",
        conda_dependencies = ['snowflake-ml-python', 'pandas', 'scikit-learn'],
    )
    if set_default:
        reg.get_model(dbt.this.identifier).default = mv
    return "OK"

$$
CALL sklearn_model__dbt_sp();
[0m02:43:00.806031 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:43:42.728722 [debug] [Thread-3 (]: SQL status: SUCCESS 1 in 41.923 seconds
[0m02:43:42.733875 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dc96bb07-9cbc-4e94-8feb-7ddcbc5dba22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093be5d0>]}
[0m02:43:42.735051 [info ] [Thread-3 (]: 2 of 3 OK created python model model aaa_titanic_miguel.sklearn_model .......... [[32mSUCCESS 1[0m in 41.96s]
[0m02:43:42.735798 [debug] [Thread-3 (]: Finished running node model.titanic.sklearn_model
[0m02:43:42.736775 [debug] [Thread-5 (]: Began running node model.titanic.sklearn_predict
[0m02:43:42.737444 [info ] [Thread-5 (]: 3 of 3 START python table model aaa_titanic_miguel.sklearn_predict ............. [RUN]
[0m02:43:42.738112 [debug] [Thread-5 (]: Acquiring new snowflake connection 'model.titanic.sklearn_predict'
[0m02:43:42.738559 [debug] [Thread-5 (]: Began compiling node model.titanic.sklearn_predict
[0m02:43:42.742857 [debug] [Thread-5 (]: Writing injected SQL for node "model.titanic.sklearn_predict"
[0m02:43:42.744128 [debug] [Thread-5 (]: Began executing node model.titanic.sklearn_predict
[0m02:43:42.767002 [debug] [Thread-5 (]: Writing runtime python for node "model.titanic.sklearn_predict"
[0m02:43:42.768839 [debug] [Thread-5 (]: Using snowflake connection "model.titanic.sklearn_predict"
[0m02:43:42.769344 [debug] [Thread-5 (]: On model.titanic.sklearn_predict: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "model.titanic.sklearn_predict"} */
WITH sklearn_predict__dbt_sp AS PROCEDURE ()

RETURNS STRING
LANGUAGE PYTHON
RUNTIME_VERSION = '3.11'
PACKAGES = ('snowflake-ml-python', 'pandas', 'scikit-learn', 'snowflake-snowpark-python')



HANDLER = 'main'
EXECUTE AS CALLER
AS
$$

import sys
sys._xoptions['snowflake_partner_attribution'].append("dbtLabs_dbtPython")


  
    
    
import pandas as pd
from sklearn.impute import SimpleImputer
from snowflake.ml.registry import registry


def preprocess(df: pd.DataFrame) -> pd.DataFrame:
  df = df[["PCLASS", "SEX", "AGE", "SIBSP", "PARCH", "FARE", "EMBARKED"]]
  df["PCLASS"] = pd.Categorical(df["PCLASS"], categories=[1, 2, 3])
  df["SEX"] = pd.Categorical(df["SEX"], categories=["male", "female"])
  df["EMBARKED"] = pd.Categorical(df["EMBARKED"], categories=["C", "Q", "S"])
  return pd.get_dummies(df, columns=["PCLASS", "SEX", "EMBARKED"])


def model(dbt, session):
  dbt.config(
    materialized="table",
    python_version="3.11",
    packages=["snowflake-ml-python", "pandas", "scikit-learn"],
  )

  dataset = dbt.ref("titanic3")

  data = dataset.to_pandas()

  x = preprocess(data)

  imputer = SimpleImputer()
  x = imputer.fit_transform(x)

  reg = registry.Registry(session=session)

  model_ref = dbt.ref("sklearn_model")
  mv = reg.get_model(model_ref.table_name).default
  data["PREDICTED"] = mv.run(x, function_name="PREDICT")

  return data


# This part is user provided model code
# you will need to copy the next section to run the code
# COMMAND ----------
# this part is dbt logic for get ref work, do not modify

def ref(*args, **kwargs):
    refs = {"sklearn_model": "analytics.aaa_titanic_miguel.sklearn_model", "titanic3": "analytics.aaa_titanic_miguel.titanic3"}
    key = '.'.join(args)
    version = kwargs.get("v") or kwargs.get("version")
    if version:
        key += f".v{version}"
    dbt_load_df_function = kwargs.get("dbt_load_df_function")
    return dbt_load_df_function(refs[key])


def source(*args, dbt_load_df_function):
    sources = {}
    key = '.'.join(args)
    return dbt_load_df_function(sources[key])


config_dict = {}


class config:
    def __init__(self, *args, **kwargs):
        pass

    @staticmethod
    def get(key, default=None):
        return config_dict.get(key, default)

class this:
    """dbt.this() or dbt.this.identifier"""
    database = "analytics"
    schema = "aaa_titanic_miguel"
    identifier = "sklearn_predict"
    
    def __repr__(self):
        return 'analytics.aaa_titanic_miguel.sklearn_predict'


class dbtObj:
    def __init__(self, load_df_function) -> None:
        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)
        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)
        self.config = config
        self.this = this()
        self.is_incremental = False

# COMMAND ----------



def materialize(session, df, target_relation):
    # make sure pandas exists
    import importlib.util
    package_name = 'pandas'
    if importlib.util.find_spec(package_name):
        import pandas
        if isinstance(df, pandas.core.frame.DataFrame):
          session.use_database(target_relation.database)
          session.use_schema(target_relation.schema)
          # session.write_pandas does not have overwrite function
          df = session.createDataFrame(df)
    
    df.write.mode("overwrite").save_as_table('analytics.aaa_titanic_miguel.sklearn_predict', table_type='transient')

def main(session):
    dbt = dbtObj(session.table)
    df = model(dbt, session)
    materialize(session, df, dbt.this)
    return "OK"

  
$$
CALL sklearn_predict__dbt_sp();
[0m02:43:42.769836 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m02:43:58.807589 [debug] [Thread-5 (]: SQL status: SUCCESS 1 in 16.038 seconds
[0m02:43:58.812695 [debug] [Thread-5 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dc96bb07-9cbc-4e94-8feb-7ddcbc5dba22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096074d0>]}
[0m02:43:58.813559 [info ] [Thread-5 (]: 3 of 3 OK created python table model aaa_titanic_miguel.sklearn_predict ........ [[32mSUCCESS 1[0m in 16.07s]
[0m02:43:58.814188 [debug] [Thread-5 (]: Finished running node model.titanic.sklearn_predict
[0m02:43:58.815775 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:43:58.816127 [debug] [MainThread]: Connection 'seed.titanic.titanic3' was left open.
[0m02:43:58.816426 [debug] [MainThread]: On seed.titanic.titanic3: Close
[0m02:43:59.427725 [debug] [MainThread]: Connection 'model.titanic.sklearn_model' was left open.
[0m02:43:59.428329 [debug] [MainThread]: On model.titanic.sklearn_model: Close
[0m02:44:00.129944 [debug] [MainThread]: Connection 'model.titanic.sklearn_predict' was left open.
[0m02:44:00.130914 [debug] [MainThread]: On model.titanic.sklearn_predict: Close
[0m02:44:00.735082 [info ] [MainThread]: 
[0m02:44:00.735784 [info ] [MainThread]: Finished running 1 model model, 1 seed, 1 table model in 0 hours 1 minutes and 9.44 seconds (69.44s).
[0m02:44:00.736761 [debug] [MainThread]: Command end result
[0m02:44:00.754760 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m02:44:00.756378 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m02:44:00.761231 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/migueldichoso/Downloads/Titanic/target/run_results.json
[0m02:44:00.761477 [info ] [MainThread]: 
[0m02:44:00.761754 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:44:00.761939 [info ] [MainThread]: 
[0m02:44:00.762130 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m02:44:00.763871 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 70.59961, "process_in_blocks": "0", "process_kernel_time": 0.435448, "process_mem_max_rss": "194707456", "process_out_blocks": "0", "process_user_time": 2.394326}
[0m02:44:00.764194 [debug] [MainThread]: Command `dbt build` succeeded at 02:44:00.764127 after 70.60 seconds
[0m02:44:00.764451 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047b5ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1040dc8f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10722c4d0>]}
[0m02:44:00.764678 [debug] [MainThread]: Flushing usage events
[0m02:44:02.595035 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:50:52.619350 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1044dec30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1049ce090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1049cdca0>]}


============================== 02:50:52.624077 | 1929722f-48a6-46c5-88c1-4126df02036c ==============================
[0m02:50:52.624077 [info ] [MainThread]: Running with dbt=1.9.3
[0m02:50:52.624580 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/migueldichoso/Downloads/Titanic', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/migueldichoso/Downloads/Titanic/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt build --full-refresh', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:50:53.291976 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1929722f-48a6-46c5-88c1-4126df02036c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105730ad0>]}
[0m02:50:53.327873 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1929722f-48a6-46c5-88c1-4126df02036c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10846af90>]}
[0m02:50:53.328680 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m02:50:53.438405 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m02:50:53.514044 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m02:50:53.514353 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m02:50:53.536701 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1929722f-48a6-46c5-88c1-4126df02036c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10860b140>]}
[0m02:50:53.576880 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m02:50:53.579281 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m02:50:53.606580 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1929722f-48a6-46c5-88c1-4126df02036c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108a27f20>]}
[0m02:50:53.606985 [info ] [MainThread]: Found 1 seed, 2 models, 480 macros
[0m02:50:53.608547 [info ] [MainThread]: 
[0m02:50:53.608810 [info ] [MainThread]: Concurrency: 10 threads (target='titanic_dev')
[0m02:50:53.608989 [info ] [MainThread]: 
[0m02:50:53.609314 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m02:50:53.612195 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_analytics'
[0m02:50:53.658524 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
[0m02:50:53.658885 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics"} */
show terse schemas in database analytics
    limit 10000
[0m02:50:53.659102 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:50:56.615797 [debug] [ThreadPool]: SQL status: SUCCESS 1757 in 2.957 seconds
[0m02:50:58.496457 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_aaa_titanic_miguel)
[0m02:50:58.504059 [debug] [ThreadPool]: Using snowflake connection "list_analytics_aaa_titanic_miguel"
[0m02:50:58.504339 [debug] [ThreadPool]: On list_analytics_aaa_titanic_miguel: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics_aaa_titanic_miguel"} */
show objects in analytics.aaa_titanic_miguel limit 10000;
[0m02:50:58.850056 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 0.345 seconds
[0m02:50:58.855309 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1929722f-48a6-46c5-88c1-4126df02036c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f857c0>]}
[0m02:50:58.860126 [debug] [Thread-1 (]: Began running node seed.titanic.titanic3
[0m02:50:58.860801 [info ] [Thread-1 (]: 1 of 3 START seed file aaa_titanic_miguel.titanic3 ............................. [RUN]
[0m02:50:58.861312 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_analytics_aaa_titanic_miguel, now seed.titanic.titanic3)
[0m02:50:58.861697 [debug] [Thread-1 (]: Began compiling node seed.titanic.titanic3
[0m02:50:58.862041 [debug] [Thread-1 (]: Began executing node seed.titanic.titanic3
[0m02:50:58.920041 [debug] [Thread-1 (]: Applying DROP to: "ANALYTICS"."AAA_TITANIC_MIGUEL"."TITANIC3"
[0m02:50:58.924088 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.titanic3"
[0m02:50:58.924342 [debug] [Thread-1 (]: On seed.titanic.titanic3: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.titanic3"} */
drop table if exists "ANALYTICS"."AAA_TITANIC_MIGUEL"."TITANIC3" cascade
[0m02:50:59.384470 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.460 seconds
[0m02:50:59.407455 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.titanic3"
[0m02:50:59.407881 [debug] [Thread-1 (]: On seed.titanic.titanic3: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.titanic3"} */
create table analytics.aaa_titanic_miguel.titanic3 (pclass integer,survived integer,name text,sex text,age float8,sibsp integer,parch integer,ticket text,fare float8,cabin text,embarked text,boat text,body integer,home_dest text)
[0m02:50:59.858366 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.450 seconds
[0m02:50:59.907106 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.titanic3"
[0m02:50:59.907384 [debug] [Thread-1 (]: On seed.titanic.titanic3: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.titanic3"} */
BEGIN
[0m02:51:00.273211 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.365 seconds
[0m02:51:00.498785 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.titanic3"
[0m02:51:00.499105 [debug] [Thread-1 (]: On seed.titanic.titanic3: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.titanic3"} */
insert into analytics.aaa_titanic_miguel.titanic3 (pclass, survived, name, sex, age, sibsp, parch, ticket, fare, cabin, embarked, boat, body, home_dest) values
            (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%...
[0m02:51:02.134278 [debug] [Thread-1 (]: SQL status: SUCCESS 1309 in 1.635 seconds
[0m02:51:02.137036 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.titanic3"
[0m02:51:02.137557 [debug] [Thread-1 (]: On seed.titanic.titanic3: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.titanic3"} */
COMMIT
[0m02:51:02.735808 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.598 seconds
[0m02:51:02.745988 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.titanic.titanic3"
[0m02:51:02.773317 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1929722f-48a6-46c5-88c1-4126df02036c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102cae0c0>]}
[0m02:51:02.773768 [info ] [Thread-1 (]: 1 of 3 OK loaded seed file aaa_titanic_miguel.titanic3 ......................... [[32mCREATE 1309[0m in 3.91s]
[0m02:51:02.774166 [debug] [Thread-1 (]: Finished running node seed.titanic.titanic3
[0m02:51:02.774909 [debug] [Thread-3 (]: Began running node model.titanic.sklearn_model
[0m02:51:02.775582 [info ] [Thread-3 (]: 2 of 3 START python model model aaa_titanic_miguel.sklearn_model ............... [RUN]
[0m02:51:02.776127 [debug] [Thread-3 (]: Acquiring new snowflake connection 'model.titanic.sklearn_model'
[0m02:51:02.776363 [debug] [Thread-3 (]: Began compiling node model.titanic.sklearn_model
[0m02:51:02.794032 [debug] [Thread-3 (]: Writing injected SQL for node "model.titanic.sklearn_model"
[0m02:51:02.794578 [debug] [Thread-3 (]: Began executing node model.titanic.sklearn_model
[0m02:51:02.804080 [debug] [Thread-3 (]: Writing runtime python for node "model.titanic.sklearn_model"
[0m02:51:02.805439 [debug] [Thread-3 (]: Using snowflake connection "model.titanic.sklearn_model"
[0m02:51:02.805805 [debug] [Thread-3 (]: On model.titanic.sklearn_model: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "model.titanic.sklearn_model"} */
WITH sklearn_model__dbt_sp AS PROCEDURE ()

RETURNS STRING
LANGUAGE PYTHON
RUNTIME_VERSION = '3.11'
PACKAGES = ('snowflake-ml-python', 'pandas', 'scikit-learn', 'snowflake-snowpark-python')



HANDLER = 'main'
EXECUTE AS CALLER
AS
$$

import sys
sys._xoptions['snowflake_partner_attribution'].append("dbtLabs_dbtPython")


        


import importlib.util
if importlib.util.find_spec("snowflake.ml") is None:
    raise ImportError("snowflake.ml is not found. Add snowflake-ml-python to package dependencies.")
from snowflake.ml.registry import Registry
import datetime
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.svm import SVC
from snowflake.ml.model import model_signature


def preprocess(df: pd.DataFrame) -> pd.DataFrame:
  df = df[["PCLASS", "SEX", "AGE", "SIBSP", "PARCH", "FARE", "EMBARKED"]]
  df["PCLASS"] = pd.Categorical(df["PCLASS"], categories=[1, 2, 3])
  df["SEX"] = pd.Categorical(df["SEX"], categories=["male", "female"])
  df["EMBARKED"] = pd.Categorical(df["EMBARKED"], categories=["C", "Q", "S"])
  return pd.get_dummies(df, columns=["PCLASS", "SEX", "EMBARKED"])


def model(dbt, session):
  dbt.config(
    materialized="model",
    python_version="3.11",
    packages=["snowflake-ml-python", "pandas", "scikit-learn"],
  )

  dataset = dbt.ref("titanic3")

  data = dataset.to_pandas()

  x = preprocess(data)
  y = data["SURVIVED"]

  imputer = SimpleImputer()
  x = imputer.fit_transform(x)

  model = SVC()
  model.fit(x, y)

  return {
    "model": model,
    "signatures": {"predict": model_signature.infer_signature(x, y)},
    "version_name": datetime.datetime.today().strftime("V%Y%m%d%s"),
    "metrics": {"r2_score": model.score(x, y)},
    "comment": f"r2_score: {model.score(x, y)}",
    "set_default": True,
  }


# This part is user provided model code
# you will need to copy the next section to run the code
# COMMAND ----------
# this part is dbt logic for get ref work, do not modify

def ref(*args, **kwargs):
    refs = {"titanic3": "analytics.aaa_titanic_miguel.titanic3"}
    key = '.'.join(args)
    version = kwargs.get("v") or kwargs.get("version")
    if version:
        key += f".v{version}"
    dbt_load_df_function = kwargs.get("dbt_load_df_function")
    return dbt_load_df_function(refs[key])


def source(*args, dbt_load_df_function):
    sources = {}
    key = '.'.join(args)
    return dbt_load_df_function(sources[key])


config_dict = {}


class config:
    def __init__(self, *args, **kwargs):
        pass

    @staticmethod
    def get(key, default=None):
        return config_dict.get(key, default)

class this:
    """dbt.this() or dbt.this.identifier"""
    database = "analytics"
    schema = "aaa_titanic_miguel"
    identifier = "sklearn_model"
    
    def __repr__(self):
        return 'analytics.aaa_titanic_miguel.sklearn_model'


class dbtObj:
    def __init__(self, load_df_function) -> None:
        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)
        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)
        self.config = config
        self.this = this()
        self.is_incremental = False

# COMMAND ----------



def main(session):
    dbt = dbtObj(session.table)
    model_dict = model(dbt, session)
    reg = Registry(
        session = session,
        database_name = dbt.this.database,
        schema_name = dbt.this.schema
    )
    set_default = model_dict.pop("set_default", False)
    assert "model_name" not in model_dict, "model_name cannot be overridden"
    assert "conda_dependencies" not in model_dict, "conda_dependencies cannot be overridden"
    mv = reg.log_model(
        **model_dict,
        model_name = "analytics.aaa_titanic_miguel.sklearn_model",
        conda_dependencies = ['snowflake-ml-python', 'pandas', 'scikit-learn'],
    )
    if set_default:
        reg.get_model(dbt.this.identifier).default = mv
    return "OK"

$$
CALL sklearn_model__dbt_sp();
[0m02:51:02.806390 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:51:22.442433 [debug] [Thread-3 (]: SQL status: SUCCESS 1 in 19.636 seconds
[0m02:51:22.447559 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1929722f-48a6-46c5-88c1-4126df02036c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f24cb30>]}
[0m02:51:22.448552 [info ] [Thread-3 (]: 2 of 3 OK created python model model aaa_titanic_miguel.sklearn_model .......... [[32mSUCCESS 1[0m in 19.67s]
[0m02:51:22.449268 [debug] [Thread-3 (]: Finished running node model.titanic.sklearn_model
[0m02:51:22.450139 [debug] [Thread-5 (]: Began running node model.titanic.sklearn_predict
[0m02:51:22.450655 [info ] [Thread-5 (]: 3 of 3 START python table model aaa_titanic_miguel.sklearn_predict ............. [RUN]
[0m02:51:22.451153 [debug] [Thread-5 (]: Acquiring new snowflake connection 'model.titanic.sklearn_predict'
[0m02:51:22.451474 [debug] [Thread-5 (]: Began compiling node model.titanic.sklearn_predict
[0m02:51:22.455966 [debug] [Thread-5 (]: Writing injected SQL for node "model.titanic.sklearn_predict"
[0m02:51:22.458826 [debug] [Thread-5 (]: Began executing node model.titanic.sklearn_predict
[0m02:51:22.479968 [debug] [Thread-5 (]: Writing runtime python for node "model.titanic.sklearn_predict"
[0m02:51:22.481719 [debug] [Thread-5 (]: Using snowflake connection "model.titanic.sklearn_predict"
[0m02:51:22.482106 [debug] [Thread-5 (]: On model.titanic.sklearn_predict: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "model.titanic.sklearn_predict"} */
WITH sklearn_predict__dbt_sp AS PROCEDURE ()

RETURNS STRING
LANGUAGE PYTHON
RUNTIME_VERSION = '3.11'
PACKAGES = ('snowflake-ml-python', 'pandas', 'scikit-learn', 'snowflake-snowpark-python')



HANDLER = 'main'
EXECUTE AS CALLER
AS
$$

import sys
sys._xoptions['snowflake_partner_attribution'].append("dbtLabs_dbtPython")


  
    
    
import pandas as pd
from sklearn.impute import SimpleImputer
from snowflake.ml.registry import registry


def preprocess(df: pd.DataFrame) -> pd.DataFrame:
  df = df[["PCLASS", "SEX", "AGE", "SIBSP", "PARCH", "FARE", "EMBARKED"]]
  df["PCLASS"] = pd.Categorical(df["PCLASS"], categories=[1, 2, 3])
  df["SEX"] = pd.Categorical(df["SEX"], categories=["male", "female"])
  df["EMBARKED"] = pd.Categorical(df["EMBARKED"], categories=["C", "Q", "S"])
  return pd.get_dummies(df, columns=["PCLASS", "SEX", "EMBARKED"])


def model(dbt, session):
  dbt.config(
    materialized="table",
    python_version="3.11",
    packages=["snowflake-ml-python", "pandas", "scikit-learn"],
  )

  dataset = dbt.ref("titanic3")

  data = dataset.to_pandas()

  x = preprocess(data)

  imputer = SimpleImputer()
  x = imputer.fit_transform(x)

  reg = registry.Registry(session=session)

  model_ref = dbt.ref("sklearn_model")
  mv = reg.get_model(model_ref.table_name).default
  data["PREDICTED"] = mv.run(x, function_name="PREDICT")

  return data


# This part is user provided model code
# you will need to copy the next section to run the code
# COMMAND ----------
# this part is dbt logic for get ref work, do not modify

def ref(*args, **kwargs):
    refs = {"sklearn_model": "analytics.aaa_titanic_miguel.sklearn_model", "titanic3": "analytics.aaa_titanic_miguel.titanic3"}
    key = '.'.join(args)
    version = kwargs.get("v") or kwargs.get("version")
    if version:
        key += f".v{version}"
    dbt_load_df_function = kwargs.get("dbt_load_df_function")
    return dbt_load_df_function(refs[key])


def source(*args, dbt_load_df_function):
    sources = {}
    key = '.'.join(args)
    return dbt_load_df_function(sources[key])


config_dict = {}


class config:
    def __init__(self, *args, **kwargs):
        pass

    @staticmethod
    def get(key, default=None):
        return config_dict.get(key, default)

class this:
    """dbt.this() or dbt.this.identifier"""
    database = "analytics"
    schema = "aaa_titanic_miguel"
    identifier = "sklearn_predict"
    
    def __repr__(self):
        return 'analytics.aaa_titanic_miguel.sklearn_predict'


class dbtObj:
    def __init__(self, load_df_function) -> None:
        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)
        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)
        self.config = config
        self.this = this()
        self.is_incremental = False

# COMMAND ----------



def materialize(session, df, target_relation):
    # make sure pandas exists
    import importlib.util
    package_name = 'pandas'
    if importlib.util.find_spec(package_name):
        import pandas
        if isinstance(df, pandas.core.frame.DataFrame):
          session.use_database(target_relation.database)
          session.use_schema(target_relation.schema)
          # session.write_pandas does not have overwrite function
          df = session.createDataFrame(df)
    
    df.write.mode("overwrite").save_as_table('analytics.aaa_titanic_miguel.sklearn_predict', table_type='transient')

def main(session):
    dbt = dbtObj(session.table)
    df = model(dbt, session)
    materialize(session, df, dbt.this)
    return "OK"

  
$$
CALL sklearn_predict__dbt_sp();
[0m02:51:22.482440 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m02:51:40.735386 [debug] [Thread-5 (]: SQL status: SUCCESS 1 in 18.253 seconds
[0m02:51:40.741389 [debug] [Thread-5 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1929722f-48a6-46c5-88c1-4126df02036c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f126240>]}
[0m02:51:40.742648 [info ] [Thread-5 (]: 3 of 3 OK created python table model aaa_titanic_miguel.sklearn_predict ........ [[32mSUCCESS 1[0m in 18.29s]
[0m02:51:40.743377 [debug] [Thread-5 (]: Finished running node model.titanic.sklearn_predict
[0m02:51:40.745306 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:51:40.745623 [debug] [MainThread]: Connection 'seed.titanic.titanic3' was left open.
[0m02:51:40.745909 [debug] [MainThread]: On seed.titanic.titanic3: Close
[0m02:51:41.343117 [debug] [MainThread]: Connection 'model.titanic.sklearn_model' was left open.
[0m02:51:41.343803 [debug] [MainThread]: On model.titanic.sklearn_model: Close
[0m02:51:41.974284 [debug] [MainThread]: Connection 'model.titanic.sklearn_predict' was left open.
[0m02:51:41.974818 [debug] [MainThread]: On model.titanic.sklearn_predict: Close
[0m02:51:42.580893 [info ] [MainThread]: 
[0m02:51:42.581786 [info ] [MainThread]: Finished running 1 model model, 1 seed, 1 table model in 0 hours 0 minutes and 48.97 seconds (48.97s).
[0m02:51:42.583359 [debug] [MainThread]: Command end result
[0m02:51:42.606748 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m02:51:42.608339 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m02:51:42.612823 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/migueldichoso/Downloads/Titanic/target/run_results.json
[0m02:51:42.613072 [info ] [MainThread]: 
[0m02:51:42.613381 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:51:42.613589 [info ] [MainThread]: 
[0m02:51:42.613809 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m02:51:42.615796 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 50.076214, "process_in_blocks": "0", "process_kernel_time": 0.454074, "process_mem_max_rss": "186187776", "process_out_blocks": "0", "process_user_time": 2.330308}
[0m02:51:42.616101 [debug] [MainThread]: Command `dbt build` succeeded at 02:51:42.616037 after 50.08 seconds
[0m02:51:42.616376 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1049cd640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102d93b30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100c92c90>]}
[0m02:51:42.616630 [debug] [MainThread]: Flushing usage events
[0m02:51:45.943219 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:58:58.935204 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f2e870>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107081fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107081be0>]}


============================== 02:58:58.939001 | a3817ccf-c0c5-41c8-bc54-edced2172d5d ==============================
[0m02:58:58.939001 [info ] [MainThread]: Running with dbt=1.9.3
[0m02:58:58.939431 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/migueldichoso/Downloads/Titanic', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/migueldichoso/Downloads/Titanic/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt seed -s train_data', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:58:59.557887 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a3817ccf-c0c5-41c8-bc54-edced2172d5d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11007de20>]}
[0m02:58:59.592104 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a3817ccf-c0c5-41c8-bc54-edced2172d5d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a28860>]}
[0m02:58:59.592823 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m02:58:59.705233 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m02:58:59.779691 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 2 files added, 0 files changed.
[0m02:58:59.780061 [debug] [MainThread]: Partial parsing: added file: titanic://models/train.py
[0m02:58:59.780281 [debug] [MainThread]: Partial parsing: added file: titanic://seeds/train_data.csv
[0m02:58:59.995488 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a3817ccf-c0c5-41c8-bc54-edced2172d5d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113f35b50>]}
[0m02:59:00.034457 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m02:59:00.036791 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m02:59:00.050982 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a3817ccf-c0c5-41c8-bc54-edced2172d5d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11499cb00>]}
[0m02:59:00.051288 [info ] [MainThread]: Found 2 seeds, 3 models, 480 macros
[0m02:59:00.051506 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a3817ccf-c0c5-41c8-bc54-edced2172d5d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1149beba0>]}
[0m02:59:00.052471 [info ] [MainThread]: 
[0m02:59:00.052705 [info ] [MainThread]: Concurrency: 10 threads (target='titanic_dev')
[0m02:59:00.052870 [info ] [MainThread]: 
[0m02:59:00.053173 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m02:59:00.053825 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_analytics'
[0m02:59:00.098829 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
[0m02:59:00.099150 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics"} */
show terse schemas in database analytics
    limit 10000
[0m02:59:00.099348 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:59:03.408525 [debug] [ThreadPool]: SQL status: SUCCESS 1757 in 3.309 seconds
[0m02:59:05.346099 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_aaa_titanic_miguel)
[0m02:59:05.353082 [debug] [ThreadPool]: Using snowflake connection "list_analytics_aaa_titanic_miguel"
[0m02:59:05.353346 [debug] [ThreadPool]: On list_analytics_aaa_titanic_miguel: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics_aaa_titanic_miguel"} */
show objects in analytics.aaa_titanic_miguel limit 10000;
[0m02:59:05.746880 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 0.393 seconds
[0m02:59:05.751752 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a3817ccf-c0c5-41c8-bc54-edced2172d5d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1149beba0>]}
[0m02:59:05.756588 [debug] [Thread-1 (]: Began running node seed.titanic.train_data
[0m02:59:05.757231 [info ] [Thread-1 (]: 1 of 1 START seed file aaa_titanic_miguel.train_data ........................... [RUN]
[0m02:59:05.757751 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_analytics_aaa_titanic_miguel, now seed.titanic.train_data)
[0m02:59:05.758119 [debug] [Thread-1 (]: Began compiling node seed.titanic.train_data
[0m02:59:05.758482 [debug] [Thread-1 (]: Began executing node seed.titanic.train_data
[0m02:59:05.791899 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.train_data"
[0m02:59:05.792206 [debug] [Thread-1 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
create table analytics.aaa_titanic_miguel.train_data (customer_id integer,age integer,monthly_expenses float8,attrition text)
[0m02:59:06.228183 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.435 seconds
[0m02:59:06.251174 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.train_data"
[0m02:59:06.251638 [debug] [Thread-1 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
BEGIN
[0m02:59:06.906445 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.654 seconds
[0m02:59:06.916506 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.train_data"
[0m02:59:06.916989 [debug] [Thread-1 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
insert into analytics.aaa_titanic_miguel.train_data (customer_id, age, monthly_expenses, attrition) values
            (%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(...
[0m02:59:08.092715 [debug] [Thread-1 (]: SQL status: SUCCESS 405 in 1.175 seconds
[0m02:59:08.093913 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.train_data"
[0m02:59:08.094384 [debug] [Thread-1 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
COMMIT
[0m02:59:08.635905 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.541 seconds
[0m02:59:08.645103 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.titanic.train_data"
[0m02:59:08.672192 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3817ccf-c0c5-41c8-bc54-edced2172d5d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115f1f590>]}
[0m02:59:08.672664 [info ] [Thread-1 (]: 1 of 1 OK loaded seed file aaa_titanic_miguel.train_data ....................... [[32mINSERT 405[0m in 2.91s]
[0m02:59:08.673085 [debug] [Thread-1 (]: Finished running node seed.titanic.train_data
[0m02:59:08.674216 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:59:08.674475 [debug] [MainThread]: Connection 'seed.titanic.train_data' was left open.
[0m02:59:08.674691 [debug] [MainThread]: On seed.titanic.train_data: Close
[0m02:59:09.312403 [info ] [MainThread]: 
[0m02:59:09.313077 [info ] [MainThread]: Finished running 1 seed in 0 hours 0 minutes and 9.26 seconds (9.26s).
[0m02:59:09.313998 [debug] [MainThread]: Command end result
[0m02:59:09.330069 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m02:59:09.331472 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m02:59:09.335395 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/migueldichoso/Downloads/Titanic/target/run_results.json
[0m02:59:09.335660 [info ] [MainThread]: 
[0m02:59:09.335915 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:59:09.336093 [info ] [MainThread]: 
[0m02:59:09.336278 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m02:59:09.338073 [debug] [MainThread]: Resource report: {"command_name": "seed", "command_success": true, "command_wall_clock_time": 10.475601, "process_in_blocks": "0", "process_kernel_time": 0.420063, "process_mem_max_rss": "184664064", "process_out_blocks": "0", "process_user_time": 1.90909}
[0m02:59:09.338478 [debug] [MainThread]: Command `dbt seed` succeeded at 02:59:09.338402 after 10.48 seconds
[0m02:59:09.338773 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065ae2a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106dfc950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113c676e0>]}
[0m02:59:09.339034 [debug] [MainThread]: Flushing usage events
[0m02:59:11.065637 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:01:35.190643 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112269f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11227e060>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11227dbb0>]}


============================== 03:01:35.194761 | 9e14f0b2-55d3-4ea7-aa1c-7eb6a9606e29 ==============================
[0m03:01:35.194761 [info ] [MainThread]: Running with dbt=1.9.3
[0m03:01:35.195210 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/migueldichoso/Downloads/Titanic', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/migueldichoso/Downloads/Titanic/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt build -s train', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m03:01:35.815631 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9e14f0b2-55d3-4ea7-aa1c-7eb6a9606e29', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116c40560>]}
[0m03:01:35.850432 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9e14f0b2-55d3-4ea7-aa1c-7eb6a9606e29', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116c40560>]}
[0m03:01:35.851180 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m03:01:35.963132 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m03:01:36.038191 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m03:01:36.038479 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m03:01:36.060491 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9e14f0b2-55d3-4ea7-aa1c-7eb6a9606e29', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115880e30>]}
[0m03:01:36.100443 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m03:01:36.102765 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m03:01:36.126112 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9e14f0b2-55d3-4ea7-aa1c-7eb6a9606e29', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11754c140>]}
[0m03:01:36.126464 [info ] [MainThread]: Found 2 seeds, 3 models, 480 macros
[0m03:01:36.127582 [info ] [MainThread]: 
[0m03:01:36.127822 [info ] [MainThread]: Concurrency: 10 threads (target='titanic_dev')
[0m03:01:36.127993 [info ] [MainThread]: 
[0m03:01:36.128299 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m03:01:36.128832 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_analytics'
[0m03:01:36.174645 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
[0m03:01:36.174998 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics"} */
show terse schemas in database analytics
    limit 10000
[0m03:01:36.175273 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:01:41.289871 [debug] [ThreadPool]: SQL status: SUCCESS 1757 in 5.114 seconds
[0m03:01:42.809298 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_aaa_titanic_miguel)
[0m03:01:42.815815 [debug] [ThreadPool]: Using snowflake connection "list_analytics_aaa_titanic_miguel"
[0m03:01:42.816045 [debug] [ThreadPool]: On list_analytics_aaa_titanic_miguel: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics_aaa_titanic_miguel"} */
show objects in analytics.aaa_titanic_miguel limit 10000;
[0m03:01:43.184121 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.368 seconds
[0m03:01:43.190509 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9e14f0b2-55d3-4ea7-aa1c-7eb6a9606e29', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117e32930>]}
[0m03:01:43.195176 [debug] [Thread-1 (]: Began running node model.titanic.train
[0m03:01:43.195658 [info ] [Thread-1 (]: 1 of 1 START python model model aaa_titanic_miguel.train ....................... [RUN]
[0m03:01:43.196026 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_analytics_aaa_titanic_miguel, now model.titanic.train)
[0m03:01:43.196319 [debug] [Thread-1 (]: Began compiling node model.titanic.train
[0m03:01:43.215813 [debug] [Thread-1 (]: Writing injected SQL for node "model.titanic.train"
[0m03:01:43.216793 [debug] [Thread-1 (]: Began executing node model.titanic.train
[0m03:01:43.230746 [debug] [Thread-1 (]: Writing runtime python for node "model.titanic.train"
[0m03:01:43.232219 [debug] [Thread-1 (]: Using snowflake connection "model.titanic.train"
[0m03:01:43.232592 [debug] [Thread-1 (]: On model.titanic.train: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "model.titanic.train"} */
WITH train__dbt_sp AS PROCEDURE ()

RETURNS STRING
LANGUAGE PYTHON
RUNTIME_VERSION = '3.11'
PACKAGES = ('snowflake-ml-python', 'pandas', 'scikit-learn', 'snowflake-snowpark-python')



HANDLER = 'main'
EXECUTE AS CALLER
AS
$$

import sys
sys._xoptions['snowflake_partner_attribution'].append("dbtLabs_dbtPython")


        


import importlib.util
if importlib.util.find_spec("snowflake.ml") is None:
    raise ImportError("snowflake.ml is not found. Add snowflake-ml-python to package dependencies.")
from snowflake.ml.registry import Registry
import datetime
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.svm import SVC
from snowflake.ml.model import model_signature


def preprocess(df: pd.DataFrame) -> pd.DataFrame:
  df = df[["CUSTOMER_ID", "AGE", "MONTHLY_EXPENSES"]]
  df["CUSTOMER_ID"] = pd.Categorical(df["CUSTOMER_ID"])
  df["AGE"] = pd.Categorical(df["AGE"])
  df["MONTHLY_EXPENSES"] = pd.Categorical(df["EMBARKED"])
  return pd.get_dummies(df, columns=["CUSTOMER_ID", "AGE", "MONTHLY_EXPENSES"])


def model(dbt, session):
  dbt.config(
    materialized="model",
    python_version="3.11",
    packages=["snowflake-ml-python", "pandas", "scikit-learn"],
  )

  dataset = dbt.ref("train_data")

  data = dataset.to_pandas()

  x = preprocess(data)
  y = data["ATTRITION"]

  imputer = SimpleImputer()
  x = imputer.fit_transform(x)

  model = SVC()
  model.fit(x, y)

  return {
    "model": model,
    "signatures": {"predict": model_signature.infer_signature(x, y)},
    "version_name": datetime.datetime.today().strftime("V%Y%m%d%s"),
    "metrics": {"r2_score": model.score(x, y)},
    "comment": f"r2_score: {model.score(x, y)}",
    "set_default": True,
  }


# This part is user provided model code
# you will need to copy the next section to run the code
# COMMAND ----------
# this part is dbt logic for get ref work, do not modify

def ref(*args, **kwargs):
    refs = {"train_data": "analytics.aaa_titanic_miguel.train_data"}
    key = '.'.join(args)
    version = kwargs.get("v") or kwargs.get("version")
    if version:
        key += f".v{version}"
    dbt_load_df_function = kwargs.get("dbt_load_df_function")
    return dbt_load_df_function(refs[key])


def source(*args, dbt_load_df_function):
    sources = {}
    key = '.'.join(args)
    return dbt_load_df_function(sources[key])


config_dict = {}


class config:
    def __init__(self, *args, **kwargs):
        pass

    @staticmethod
    def get(key, default=None):
        return config_dict.get(key, default)

class this:
    """dbt.this() or dbt.this.identifier"""
    database = "analytics"
    schema = "aaa_titanic_miguel"
    identifier = "train"
    
    def __repr__(self):
        return 'analytics.aaa_titanic_miguel.train'


class dbtObj:
    def __init__(self, load_df_function) -> None:
        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)
        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)
        self.config = config
        self.this = this()
        self.is_incremental = False

# COMMAND ----------



def main(session):
    dbt = dbtObj(session.table)
    model_dict = model(dbt, session)
    reg = Registry(
        session = session,
        database_name = dbt.this.database,
        schema_name = dbt.this.schema
    )
    set_default = model_dict.pop("set_default", False)
    assert "model_name" not in model_dict, "model_name cannot be overridden"
    assert "conda_dependencies" not in model_dict, "conda_dependencies cannot be overridden"
    mv = reg.log_model(
        **model_dict,
        model_name = "analytics.aaa_titanic_miguel.train",
        conda_dependencies = ['snowflake-ml-python', 'pandas', 'scikit-learn'],
    )
    if set_default:
        reg.get_model(dbt.this.identifier).default = mv
    return "OK"

$$
CALL train__dbt_sp();
[0m03:01:51.561436 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01baeb95-0907-baa2-0007-978308d0c51a
[0m03:01:51.562450 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 100357 (P0000): Python Interpreter Error:
Traceback (most recent call last):
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 3805, in get_loc
    return self._engine.get_loc(casted_key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "index.pyx", line 167, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 196, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'EMBARKED'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "_udf_code.py", line 115, in main
    model_dict = model(dbt, session)
                 ^^^^^^^^^^^^^^^^^^^
  File "_udf_code.py", line 40, in model
    x = preprocess(data)
        ^^^^^^^^^^^^^^^^
  File "_udf_code.py", line 25, in preprocess
    df["MONTHLY_EXPENSES"] = pd.Categorical(df["EMBARKED"])
                                            ~~^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/frame.py", line 4102, in __getitem__
    indexer = self.columns.get_loc(key)
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 3812, in get_loc
    raise KeyError(key) from err
KeyError: 'EMBARKED'
 in function TRAIN__DBT_SP with handler main
[0m03:01:51.567316 [debug] [Thread-1 (]: Database Error in model train (models/train.py)
  100357 (P0000): Python Interpreter Error:
  Traceback (most recent call last):
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 3805, in get_loc
      return self._engine.get_loc(casted_key)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "index.pyx", line 167, in pandas._libs.index.IndexEngine.get_loc
    File "index.pyx", line 196, in pandas._libs.index.IndexEngine.get_loc
    File "pandas/_libs/hashtable_class_helper.pxi", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item
    File "pandas/_libs/hashtable_class_helper.pxi", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item
  KeyError: 'EMBARKED'
  
  The above exception was the direct cause of the following exception:
  
  Traceback (most recent call last):
    File "_udf_code.py", line 115, in main
      model_dict = model(dbt, session)
                   ^^^^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 40, in model
      x = preprocess(data)
          ^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 25, in preprocess
      df["MONTHLY_EXPENSES"] = pd.Categorical(df["EMBARKED"])
                                              ~~^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/frame.py", line 4102, in __getitem__
      indexer = self.columns.get_loc(key)
                ^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 3812, in get_loc
      raise KeyError(key) from err
  KeyError: 'EMBARKED'
   in function TRAIN__DBT_SP with handler main
  compiled code at target/run/titanic/models/train.py
[0m03:01:51.569280 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e14f0b2-55d3-4ea7-aa1c-7eb6a9606e29', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078d87a0>]}
[0m03:01:51.569978 [error] [Thread-1 (]: 1 of 1 ERROR creating python model model aaa_titanic_miguel.train .............. [[31mERROR[0m in 8.37s]
[0m03:01:51.570586 [debug] [Thread-1 (]: Finished running node model.titanic.train
[0m03:01:51.571146 [debug] [Thread-13 ]: Marking all children of 'model.titanic.train' to be skipped because of status 'error'.  Reason: Database Error in model train (models/train.py)
  100357 (P0000): Python Interpreter Error:
  Traceback (most recent call last):
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 3805, in get_loc
      return self._engine.get_loc(casted_key)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "index.pyx", line 167, in pandas._libs.index.IndexEngine.get_loc
    File "index.pyx", line 196, in pandas._libs.index.IndexEngine.get_loc
    File "pandas/_libs/hashtable_class_helper.pxi", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item
    File "pandas/_libs/hashtable_class_helper.pxi", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item
  KeyError: 'EMBARKED'
  
  The above exception was the direct cause of the following exception:
  
  Traceback (most recent call last):
    File "_udf_code.py", line 115, in main
      model_dict = model(dbt, session)
                   ^^^^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 40, in model
      x = preprocess(data)
          ^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 25, in preprocess
      df["MONTHLY_EXPENSES"] = pd.Categorical(df["EMBARKED"])
                                              ~~^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/frame.py", line 4102, in __getitem__
      indexer = self.columns.get_loc(key)
                ^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 3812, in get_loc
      raise KeyError(key) from err
  KeyError: 'EMBARKED'
   in function TRAIN__DBT_SP with handler main
  compiled code at target/run/titanic/models/train.py.
[0m03:01:51.572825 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:01:51.573085 [debug] [MainThread]: Connection 'model.titanic.train' was left open.
[0m03:01:51.573327 [debug] [MainThread]: On model.titanic.train: Close
[0m03:01:52.195680 [info ] [MainThread]: 
[0m03:01:52.196466 [info ] [MainThread]: Finished running 1 model model in 0 hours 0 minutes and 16.07 seconds (16.07s).
[0m03:01:52.197413 [debug] [MainThread]: Command end result
[0m03:01:52.218596 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m03:01:52.220464 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m03:01:52.225474 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/migueldichoso/Downloads/Titanic/target/run_results.json
[0m03:01:52.225742 [info ] [MainThread]: 
[0m03:01:52.226014 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m03:01:52.226220 [info ] [MainThread]: 
[0m03:01:52.226518 [error] [MainThread]:   Database Error in model train (models/train.py)
  100357 (P0000): Python Interpreter Error:
  Traceback (most recent call last):
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 3805, in get_loc
      return self._engine.get_loc(casted_key)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "index.pyx", line 167, in pandas._libs.index.IndexEngine.get_loc
    File "index.pyx", line 196, in pandas._libs.index.IndexEngine.get_loc
    File "pandas/_libs/hashtable_class_helper.pxi", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item
    File "pandas/_libs/hashtable_class_helper.pxi", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item
  KeyError: 'EMBARKED'
  
  The above exception was the direct cause of the following exception:
  
  Traceback (most recent call last):
    File "_udf_code.py", line 115, in main
      model_dict = model(dbt, session)
                   ^^^^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 40, in model
      x = preprocess(data)
          ^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 25, in preprocess
      df["MONTHLY_EXPENSES"] = pd.Categorical(df["EMBARKED"])
                                              ~~^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/frame.py", line 4102, in __getitem__
      indexer = self.columns.get_loc(key)
                ^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 3812, in get_loc
      raise KeyError(key) from err
  KeyError: 'EMBARKED'
   in function TRAIN__DBT_SP with handler main
  compiled code at target/run/titanic/models/train.py
[0m03:01:52.226909 [info ] [MainThread]: 
[0m03:01:52.227182 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m03:01:52.229002 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 17.11425, "process_in_blocks": "0", "process_kernel_time": 0.424776, "process_mem_max_rss": "180322304", "process_out_blocks": "0", "process_user_time": 1.716483}
[0m03:01:52.229364 [debug] [MainThread]: Command `dbt build` failed at 03:01:52.229290 after 17.11 seconds
[0m03:01:52.229658 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11227ddf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11725a0f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106eef230>]}
[0m03:01:52.229946 [debug] [MainThread]: Flushing usage events
[0m03:01:57.557050 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:02:49.807417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110ca5ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111b86210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111b85e20>]}


============================== 03:02:49.811139 | 20099a1e-d0ee-4085-a449-5a6a67ff9d0a ==============================
[0m03:02:49.811139 [info ] [MainThread]: Running with dbt=1.9.3
[0m03:02:49.811566 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/migueldichoso/Downloads/Titanic', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/migueldichoso/Downloads/Titanic/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt build -s train', 'send_anonymous_usage_stats': 'True'}
[0m03:02:50.461943 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '20099a1e-d0ee-4085-a449-5a6a67ff9d0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1162ea420>]}
[0m03:02:50.501872 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '20099a1e-d0ee-4085-a449-5a6a67ff9d0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11056aae0>]}
[0m03:02:50.503100 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m03:02:50.613051 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m03:02:50.687290 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m03:02:50.687700 [debug] [MainThread]: Partial parsing: updated file: titanic://models/train.py
[0m03:02:50.835170 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '20099a1e-d0ee-4085-a449-5a6a67ff9d0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11697f680>]}
[0m03:02:50.879525 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m03:02:50.882190 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m03:02:50.909301 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '20099a1e-d0ee-4085-a449-5a6a67ff9d0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116bb62a0>]}
[0m03:02:50.909815 [info ] [MainThread]: Found 2 seeds, 3 models, 480 macros
[0m03:02:50.911349 [info ] [MainThread]: 
[0m03:02:50.911632 [info ] [MainThread]: Concurrency: 10 threads (target='titanic_dev')
[0m03:02:50.911822 [info ] [MainThread]: 
[0m03:02:50.912178 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m03:02:50.912897 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_analytics'
[0m03:02:50.958978 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
[0m03:02:50.959336 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics"} */
show terse schemas in database analytics
    limit 10000
[0m03:02:50.959562 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:02:54.320032 [debug] [ThreadPool]: SQL status: SUCCESS 1757 in 3.360 seconds
[0m03:02:55.765301 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_aaa_titanic_miguel)
[0m03:02:55.772327 [debug] [ThreadPool]: Using snowflake connection "list_analytics_aaa_titanic_miguel"
[0m03:02:55.772589 [debug] [ThreadPool]: On list_analytics_aaa_titanic_miguel: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics_aaa_titanic_miguel"} */
show objects in analytics.aaa_titanic_miguel limit 10000;
[0m03:02:56.144165 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.371 seconds
[0m03:02:56.149306 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '20099a1e-d0ee-4085-a449-5a6a67ff9d0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1170dab40>]}
[0m03:02:56.154831 [debug] [Thread-1 (]: Began running node model.titanic.train
[0m03:02:56.155606 [info ] [Thread-1 (]: 1 of 1 START python model model aaa_titanic_miguel.train ....................... [RUN]
[0m03:02:56.156133 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_analytics_aaa_titanic_miguel, now model.titanic.train)
[0m03:02:56.156501 [debug] [Thread-1 (]: Began compiling node model.titanic.train
[0m03:02:56.179428 [debug] [Thread-1 (]: Writing injected SQL for node "model.titanic.train"
[0m03:02:56.180545 [debug] [Thread-1 (]: Began executing node model.titanic.train
[0m03:02:56.195671 [debug] [Thread-1 (]: Writing runtime python for node "model.titanic.train"
[0m03:02:56.197365 [debug] [Thread-1 (]: Using snowflake connection "model.titanic.train"
[0m03:02:56.197751 [debug] [Thread-1 (]: On model.titanic.train: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "model.titanic.train"} */
WITH train__dbt_sp AS PROCEDURE ()

RETURNS STRING
LANGUAGE PYTHON
RUNTIME_VERSION = '3.11'
PACKAGES = ('snowflake-ml-python', 'pandas', 'scikit-learn', 'snowflake-snowpark-python')



HANDLER = 'main'
EXECUTE AS CALLER
AS
$$

import sys
sys._xoptions['snowflake_partner_attribution'].append("dbtLabs_dbtPython")


        


import importlib.util
if importlib.util.find_spec("snowflake.ml") is None:
    raise ImportError("snowflake.ml is not found. Add snowflake-ml-python to package dependencies.")
from snowflake.ml.registry import Registry
import datetime
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.svm import SVC
from snowflake.ml.model import model_signature


def preprocess(df: pd.DataFrame) -> pd.DataFrame:
  df = df[["CUSTOMER_ID", "AGE", "MONTHLY_EXPENSES"]]
  df["CUSTOMER_ID"] = pd.Categorical(df["CUSTOMER_ID"])
  df["AGE"] = pd.Categorical(df["AGE"])
  df["MONTHLY_EXPENSES"] = pd.Categorical(df["MONTHLY_EXPENSES"])
  return pd.get_dummies(df, columns=["CUSTOMER_ID", "AGE", "MONTHLY_EXPENSES"])


def model(dbt, session):
  dbt.config(
    materialized="model",
    python_version="3.11",
    packages=["snowflake-ml-python", "pandas", "scikit-learn"],
  )

  dataset = dbt.ref("train_data")

  data = dataset.to_pandas()

  x = preprocess(data)
  y = data["ATTRITION"]

  imputer = SimpleImputer()
  x = imputer.fit_transform(x)

  model = SVC()
  model.fit(x, y)

  return {
    "model": model,
    "signatures": {"predict": model_signature.infer_signature(x, y)},
    "version_name": datetime.datetime.today().strftime("V%Y%m%d%s"),
    "metrics": {"r2_score": model.score(x, y)},
    "comment": f"r2_score: {model.score(x, y)}",
    "set_default": True,
  }


# This part is user provided model code
# you will need to copy the next section to run the code
# COMMAND ----------
# this part is dbt logic for get ref work, do not modify

def ref(*args, **kwargs):
    refs = {"train_data": "analytics.aaa_titanic_miguel.train_data"}
    key = '.'.join(args)
    version = kwargs.get("v") or kwargs.get("version")
    if version:
        key += f".v{version}"
    dbt_load_df_function = kwargs.get("dbt_load_df_function")
    return dbt_load_df_function(refs[key])


def source(*args, dbt_load_df_function):
    sources = {}
    key = '.'.join(args)
    return dbt_load_df_function(sources[key])


config_dict = {}


class config:
    def __init__(self, *args, **kwargs):
        pass

    @staticmethod
    def get(key, default=None):
        return config_dict.get(key, default)

class this:
    """dbt.this() or dbt.this.identifier"""
    database = "analytics"
    schema = "aaa_titanic_miguel"
    identifier = "train"
    
    def __repr__(self):
        return 'analytics.aaa_titanic_miguel.train'


class dbtObj:
    def __init__(self, load_df_function) -> None:
        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)
        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)
        self.config = config
        self.this = this()
        self.is_incremental = False

# COMMAND ----------



def main(session):
    dbt = dbtObj(session.table)
    model_dict = model(dbt, session)
    reg = Registry(
        session = session,
        database_name = dbt.this.database,
        schema_name = dbt.this.schema
    )
    set_default = model_dict.pop("set_default", False)
    assert "model_name" not in model_dict, "model_name cannot be overridden"
    assert "conda_dependencies" not in model_dict, "conda_dependencies cannot be overridden"
    mv = reg.log_model(
        **model_dict,
        model_name = "analytics.aaa_titanic_miguel.train",
        conda_dependencies = ['snowflake-ml-python', 'pandas', 'scikit-learn'],
    )
    if set_default:
        reg.get_model(dbt.this.identifier).default = mv
    return "OK"

$$
CALL train__dbt_sp();
[0m03:03:13.948108 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 17.749 seconds
[0m03:03:13.974847 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '20099a1e-d0ee-4085-a449-5a6a67ff9d0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106dd5af0>]}
[0m03:03:13.975550 [info ] [Thread-1 (]: 1 of 1 OK created python model model aaa_titanic_miguel.train .................. [[32mSUCCESS 1[0m in 17.82s]
[0m03:03:13.976016 [debug] [Thread-1 (]: Finished running node model.titanic.train
[0m03:03:13.977421 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:03:13.977616 [debug] [MainThread]: Connection 'model.titanic.train' was left open.
[0m03:03:13.977806 [debug] [MainThread]: On model.titanic.train: Close
[0m03:03:14.580548 [info ] [MainThread]: 
[0m03:03:14.581307 [info ] [MainThread]: Finished running 1 model model in 0 hours 0 minutes and 23.67 seconds (23.67s).
[0m03:03:14.582181 [debug] [MainThread]: Command end result
[0m03:03:14.602330 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m03:03:14.603994 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m03:03:14.610408 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/migueldichoso/Downloads/Titanic/target/run_results.json
[0m03:03:14.610699 [info ] [MainThread]: 
[0m03:03:14.610973 [info ] [MainThread]: [32mCompleted successfully[0m
[0m03:03:14.611182 [info ] [MainThread]: 
[0m03:03:14.611406 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m03:03:14.613257 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 24.878904, "process_in_blocks": "0", "process_kernel_time": 0.428725, "process_mem_max_rss": "184975360", "process_out_blocks": "0", "process_user_time": 1.877584}
[0m03:03:14.613561 [debug] [MainThread]: Command `dbt build` succeeded at 03:03:14.613498 after 24.88 seconds
[0m03:03:14.613841 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111b85fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110daafc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11634bf50>]}
[0m03:03:14.614088 [debug] [MainThread]: Flushing usage events
[0m03:03:20.805461 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:06:34.737654 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1040f4a70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1045d9f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1045d9b80>]}


============================== 03:06:34.741630 | ffe30986-11bf-4fa3-89b2-540bfa9b323f ==============================
[0m03:06:34.741630 [info ] [MainThread]: Running with dbt=1.9.3
[0m03:06:34.742068 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/migueldichoso/Downloads/Titanic', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/migueldichoso/Downloads/Titanic/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt build', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m03:06:35.411061 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ffe30986-11bf-4fa3-89b2-540bfa9b323f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d63920>]}
[0m03:06:35.446848 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ffe30986-11bf-4fa3-89b2-540bfa9b323f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d7c440>]}
[0m03:06:35.447782 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m03:06:35.559589 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m03:06:35.639841 [debug] [MainThread]: Partial parsing enabled: 3 files deleted, 2 files added, 0 files changed.
[0m03:06:35.640303 [debug] [MainThread]: Partial parsing: added file: titanic://seeds/predit_data.csv
[0m03:06:35.640536 [debug] [MainThread]: Partial parsing: added file: titanic://models/predict.py
[0m03:06:35.640727 [debug] [MainThread]: Partial parsing: deleted file: titanic://models/sklearn_model.py
[0m03:06:35.640899 [debug] [MainThread]: Partial parsing: deleted file: titanic://models/sklearn_predict.py
[0m03:06:35.641070 [debug] [MainThread]: Partial parsing: deleted file: titanic://seeds/titanic3.csv
[0m03:06:35.843503 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.titanic.predict' (models/predict.py) depends on a node named 'predict_data' which was not found
[0m03:06:35.846997 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 1.1878484, "process_in_blocks": "0", "process_kernel_time": 0.357167, "process_mem_max_rss": "165593088", "process_out_blocks": "0", "process_user_time": 1.531424}
[0m03:06:35.847351 [debug] [MainThread]: Command `dbt build` failed at 03:06:35.847271 after 1.19 seconds
[0m03:06:35.847656 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090213a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090346b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10821c5c0>]}
[0m03:06:35.847916 [debug] [MainThread]: Flushing usage events
[0m03:06:37.599237 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:06:45.040239 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106219e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108019e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108019970>]}


============================== 03:06:45.043540 | db2c677b-5245-41f0-b2fc-d075b2e7262b ==============================
[0m03:06:45.043540 [info ] [MainThread]: Running with dbt=1.9.3
[0m03:06:45.043987 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/Users/migueldichoso/Downloads/Titanic', 'log_path': '/Users/migueldichoso/Downloads/Titanic/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt seed', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:06:45.472213 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'db2c677b-5245-41f0-b2fc-d075b2e7262b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aec3110>]}
[0m03:06:45.506485 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'db2c677b-5245-41f0-b2fc-d075b2e7262b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107797f80>]}
[0m03:06:45.507022 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m03:06:45.613572 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m03:06:45.687079 [debug] [MainThread]: Partial parsing enabled: 3 files deleted, 2 files added, 0 files changed.
[0m03:06:45.687526 [debug] [MainThread]: Partial parsing: added file: titanic://models/predict.py
[0m03:06:45.687759 [debug] [MainThread]: Partial parsing: added file: titanic://seeds/predit_data.csv
[0m03:06:45.687947 [debug] [MainThread]: Partial parsing: deleted file: titanic://models/sklearn_predict.py
[0m03:06:45.688130 [debug] [MainThread]: Partial parsing: deleted file: titanic://models/sklearn_model.py
[0m03:06:45.688298 [debug] [MainThread]: Partial parsing: deleted file: titanic://seeds/titanic3.csv
[0m03:06:45.882968 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.titanic.predict' (models/predict.py) depends on a node named 'predict_data' which was not found
[0m03:06:45.885685 [debug] [MainThread]: Resource report: {"command_name": "seed", "command_success": false, "command_wall_clock_time": 0.9150924, "process_in_blocks": "0", "process_kernel_time": 0.257126, "process_mem_max_rss": "164134912", "process_out_blocks": "0", "process_user_time": 1.470971}
[0m03:06:45.886024 [debug] [MainThread]: Command `dbt seed` failed at 03:06:45.885957 after 0.92 seconds
[0m03:06:45.886322 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107671f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf94d70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106cb0230>]}
[0m03:06:45.886577 [debug] [MainThread]: Flushing usage events
[0m03:06:46.760046 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:07:06.277606 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10733c260>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10736de20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10736da30>]}


============================== 03:07:06.281388 | 0536d633-81e8-4fd4-8311-b10207a55583 ==============================
[0m03:07:06.281388 [info ] [MainThread]: Running with dbt=1.9.3
[0m03:07:06.281817 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/Users/migueldichoso/Downloads/Titanic', 'log_path': '/Users/migueldichoso/Downloads/Titanic/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt seed', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:07:06.852436 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0536d633-81e8-4fd4-8311-b10207a55583', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10736dca0>]}
[0m03:07:06.886388 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0536d633-81e8-4fd4-8311-b10207a55583', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f6a4e0>]}
[0m03:07:06.887035 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m03:07:06.992088 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m03:07:07.063661 [debug] [MainThread]: Partial parsing enabled: 3 files deleted, 2 files added, 0 files changed.
[0m03:07:07.064058 [debug] [MainThread]: Partial parsing: added file: titanic://seeds/predict_data.csv
[0m03:07:07.064275 [debug] [MainThread]: Partial parsing: added file: titanic://models/predict.py
[0m03:07:07.064457 [debug] [MainThread]: Partial parsing: deleted file: titanic://models/sklearn_model.py
[0m03:07:07.064624 [debug] [MainThread]: Partial parsing: deleted file: titanic://seeds/titanic3.csv
[0m03:07:07.064785 [debug] [MainThread]: Partial parsing: deleted file: titanic://models/sklearn_predict.py
[0m03:07:07.278403 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0536d633-81e8-4fd4-8311-b10207a55583', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114c88230>]}
[0m03:07:07.316722 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m03:07:07.321076 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m03:07:07.335045 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0536d633-81e8-4fd4-8311-b10207a55583', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114d90a10>]}
[0m03:07:07.335348 [info ] [MainThread]: Found 2 seeds, 2 models, 480 macros
[0m03:07:07.335571 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0536d633-81e8-4fd4-8311-b10207a55583', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114c5ba10>]}
[0m03:07:07.336775 [info ] [MainThread]: 
[0m03:07:07.337021 [info ] [MainThread]: Concurrency: 10 threads (target='titanic_dev')
[0m03:07:07.337189 [info ] [MainThread]: 
[0m03:07:07.337477 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m03:07:07.340045 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_analytics'
[0m03:07:07.386178 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
[0m03:07:07.386473 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics"} */
show terse schemas in database analytics
    limit 10000
[0m03:07:07.386679 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:07:10.620059 [debug] [ThreadPool]: SQL status: SUCCESS 1756 in 3.233 seconds
[0m03:07:12.478397 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now create_analytics_aaa_titanic_miguel)
[0m03:07:12.479213 [debug] [ThreadPool]: Creating schema "database: "analytics"
schema: "aaa_titanic_miguel"
"
[0m03:07:12.482579 [debug] [ThreadPool]: Using snowflake connection "create_analytics_aaa_titanic_miguel"
[0m03:07:12.482817 [debug] [ThreadPool]: On create_analytics_aaa_titanic_miguel: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "create_analytics_aaa_titanic_miguel"} */
create schema if not exists analytics.aaa_titanic_miguel
[0m03:07:12.853975 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.371 seconds
[0m03:07:12.859550 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_analytics_aaa_titanic_miguel, now list_analytics_aaa_titanic_miguel_predict)
[0m03:07:12.866659 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_analytics_aaa_titanic_miguel'
[0m03:07:12.871385 [debug] [ThreadPool]: Using snowflake connection "list_analytics_aaa_titanic_miguel_predict"
[0m03:07:12.873242 [debug] [ThreadPool]: Using snowflake connection "list_analytics_aaa_titanic_miguel"
[0m03:07:12.873551 [debug] [ThreadPool]: On list_analytics_aaa_titanic_miguel_predict: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics_aaa_titanic_miguel_predict"} */
show objects in analytics.aaa_titanic_miguel_predict limit 10000;
[0m03:07:12.873848 [debug] [ThreadPool]: On list_analytics_aaa_titanic_miguel: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics_aaa_titanic_miguel"} */
show objects in analytics.aaa_titanic_miguel limit 10000;
[0m03:07:12.874343 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:07:13.231704 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01baeb9b-0907-baa2-0007-978308d0c6ae
[0m03:07:13.232183 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
[0m03:07:13.232570 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
[0m03:07:13.232809 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m03:07:14.452289 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 1.578 seconds
[0m03:07:14.457063 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0536d633-81e8-4fd4-8311-b10207a55583', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11577d640>]}
[0m03:07:14.463443 [debug] [Thread-1 (]: Began running node seed.titanic.predict_data
[0m03:07:14.464026 [debug] [Thread-2 (]: Began running node seed.titanic.train_data
[0m03:07:14.464655 [info ] [Thread-1 (]: 1 of 2 START seed file aaa_titanic_miguel.predict_data ......................... [RUN]
[0m03:07:14.465318 [info ] [Thread-2 (]: 2 of 2 START seed file aaa_titanic_miguel.train_data ........................... [RUN]
[0m03:07:14.465908 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_analytics_aaa_titanic_miguel_predict, now seed.titanic.predict_data)
[0m03:07:14.466296 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_analytics_aaa_titanic_miguel, now seed.titanic.train_data)
[0m03:07:14.466671 [debug] [Thread-1 (]: Began compiling node seed.titanic.predict_data
[0m03:07:14.466989 [debug] [Thread-2 (]: Began compiling node seed.titanic.train_data
[0m03:07:14.467345 [debug] [Thread-1 (]: Began executing node seed.titanic.predict_data
[0m03:07:14.467660 [debug] [Thread-2 (]: Began executing node seed.titanic.train_data
[0m03:07:14.504383 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.predict_data"
[0m03:07:14.506155 [debug] [Thread-2 (]: Using snowflake connection "seed.titanic.train_data"
[0m03:07:14.506405 [debug] [Thread-1 (]: On seed.titanic.predict_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.predict_data"} */
create table analytics.aaa_titanic_miguel.predict_data (customer_id integer,age integer,monthly_expenses float8)
[0m03:07:14.506642 [debug] [Thread-2 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
create table analytics.aaa_titanic_miguel.train_data (customer_id integer,age integer,monthly_expenses float8,attrition text)
[0m03:07:14.958010 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.451 seconds
[0m03:07:14.959315 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.452 seconds
[0m03:07:14.984879 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.predict_data"
[0m03:07:14.985261 [debug] [Thread-2 (]: Using snowflake connection "seed.titanic.train_data"
[0m03:07:14.985602 [debug] [Thread-1 (]: On seed.titanic.predict_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.predict_data"} */
BEGIN
[0m03:07:14.985882 [debug] [Thread-2 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
BEGIN
[0m03:07:15.353592 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.367 seconds
[0m03:07:15.366151 [debug] [Thread-2 (]: Using snowflake connection "seed.titanic.train_data"
[0m03:07:15.367215 [debug] [Thread-2 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
insert into analytics.aaa_titanic_miguel.train_data (customer_id, age, monthly_expenses, attrition) values
            (%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(...
[0m03:07:15.373093 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.387 seconds
[0m03:07:15.376235 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.predict_data"
[0m03:07:15.376626 [debug] [Thread-1 (]: On seed.titanic.predict_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.predict_data"} */
insert into analytics.aaa_titanic_miguel.predict_data (customer_id, age, monthly_expenses) values
            (%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,...
[0m03:07:16.028731 [debug] [Thread-2 (]: SQL status: SUCCESS 405 in 0.661 seconds
[0m03:07:16.030207 [debug] [Thread-1 (]: SQL status: SUCCESS 200 in 0.653 seconds
[0m03:07:16.030994 [debug] [Thread-2 (]: Using snowflake connection "seed.titanic.train_data"
[0m03:07:16.031735 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.predict_data"
[0m03:07:16.032525 [debug] [Thread-2 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
COMMIT
[0m03:07:16.032992 [debug] [Thread-1 (]: On seed.titanic.predict_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.predict_data"} */
COMMIT
[0m03:07:16.573297 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.539 seconds
[0m03:07:16.582222 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.titanic.predict_data"
[0m03:07:16.606249 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0536d633-81e8-4fd4-8311-b10207a55583', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106344b90>]}
[0m03:07:16.606659 [info ] [Thread-1 (]: 1 of 2 OK loaded seed file aaa_titanic_miguel.predict_data ..................... [[32mINSERT 200[0m in 2.14s]
[0m03:07:16.607041 [debug] [Thread-1 (]: Finished running node seed.titanic.predict_data
[0m03:07:16.616207 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.583 seconds
[0m03:07:16.616779 [debug] [Thread-2 (]: Writing runtime SQL for node "seed.titanic.train_data"
[0m03:07:16.619244 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0536d633-81e8-4fd4-8311-b10207a55583', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114a9e660>]}
[0m03:07:16.619599 [info ] [Thread-2 (]: 2 of 2 OK loaded seed file aaa_titanic_miguel.train_data ....................... [[32mINSERT 405[0m in 2.15s]
[0m03:07:16.619979 [debug] [Thread-2 (]: Finished running node seed.titanic.train_data
[0m03:07:16.620849 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:07:16.621033 [debug] [MainThread]: Connection 'seed.titanic.predict_data' was left open.
[0m03:07:16.621199 [debug] [MainThread]: On seed.titanic.predict_data: Close
[0m03:07:17.228815 [debug] [MainThread]: Connection 'seed.titanic.train_data' was left open.
[0m03:07:17.229481 [debug] [MainThread]: On seed.titanic.train_data: Close
[0m03:07:17.849700 [info ] [MainThread]: 
[0m03:07:17.850724 [info ] [MainThread]: Finished running 2 seeds in 0 hours 0 minutes and 10.51 seconds (10.51s).
[0m03:07:17.851835 [debug] [MainThread]: Command end result
[0m03:07:17.873862 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m03:07:17.875621 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m03:07:17.879945 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/migueldichoso/Downloads/Titanic/target/run_results.json
[0m03:07:17.880187 [info ] [MainThread]: 
[0m03:07:17.880494 [info ] [MainThread]: [32mCompleted successfully[0m
[0m03:07:17.880698 [info ] [MainThread]: 
[0m03:07:17.880911 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m03:07:17.882853 [debug] [MainThread]: Resource report: {"command_name": "seed", "command_success": true, "command_wall_clock_time": 11.677418, "process_in_blocks": "0", "process_kernel_time": 0.400064, "process_mem_max_rss": "187465728", "process_out_blocks": "0", "process_user_time": 2.025481}
[0m03:07:17.883131 [debug] [MainThread]: Command `dbt seed` succeeded at 03:07:17.883072 after 11.68 seconds
[0m03:07:17.883381 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114a40290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114863530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115155520>]}
[0m03:07:17.883611 [debug] [MainThread]: Flushing usage events
[0m03:07:18.791392 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:07:24.190495 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10628fad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10651de50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10651da30>]}


============================== 03:07:24.193778 | 8ab31a1e-2790-4471-a84b-257625c7e9a6 ==============================
[0m03:07:24.193778 [info ] [MainThread]: Running with dbt=1.9.3
[0m03:07:24.194210 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/migueldichoso/Downloads/Titanic/logs', 'version_check': 'True', 'profiles_dir': '/Users/migueldichoso/Downloads/Titanic', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt build', 'send_anonymous_usage_stats': 'True'}
[0m03:07:24.629904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8ab31a1e-2790-4471-a84b-257625c7e9a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047ff050>]}
[0m03:07:24.664199 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8ab31a1e-2790-4471-a84b-257625c7e9a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b0e6b70>]}
[0m03:07:24.664733 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m03:07:24.767650 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m03:07:24.831879 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m03:07:24.832168 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m03:07:24.853587 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8ab31a1e-2790-4471-a84b-257625c7e9a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b534680>]}
[0m03:07:24.892775 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m03:07:24.894612 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m03:07:24.913507 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8ab31a1e-2790-4471-a84b-257625c7e9a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb27860>]}
[0m03:07:24.913835 [info ] [MainThread]: Found 2 seeds, 2 models, 480 macros
[0m03:07:24.915190 [info ] [MainThread]: 
[0m03:07:24.915433 [info ] [MainThread]: Concurrency: 10 threads (target='titanic_dev')
[0m03:07:24.915604 [info ] [MainThread]: 
[0m03:07:24.915904 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m03:07:24.918671 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_analytics'
[0m03:07:24.920059 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_analytics'
[0m03:07:24.958113 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
[0m03:07:24.958520 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
[0m03:07:24.958759 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics"} */
show terse schemas in database analytics
    limit 10000
[0m03:07:24.958998 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics"} */
show terse schemas in database analytics
    limit 10000
[0m03:07:24.959195 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:07:24.959367 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:07:27.183511 [debug] [ThreadPool]: SQL status: SUCCESS 1757 in 2.224 seconds
[0m03:07:27.204680 [debug] [ThreadPool]: SQL status: SUCCESS 1757 in 2.245 seconds
[0m03:07:28.690350 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now create_analytics_aaa_titanic_miguel_predict)
[0m03:07:28.690725 [debug] [ThreadPool]: Creating schema "database: "analytics"
schema: "aaa_titanic_miguel_predict"
"
[0m03:07:28.693716 [debug] [ThreadPool]: Using snowflake connection "create_analytics_aaa_titanic_miguel_predict"
[0m03:07:28.693938 [debug] [ThreadPool]: On create_analytics_aaa_titanic_miguel_predict: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "create_analytics_aaa_titanic_miguel_predict"} */
create schema if not exists analytics.aaa_titanic_miguel_predict
[0m03:07:29.054173 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.360 seconds
[0m03:07:29.059356 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_aaa_titanic_miguel)
[0m03:07:29.066467 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_analytics_aaa_titanic_miguel_predict, now list_analytics_aaa_titanic_miguel_predict)
[0m03:07:29.072291 [debug] [ThreadPool]: Using snowflake connection "list_analytics_aaa_titanic_miguel"
[0m03:07:29.074287 [debug] [ThreadPool]: Using snowflake connection "list_analytics_aaa_titanic_miguel_predict"
[0m03:07:29.074645 [debug] [ThreadPool]: On list_analytics_aaa_titanic_miguel: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics_aaa_titanic_miguel"} */
show objects in analytics.aaa_titanic_miguel limit 10000;
[0m03:07:29.074957 [debug] [ThreadPool]: On list_analytics_aaa_titanic_miguel_predict: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics_aaa_titanic_miguel_predict"} */
show objects in analytics.aaa_titanic_miguel_predict limit 10000;
[0m03:07:29.444436 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 0.369 seconds
[0m03:07:29.446119 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.371 seconds
[0m03:07:29.451290 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8ab31a1e-2790-4471-a84b-257625c7e9a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf77200>]}
[0m03:07:29.454299 [debug] [Thread-1 (]: Began running node seed.titanic.predict_data
[0m03:07:29.454770 [debug] [Thread-2 (]: Began running node seed.titanic.train_data
[0m03:07:29.455336 [info ] [Thread-1 (]: 1 of 4 START seed file aaa_titanic_miguel.predict_data ......................... [RUN]
[0m03:07:29.455917 [info ] [Thread-2 (]: 2 of 4 START seed file aaa_titanic_miguel.train_data ........................... [RUN]
[0m03:07:29.456382 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_analytics_aaa_titanic_miguel, now seed.titanic.predict_data)
[0m03:07:29.456759 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_analytics_aaa_titanic_miguel_predict, now seed.titanic.train_data)
[0m03:07:29.457109 [debug] [Thread-1 (]: Began compiling node seed.titanic.predict_data
[0m03:07:29.457448 [debug] [Thread-2 (]: Began compiling node seed.titanic.train_data
[0m03:07:29.457799 [debug] [Thread-1 (]: Began executing node seed.titanic.predict_data
[0m03:07:29.458117 [debug] [Thread-2 (]: Began executing node seed.titanic.train_data
[0m03:07:29.499594 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.predict_data"
[0m03:07:29.503704 [debug] [Thread-1 (]: On seed.titanic.predict_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.predict_data"} */
BEGIN
[0m03:07:29.506184 [debug] [Thread-2 (]: Using snowflake connection "seed.titanic.train_data"
[0m03:07:29.506647 [debug] [Thread-2 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
BEGIN
[0m03:07:29.874306 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.367 seconds
[0m03:07:29.875576 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.369 seconds
[0m03:07:29.876110 [debug] [Thread-2 (]: Using snowflake connection "seed.titanic.train_data"
[0m03:07:29.876514 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.predict_data"
[0m03:07:29.876856 [debug] [Thread-2 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
truncate table "ANALYTICS"."AAA_TITANIC_MIGUEL"."TRAIN_DATA"
  ;
[0m03:07:29.877193 [debug] [Thread-1 (]: On seed.titanic.predict_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.predict_data"} */
truncate table "ANALYTICS"."AAA_TITANIC_MIGUEL"."PREDICT_DATA"
  ;
[0m03:07:30.570690 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.693 seconds
[0m03:07:30.572107 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.695 seconds
[0m03:07:30.572776 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.predict_data"
[0m03:07:30.573301 [debug] [Thread-2 (]: Using snowflake connection "seed.titanic.train_data"
[0m03:07:30.573700 [debug] [Thread-1 (]: On seed.titanic.predict_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.predict_data"} */
COMMIT
[0m03:07:30.574075 [debug] [Thread-2 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
COMMIT
[0m03:07:31.360417 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.786 seconds
[0m03:07:31.361995 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.787 seconds
[0m03:07:31.388168 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.predict_data"
[0m03:07:31.387510 [debug] [Thread-2 (]: Using snowflake connection "seed.titanic.train_data"
[0m03:07:31.388706 [debug] [Thread-1 (]: On seed.titanic.predict_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.predict_data"} */
BEGIN
[0m03:07:31.388986 [debug] [Thread-2 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
BEGIN
[0m03:07:31.746228 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.356 seconds
[0m03:07:31.752186 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.predict_data"
[0m03:07:31.753533 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.364 seconds
[0m03:07:31.754099 [debug] [Thread-1 (]: On seed.titanic.predict_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.predict_data"} */
insert into analytics.aaa_titanic_miguel.predict_data (customer_id, age, monthly_expenses) values
            (%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,...
[0m03:07:31.763853 [debug] [Thread-2 (]: Using snowflake connection "seed.titanic.train_data"
[0m03:07:31.766317 [debug] [Thread-2 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
insert into analytics.aaa_titanic_miguel.train_data (customer_id, age, monthly_expenses, attrition) values
            (%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(...
[0m03:07:32.439673 [debug] [Thread-1 (]: SQL status: SUCCESS 200 in 0.675 seconds
[0m03:07:32.441138 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.predict_data"
[0m03:07:32.441640 [debug] [Thread-1 (]: On seed.titanic.predict_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.predict_data"} */
COMMIT
[0m03:07:32.450421 [debug] [Thread-2 (]: SQL status: SUCCESS 405 in 0.684 seconds
[0m03:07:32.451227 [debug] [Thread-2 (]: Using snowflake connection "seed.titanic.train_data"
[0m03:07:32.451656 [debug] [Thread-2 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
COMMIT
[0m03:07:33.057541 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.615 seconds
[0m03:07:33.066535 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.titanic.predict_data"
[0m03:07:33.088135 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.636 seconds
[0m03:07:33.088743 [debug] [Thread-2 (]: Writing runtime SQL for node "seed.titanic.train_data"
[0m03:07:33.089115 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8ab31a1e-2790-4471-a84b-257625c7e9a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ed0bd40>]}
[0m03:07:33.089577 [info ] [Thread-1 (]: 1 of 4 OK loaded seed file aaa_titanic_miguel.predict_data ..................... [[32mINSERT 200[0m in 3.63s]
[0m03:07:33.091060 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8ab31a1e-2790-4471-a84b-257625c7e9a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eaf9bb0>]}
[0m03:07:33.091425 [debug] [Thread-1 (]: Finished running node seed.titanic.predict_data
[0m03:07:33.091805 [info ] [Thread-2 (]: 2 of 4 OK loaded seed file aaa_titanic_miguel.train_data ....................... [[32mINSERT 405[0m in 3.63s]
[0m03:07:33.092305 [debug] [Thread-2 (]: Finished running node seed.titanic.train_data
[0m03:07:33.093065 [debug] [Thread-4 (]: Began running node model.titanic.train
[0m03:07:33.093539 [info ] [Thread-4 (]: 3 of 4 START python model model aaa_titanic_miguel.train ....................... [RUN]
[0m03:07:33.093965 [debug] [Thread-4 (]: Acquiring new snowflake connection 'model.titanic.train'
[0m03:07:33.094223 [debug] [Thread-4 (]: Began compiling node model.titanic.train
[0m03:07:33.112191 [debug] [Thread-4 (]: Writing injected SQL for node "model.titanic.train"
[0m03:07:33.112817 [debug] [Thread-4 (]: Began executing node model.titanic.train
[0m03:07:33.121308 [debug] [Thread-4 (]: Writing runtime python for node "model.titanic.train"
[0m03:07:33.122680 [debug] [Thread-4 (]: Using snowflake connection "model.titanic.train"
[0m03:07:33.123075 [debug] [Thread-4 (]: On model.titanic.train: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "model.titanic.train"} */
WITH train__dbt_sp AS PROCEDURE ()

RETURNS STRING
LANGUAGE PYTHON
RUNTIME_VERSION = '3.11'
PACKAGES = ('snowflake-ml-python', 'pandas', 'scikit-learn', 'snowflake-snowpark-python')



HANDLER = 'main'
EXECUTE AS CALLER
AS
$$

import sys
sys._xoptions['snowflake_partner_attribution'].append("dbtLabs_dbtPython")


        


import importlib.util
if importlib.util.find_spec("snowflake.ml") is None:
    raise ImportError("snowflake.ml is not found. Add snowflake-ml-python to package dependencies.")
from snowflake.ml.registry import Registry
import datetime
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.svm import SVC
from snowflake.ml.model import model_signature


def preprocess(df: pd.DataFrame) -> pd.DataFrame:
  df = df[["CUSTOMER_ID", "AGE", "MONTHLY_EXPENSES"]]
  df["CUSTOMER_ID"] = pd.Categorical(df["CUSTOMER_ID"])
  df["AGE"] = pd.Categorical(df["AGE"])
  df["MONTHLY_EXPENSES"] = pd.Categorical(df["MONTHLY_EXPENSES"])
  return pd.get_dummies(df, columns=["CUSTOMER_ID", "AGE", "MONTHLY_EXPENSES"])


def model(dbt, session):
  dbt.config(
    materialized="model",
    python_version="3.11",
    packages=["snowflake-ml-python", "pandas", "scikit-learn"],
  )

  dataset = dbt.ref("train_data")

  data = dataset.to_pandas()

  x = preprocess(data)
  y = data["ATTRITION"]

  imputer = SimpleImputer()
  x = imputer.fit_transform(x)

  model = SVC()
  model.fit(x, y)

  return {
    "model": model,
    "signatures": {"predict": model_signature.infer_signature(x, y)},
    "version_name": datetime.datetime.today().strftime("V%Y%m%d%s"),
    "metrics": {"r2_score": model.score(x, y)},
    "comment": f"r2_score: {model.score(x, y)}",
    "set_default": True,
  }


# This part is user provided model code
# you will need to copy the next section to run the code
# COMMAND ----------
# this part is dbt logic for get ref work, do not modify

def ref(*args, **kwargs):
    refs = {"train_data": "analytics.aaa_titanic_miguel.train_data"}
    key = '.'.join(args)
    version = kwargs.get("v") or kwargs.get("version")
    if version:
        key += f".v{version}"
    dbt_load_df_function = kwargs.get("dbt_load_df_function")
    return dbt_load_df_function(refs[key])


def source(*args, dbt_load_df_function):
    sources = {}
    key = '.'.join(args)
    return dbt_load_df_function(sources[key])


config_dict = {}


class config:
    def __init__(self, *args, **kwargs):
        pass

    @staticmethod
    def get(key, default=None):
        return config_dict.get(key, default)

class this:
    """dbt.this() or dbt.this.identifier"""
    database = "analytics"
    schema = "aaa_titanic_miguel"
    identifier = "train"
    
    def __repr__(self):
        return 'analytics.aaa_titanic_miguel.train'


class dbtObj:
    def __init__(self, load_df_function) -> None:
        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)
        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)
        self.config = config
        self.this = this()
        self.is_incremental = False

# COMMAND ----------



def main(session):
    dbt = dbtObj(session.table)
    model_dict = model(dbt, session)
    reg = Registry(
        session = session,
        database_name = dbt.this.database,
        schema_name = dbt.this.schema
    )
    set_default = model_dict.pop("set_default", False)
    assert "model_name" not in model_dict, "model_name cannot be overridden"
    assert "conda_dependencies" not in model_dict, "conda_dependencies cannot be overridden"
    mv = reg.log_model(
        **model_dict,
        model_name = "analytics.aaa_titanic_miguel.train",
        conda_dependencies = ['snowflake-ml-python', 'pandas', 'scikit-learn'],
    )
    if set_default:
        reg.get_model(dbt.this.identifier).default = mv
    return "OK"

$$
CALL train__dbt_sp();
[0m03:07:33.123430 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m03:07:56.466899 [debug] [Thread-4 (]: SQL status: SUCCESS 1 in 23.343 seconds
[0m03:07:56.473723 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8ab31a1e-2790-4471-a84b-257625c7e9a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ea98f20>]}
[0m03:07:56.474861 [info ] [Thread-4 (]: 3 of 4 OK created python model model aaa_titanic_miguel.train .................. [[32mSUCCESS 1[0m in 23.38s]
[0m03:07:56.475652 [debug] [Thread-4 (]: Finished running node model.titanic.train
[0m03:07:56.476689 [debug] [Thread-6 (]: Began running node model.titanic.predict
[0m03:07:56.477152 [info ] [Thread-6 (]: 4 of 4 START python table model aaa_titanic_miguel_predict.predict ............. [RUN]
[0m03:07:56.477663 [debug] [Thread-6 (]: Acquiring new snowflake connection 'model.titanic.predict'
[0m03:07:56.477992 [debug] [Thread-6 (]: Began compiling node model.titanic.predict
[0m03:07:56.482863 [debug] [Thread-6 (]: Writing injected SQL for node "model.titanic.predict"
[0m03:07:56.484193 [debug] [Thread-6 (]: Began executing node model.titanic.predict
[0m03:07:56.505576 [debug] [Thread-6 (]: Writing runtime python for node "model.titanic.predict"
[0m03:07:56.507142 [debug] [Thread-6 (]: Using snowflake connection "model.titanic.predict"
[0m03:07:56.507529 [debug] [Thread-6 (]: On model.titanic.predict: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "model.titanic.predict"} */
WITH predict__dbt_sp AS PROCEDURE ()

RETURNS STRING
LANGUAGE PYTHON
RUNTIME_VERSION = '3.11'
PACKAGES = ('snowflake-ml-python', 'pandas', 'scikit-learn', 'snowflake-snowpark-python')



HANDLER = 'main'
EXECUTE AS CALLER
AS
$$

import sys
sys._xoptions['snowflake_partner_attribution'].append("dbtLabs_dbtPython")


  
    
    
import pandas as pd
from sklearn.impute import SimpleImputer
from snowflake.ml.registry import registry


def preprocess(df: pd.DataFrame) -> pd.DataFrame:
  df = df[["CUSTOMER_ID", "AGE", "MONTHLY_EXPENSES"]]
  df["CUSTOMER_ID"] = pd.Categorical(df["CUSTOMER_ID"])
  df["AGE"] = pd.Categorical(df["AGE"])
  df["MONTHLY_EXPENSES"] = pd.Categorical(df["MONTHLY_EXPENSES"])
  return pd.get_dummies(df, columns=["CUSTOMER_ID", "AGE", "MONTHLY_EXPENSES"])


def model(dbt, session):
  dbt.config(
    materialized="table",
    python_version="3.11",
    packages=["snowflake-ml-python", "pandas", "scikit-learn"],
    schema="predict",
  )

  dataset = dbt.ref("predict_data")

  data = dataset.to_pandas()

  x = preprocess(data)

  imputer = SimpleImputer()
  x = imputer.fit_transform(x)

  reg = registry.Registry(session=session)

  model_ref = dbt.ref("train")
  mv = reg.get_model(model_ref.table_name).default
  data["PREDICTED"] = mv.run(x, function_name="PREDICT")

  return data


# This part is user provided model code
# you will need to copy the next section to run the code
# COMMAND ----------
# this part is dbt logic for get ref work, do not modify

def ref(*args, **kwargs):
    refs = {"predict_data": "analytics.aaa_titanic_miguel.predict_data", "train": "analytics.aaa_titanic_miguel.train"}
    key = '.'.join(args)
    version = kwargs.get("v") or kwargs.get("version")
    if version:
        key += f".v{version}"
    dbt_load_df_function = kwargs.get("dbt_load_df_function")
    return dbt_load_df_function(refs[key])


def source(*args, dbt_load_df_function):
    sources = {}
    key = '.'.join(args)
    return dbt_load_df_function(sources[key])


config_dict = {}


class config:
    def __init__(self, *args, **kwargs):
        pass

    @staticmethod
    def get(key, default=None):
        return config_dict.get(key, default)

class this:
    """dbt.this() or dbt.this.identifier"""
    database = "analytics"
    schema = "aaa_titanic_miguel_predict"
    identifier = "predict"
    
    def __repr__(self):
        return 'analytics.aaa_titanic_miguel_predict.predict'


class dbtObj:
    def __init__(self, load_df_function) -> None:
        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)
        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)
        self.config = config
        self.this = this()
        self.is_incremental = False

# COMMAND ----------



def materialize(session, df, target_relation):
    # make sure pandas exists
    import importlib.util
    package_name = 'pandas'
    if importlib.util.find_spec(package_name):
        import pandas
        if isinstance(df, pandas.core.frame.DataFrame):
          session.use_database(target_relation.database)
          session.use_schema(target_relation.schema)
          # session.write_pandas does not have overwrite function
          df = session.createDataFrame(df)
    
    df.write.mode("overwrite").save_as_table('analytics.aaa_titanic_miguel_predict.predict', table_type='transient')

def main(session):
    dbt = dbtObj(session.table)
    df = model(dbt, session)
    materialize(session, df, dbt.this)
    return "OK"

  
$$
CALL predict__dbt_sp();
[0m03:07:56.507897 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m03:08:03.351090 [debug] [Thread-6 (]: Snowflake adapter: Snowflake query id: 01baeb9b-0907-ba98-0007-978308d0d052
[0m03:08:03.351863 [debug] [Thread-6 (]: Snowflake adapter: Snowflake error: 100357 (P0000): Python Interpreter Error:
Traceback (most recent call last):
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py", line 527, in wrap
    return ctx.run(execute_func_with_statement_params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py", line 503, in execute_func_with_statement_params
    result = func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/model/_client/model/model_version_impl.py", line 463, in run
    return self._model_ops.invoke_method(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/model/_client/ops/model_ops.py", line 857, in invoke_method
    df = model_signature._convert_and_validate_local_data(X, signature.inputs, strict=strict_input_validation)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/model/model_signature.py", line 684, in _convert_and_validate_local_data
    df = utils.rename_pandas_df(df, features)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/model/_signatures/utils.py", line 96, in rename_pandas_df
    raise snowml_exceptions.SnowflakeMLException(
snowflake.ml._internal.exceptions.exceptions.SnowflakeMLException: ValueError('(2110) Data does not have the same number of features as signature. Signature requires 675 features, but have 407 in input data.')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "_udf_code.py", line 119, in main
    df = model(dbt, session)
         ^^^^^^^^^^^^^^^^^^^
  File "_udf_code.py", line 44, in model
    data["PREDICTED"] = mv.run(x, function_name="PREDICT")
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py", line 529, in wrap
    raise e.original_exception from e
ValueError: (2110) Data does not have the same number of features as signature. Signature requires 675 features, but have 407 in input data.
 in function PREDICT__DBT_SP with handler main
[0m03:08:03.356916 [debug] [Thread-6 (]: Database Error in model predict (models/predict.py)
  100357 (P0000): Python Interpreter Error:
  Traceback (most recent call last):
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py", line 527, in wrap
      return ctx.run(execute_func_with_statement_params)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py", line 503, in execute_func_with_statement_params
      result = func(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/model/_client/model/model_version_impl.py", line 463, in run
      return self._model_ops.invoke_method(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/model/_client/ops/model_ops.py", line 857, in invoke_method
      df = model_signature._convert_and_validate_local_data(X, signature.inputs, strict=strict_input_validation)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/model/model_signature.py", line 684, in _convert_and_validate_local_data
      df = utils.rename_pandas_df(df, features)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/model/_signatures/utils.py", line 96, in rename_pandas_df
      raise snowml_exceptions.SnowflakeMLException(
  snowflake.ml._internal.exceptions.exceptions.SnowflakeMLException: ValueError('(2110) Data does not have the same number of features as signature. Signature requires 675 features, but have 407 in input data.')
  
  The above exception was the direct cause of the following exception:
  
  Traceback (most recent call last):
    File "_udf_code.py", line 119, in main
      df = model(dbt, session)
           ^^^^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 44, in model
      data["PREDICTED"] = mv.run(x, function_name="PREDICT")
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py", line 529, in wrap
      raise e.original_exception from e
  ValueError: (2110) Data does not have the same number of features as signature. Signature requires 675 features, but have 407 in input data.
   in function PREDICT__DBT_SP with handler main
  compiled code at target/run/titanic/models/predict.py
[0m03:08:03.357587 [debug] [Thread-6 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8ab31a1e-2790-4471-a84b-257625c7e9a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eabfb90>]}
[0m03:08:03.358226 [error] [Thread-6 (]: 4 of 4 ERROR creating python table model aaa_titanic_miguel_predict.predict .... [[31mERROR[0m in 6.88s]
[0m03:08:03.358859 [debug] [Thread-6 (]: Finished running node model.titanic.predict
[0m03:08:03.359450 [debug] [Thread-13 ]: Marking all children of 'model.titanic.predict' to be skipped because of status 'error'.  Reason: Database Error in model predict (models/predict.py)
  100357 (P0000): Python Interpreter Error:
  Traceback (most recent call last):
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py", line 527, in wrap
      return ctx.run(execute_func_with_statement_params)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py", line 503, in execute_func_with_statement_params
      result = func(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/model/_client/model/model_version_impl.py", line 463, in run
      return self._model_ops.invoke_method(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/model/_client/ops/model_ops.py", line 857, in invoke_method
      df = model_signature._convert_and_validate_local_data(X, signature.inputs, strict=strict_input_validation)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/model/model_signature.py", line 684, in _convert_and_validate_local_data
      df = utils.rename_pandas_df(df, features)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/model/_signatures/utils.py", line 96, in rename_pandas_df
      raise snowml_exceptions.SnowflakeMLException(
  snowflake.ml._internal.exceptions.exceptions.SnowflakeMLException: ValueError('(2110) Data does not have the same number of features as signature. Signature requires 675 features, but have 407 in input data.')
  
  The above exception was the direct cause of the following exception:
  
  Traceback (most recent call last):
    File "_udf_code.py", line 119, in main
      df = model(dbt, session)
           ^^^^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 44, in model
      data["PREDICTED"] = mv.run(x, function_name="PREDICT")
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py", line 529, in wrap
      raise e.original_exception from e
  ValueError: (2110) Data does not have the same number of features as signature. Signature requires 675 features, but have 407 in input data.
   in function PREDICT__DBT_SP with handler main
  compiled code at target/run/titanic/models/predict.py.
[0m03:08:03.361159 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:08:03.361382 [debug] [MainThread]: Connection 'seed.titanic.predict_data' was left open.
[0m03:08:03.361592 [debug] [MainThread]: On seed.titanic.predict_data: Close
[0m03:08:04.063877 [debug] [MainThread]: Connection 'seed.titanic.train_data' was left open.
[0m03:08:04.064633 [debug] [MainThread]: On seed.titanic.train_data: Close
[0m03:08:04.675459 [debug] [MainThread]: Connection 'model.titanic.train' was left open.
[0m03:08:04.675974 [debug] [MainThread]: On model.titanic.train: Close
[0m03:08:05.285191 [debug] [MainThread]: Connection 'model.titanic.predict' was left open.
[0m03:08:05.286143 [debug] [MainThread]: On model.titanic.predict: Close
[0m03:08:05.903814 [info ] [MainThread]: 
[0m03:08:05.904833 [info ] [MainThread]: Finished running 1 model model, 2 seeds, 1 table model in 0 hours 0 minutes and 40.99 seconds (40.99s).
[0m03:08:05.906749 [debug] [MainThread]: Command end result
[0m03:08:05.931863 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m03:08:05.933657 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m03:08:05.937996 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/migueldichoso/Downloads/Titanic/target/run_results.json
[0m03:08:05.938225 [info ] [MainThread]: 
[0m03:08:05.938494 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m03:08:05.938685 [info ] [MainThread]: 
[0m03:08:05.939022 [error] [MainThread]:   Database Error in model predict (models/predict.py)
  100357 (P0000): Python Interpreter Error:
  Traceback (most recent call last):
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py", line 527, in wrap
      return ctx.run(execute_func_with_statement_params)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py", line 503, in execute_func_with_statement_params
      result = func(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/model/_client/model/model_version_impl.py", line 463, in run
      return self._model_ops.invoke_method(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/model/_client/ops/model_ops.py", line 857, in invoke_method
      df = model_signature._convert_and_validate_local_data(X, signature.inputs, strict=strict_input_validation)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/model/model_signature.py", line 684, in _convert_and_validate_local_data
      df = utils.rename_pandas_df(df, features)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/model/_signatures/utils.py", line 96, in rename_pandas_df
      raise snowml_exceptions.SnowflakeMLException(
  snowflake.ml._internal.exceptions.exceptions.SnowflakeMLException: ValueError('(2110) Data does not have the same number of features as signature. Signature requires 675 features, but have 407 in input data.')
  
  The above exception was the direct cause of the following exception:
  
  Traceback (most recent call last):
    File "_udf_code.py", line 119, in main
      df = model(dbt, session)
           ^^^^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 44, in model
      data["PREDICTED"] = mv.run(x, function_name="PREDICT")
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py", line 529, in wrap
      raise e.original_exception from e
  ValueError: (2110) Data does not have the same number of features as signature. Signature requires 675 features, but have 407 in input data.
   in function PREDICT__DBT_SP with handler main
  compiled code at target/run/titanic/models/predict.py
[0m03:08:05.939424 [info ] [MainThread]: 
[0m03:08:05.939673 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m03:08:05.941649 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 41.821514, "process_in_blocks": "0", "process_kernel_time": 0.356205, "process_mem_max_rss": "189644800", "process_out_blocks": "0", "process_user_time": 2.142651}
[0m03:08:05.941965 [debug] [MainThread]: Command `dbt build` failed at 03:08:05.941911 after 41.82 seconds
[0m03:08:05.942215 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10651daf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1095bd9a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104783b90>]}
[0m03:08:05.942431 [debug] [MainThread]: Flushing usage events
[0m03:08:12.357381 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:09:53.636157 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1092656d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1092821b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109281d90>]}


============================== 03:09:53.640459 | 067a4618-040e-489f-a77d-0b9cffad6250 ==============================
[0m03:09:53.640459 [info ] [MainThread]: Running with dbt=1.9.3
[0m03:09:53.640902 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/migueldichoso/Downloads/Titanic', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/migueldichoso/Downloads/Titanic/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt build', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:09:54.271343 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '067a4618-040e-489f-a77d-0b9cffad6250', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d863620>]}
[0m03:09:54.307351 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '067a4618-040e-489f-a77d-0b9cffad6250', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ffd100>]}
[0m03:09:54.308194 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m03:09:54.420661 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m03:09:54.495427 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m03:09:54.495867 [debug] [MainThread]: Partial parsing: updated file: titanic://seeds/predict_data.csv
[0m03:09:54.619169 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '067a4618-040e-489f-a77d-0b9cffad6250', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e08a2a0>]}
[0m03:09:54.658135 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m03:09:54.660358 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m03:09:54.684408 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '067a4618-040e-489f-a77d-0b9cffad6250', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e38c7a0>]}
[0m03:09:54.684735 [info ] [MainThread]: Found 2 seeds, 2 models, 480 macros
[0m03:09:54.686113 [info ] [MainThread]: 
[0m03:09:54.686350 [info ] [MainThread]: Concurrency: 10 threads (target='titanic_dev')
[0m03:09:54.686528 [info ] [MainThread]: 
[0m03:09:54.686830 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m03:09:54.689466 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_analytics'
[0m03:09:54.696165 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_analytics'
[0m03:09:54.738615 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
[0m03:09:54.739028 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
[0m03:09:54.739265 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics"} */
show terse schemas in database analytics
    limit 10000
[0m03:09:54.739480 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics"} */
show terse schemas in database analytics
    limit 10000
[0m03:09:54.739685 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:09:54.739851 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:09:57.655396 [debug] [ThreadPool]: SQL status: SUCCESS 1758 in 2.915 seconds
[0m03:09:57.932290 [debug] [ThreadPool]: SQL status: SUCCESS 1758 in 3.193 seconds
[0m03:09:59.115629 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_aaa_titanic_miguel)
[0m03:09:59.116007 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_aaa_titanic_miguel_predict)
[0m03:09:59.122445 [debug] [ThreadPool]: Using snowflake connection "list_analytics_aaa_titanic_miguel"
[0m03:09:59.123774 [debug] [ThreadPool]: Using snowflake connection "list_analytics_aaa_titanic_miguel_predict"
[0m03:09:59.123999 [debug] [ThreadPool]: On list_analytics_aaa_titanic_miguel: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics_aaa_titanic_miguel"} */
show objects in analytics.aaa_titanic_miguel limit 10000;
[0m03:09:59.124198 [debug] [ThreadPool]: On list_analytics_aaa_titanic_miguel_predict: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics_aaa_titanic_miguel_predict"} */
show objects in analytics.aaa_titanic_miguel_predict limit 10000;
[0m03:09:59.471323 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.346 seconds
[0m03:09:59.492494 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 0.368 seconds
[0m03:09:59.496304 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '067a4618-040e-489f-a77d-0b9cffad6250', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df189b0>]}
[0m03:09:59.502816 [debug] [Thread-1 (]: Began running node seed.titanic.predict_data
[0m03:09:59.503323 [debug] [Thread-2 (]: Began running node seed.titanic.train_data
[0m03:09:59.503915 [info ] [Thread-1 (]: 1 of 4 START seed file aaa_titanic_miguel.predict_data ......................... [RUN]
[0m03:09:59.504566 [info ] [Thread-2 (]: 2 of 4 START seed file aaa_titanic_miguel.train_data ........................... [RUN]
[0m03:09:59.505108 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_analytics_aaa_titanic_miguel, now seed.titanic.predict_data)
[0m03:09:59.505488 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_analytics_aaa_titanic_miguel_predict, now seed.titanic.train_data)
[0m03:09:59.505850 [debug] [Thread-1 (]: Began compiling node seed.titanic.predict_data
[0m03:09:59.506168 [debug] [Thread-2 (]: Began compiling node seed.titanic.train_data
[0m03:09:59.506511 [debug] [Thread-1 (]: Began executing node seed.titanic.predict_data
[0m03:09:59.506824 [debug] [Thread-2 (]: Began executing node seed.titanic.train_data
[0m03:09:59.546278 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.predict_data"
[0m03:09:59.547888 [debug] [Thread-2 (]: Using snowflake connection "seed.titanic.train_data"
[0m03:09:59.548135 [debug] [Thread-1 (]: On seed.titanic.predict_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.predict_data"} */
BEGIN
[0m03:09:59.548377 [debug] [Thread-2 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
BEGIN
[0m03:09:59.927755 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.379 seconds
[0m03:09:59.928915 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.predict_data"
[0m03:09:59.929524 [debug] [Thread-1 (]: On seed.titanic.predict_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.predict_data"} */
truncate table "ANALYTICS"."AAA_TITANIC_MIGUEL"."PREDICT_DATA"
  ;
[0m03:09:59.931921 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.383 seconds
[0m03:09:59.932808 [debug] [Thread-2 (]: Using snowflake connection "seed.titanic.train_data"
[0m03:09:59.933313 [debug] [Thread-2 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
truncate table "ANALYTICS"."AAA_TITANIC_MIGUEL"."TRAIN_DATA"
  ;
[0m03:10:00.601623 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.671 seconds
[0m03:10:00.602745 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.predict_data"
[0m03:10:00.603991 [debug] [Thread-1 (]: On seed.titanic.predict_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.predict_data"} */
COMMIT
[0m03:10:00.605543 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.671 seconds
[0m03:10:00.606096 [debug] [Thread-2 (]: Using snowflake connection "seed.titanic.train_data"
[0m03:10:00.606526 [debug] [Thread-2 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
COMMIT
[0m03:10:01.207052 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.600 seconds
[0m03:10:01.229851 [debug] [Thread-2 (]: Using snowflake connection "seed.titanic.train_data"
[0m03:10:01.230760 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.626 seconds
[0m03:10:01.231095 [debug] [Thread-2 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
BEGIN
[0m03:10:01.234752 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.predict_data"
[0m03:10:01.235265 [debug] [Thread-1 (]: On seed.titanic.predict_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.predict_data"} */
BEGIN
[0m03:10:01.628530 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.392 seconds
[0m03:10:01.630136 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.395 seconds
[0m03:10:01.635310 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.predict_data"
[0m03:10:01.644427 [debug] [Thread-2 (]: Using snowflake connection "seed.titanic.train_data"
[0m03:10:01.644783 [debug] [Thread-1 (]: On seed.titanic.predict_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.predict_data"} */
insert into analytics.aaa_titanic_miguel.predict_data (customer_id, age, monthly_expenses, attrition) values
            (%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%...
[0m03:10:01.645121 [debug] [Thread-2 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
insert into analytics.aaa_titanic_miguel.train_data (customer_id, age, monthly_expenses, attrition) values
            (%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(...
[0m03:10:02.014522 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01baeb9e-0907-ba98-0007-978308d0d1c6
[0m03:10:02.015067 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 000904 (42000): SQL compilation error: error line 1 at position 91
invalid identifier 'ATTRITION'
[0m03:10:02.019872 [debug] [Thread-1 (]: Database Error in seed predict_data (seeds/predict_data.csv)
  000904 (42000): SQL compilation error: error line 1 at position 91
  invalid identifier 'ATTRITION'
[0m03:10:02.022360 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '067a4618-040e-489f-a77d-0b9cffad6250', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f614d10>]}
[0m03:10:02.023060 [error] [Thread-1 (]: 1 of 4 ERROR loading seed file aaa_titanic_miguel.predict_data ................. [[31mERROR[0m in 2.52s]
[0m03:10:02.023805 [debug] [Thread-1 (]: Finished running node seed.titanic.predict_data
[0m03:10:02.024402 [debug] [Thread-13 ]: Marking all children of 'seed.titanic.predict_data' to be skipped because of status 'error'.  Reason: Database Error in seed predict_data (seeds/predict_data.csv)
  000904 (42000): SQL compilation error: error line 1 at position 91
  invalid identifier 'ATTRITION'.
[0m03:10:02.385165 [debug] [Thread-2 (]: SQL status: SUCCESS 405 in 0.737 seconds
[0m03:10:02.386819 [debug] [Thread-2 (]: Using snowflake connection "seed.titanic.train_data"
[0m03:10:02.387322 [debug] [Thread-2 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
COMMIT
[0m03:10:03.156788 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.769 seconds
[0m03:10:03.163547 [debug] [Thread-2 (]: Writing runtime SQL for node "seed.titanic.train_data"
[0m03:10:03.183418 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '067a4618-040e-489f-a77d-0b9cffad6250', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f9f9700>]}
[0m03:10:03.183899 [info ] [Thread-2 (]: 2 of 4 OK loaded seed file aaa_titanic_miguel.train_data ....................... [[32mINSERT 405[0m in 3.68s]
[0m03:10:03.184308 [debug] [Thread-2 (]: Finished running node seed.titanic.train_data
[0m03:10:03.184870 [debug] [Thread-4 (]: Began running node model.titanic.train
[0m03:10:03.185302 [info ] [Thread-4 (]: 3 of 4 START python model model aaa_titanic_miguel.train ....................... [RUN]
[0m03:10:03.185813 [debug] [Thread-4 (]: Acquiring new snowflake connection 'model.titanic.train'
[0m03:10:03.186074 [debug] [Thread-4 (]: Began compiling node model.titanic.train
[0m03:10:03.203135 [debug] [Thread-4 (]: Writing injected SQL for node "model.titanic.train"
[0m03:10:03.203759 [debug] [Thread-4 (]: Began executing node model.titanic.train
[0m03:10:03.212943 [debug] [Thread-4 (]: Writing runtime python for node "model.titanic.train"
[0m03:10:03.214356 [debug] [Thread-4 (]: Using snowflake connection "model.titanic.train"
[0m03:10:03.214712 [debug] [Thread-4 (]: On model.titanic.train: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "model.titanic.train"} */
WITH train__dbt_sp AS PROCEDURE ()

RETURNS STRING
LANGUAGE PYTHON
RUNTIME_VERSION = '3.11'
PACKAGES = ('snowflake-ml-python', 'pandas', 'scikit-learn', 'snowflake-snowpark-python')



HANDLER = 'main'
EXECUTE AS CALLER
AS
$$

import sys
sys._xoptions['snowflake_partner_attribution'].append("dbtLabs_dbtPython")


        


import importlib.util
if importlib.util.find_spec("snowflake.ml") is None:
    raise ImportError("snowflake.ml is not found. Add snowflake-ml-python to package dependencies.")
from snowflake.ml.registry import Registry
import datetime
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.svm import SVC
from snowflake.ml.model import model_signature


def preprocess(df: pd.DataFrame) -> pd.DataFrame:
  df = df[["CUSTOMER_ID", "AGE", "MONTHLY_EXPENSES"]]
  df["CUSTOMER_ID"] = pd.Categorical(df["CUSTOMER_ID"])
  df["AGE"] = pd.Categorical(df["AGE"])
  df["MONTHLY_EXPENSES"] = pd.Categorical(df["MONTHLY_EXPENSES"])
  return pd.get_dummies(df, columns=["CUSTOMER_ID", "AGE", "MONTHLY_EXPENSES"])


def model(dbt, session):
  dbt.config(
    materialized="model",
    python_version="3.11",
    packages=["snowflake-ml-python", "pandas", "scikit-learn"],
  )

  dataset = dbt.ref("train_data")

  data = dataset.to_pandas()

  x = preprocess(data)
  y = data["ATTRITION"]

  imputer = SimpleImputer()
  x = imputer.fit_transform(x)

  model = SVC()
  model.fit(x, y)

  return {
    "model": model,
    "signatures": {"predict": model_signature.infer_signature(x, y)},
    "version_name": datetime.datetime.today().strftime("V%Y%m%d%s"),
    "metrics": {"r2_score": model.score(x, y)},
    "comment": f"r2_score: {model.score(x, y)}",
    "set_default": True,
  }


# This part is user provided model code
# you will need to copy the next section to run the code
# COMMAND ----------
# this part is dbt logic for get ref work, do not modify

def ref(*args, **kwargs):
    refs = {"train_data": "analytics.aaa_titanic_miguel.train_data"}
    key = '.'.join(args)
    version = kwargs.get("v") or kwargs.get("version")
    if version:
        key += f".v{version}"
    dbt_load_df_function = kwargs.get("dbt_load_df_function")
    return dbt_load_df_function(refs[key])


def source(*args, dbt_load_df_function):
    sources = {}
    key = '.'.join(args)
    return dbt_load_df_function(sources[key])


config_dict = {}


class config:
    def __init__(self, *args, **kwargs):
        pass

    @staticmethod
    def get(key, default=None):
        return config_dict.get(key, default)

class this:
    """dbt.this() or dbt.this.identifier"""
    database = "analytics"
    schema = "aaa_titanic_miguel"
    identifier = "train"
    
    def __repr__(self):
        return 'analytics.aaa_titanic_miguel.train'


class dbtObj:
    def __init__(self, load_df_function) -> None:
        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)
        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)
        self.config = config
        self.this = this()
        self.is_incremental = False

# COMMAND ----------



def main(session):
    dbt = dbtObj(session.table)
    model_dict = model(dbt, session)
    reg = Registry(
        session = session,
        database_name = dbt.this.database,
        schema_name = dbt.this.schema
    )
    set_default = model_dict.pop("set_default", False)
    assert "model_name" not in model_dict, "model_name cannot be overridden"
    assert "conda_dependencies" not in model_dict, "conda_dependencies cannot be overridden"
    mv = reg.log_model(
        **model_dict,
        model_name = "analytics.aaa_titanic_miguel.train",
        conda_dependencies = ['snowflake-ml-python', 'pandas', 'scikit-learn'],
    )
    if set_default:
        reg.get_model(dbt.this.identifier).default = mv
    return "OK"

$$
CALL train__dbt_sp();
[0m03:10:03.215075 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m03:10:20.659271 [debug] [Thread-4 (]: SQL status: SUCCESS 1 in 17.444 seconds
[0m03:10:20.665359 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '067a4618-040e-489f-a77d-0b9cffad6250', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc5bc20>]}
[0m03:10:20.666166 [info ] [Thread-4 (]: 3 of 4 OK created python model model aaa_titanic_miguel.train .................. [[32mSUCCESS 1[0m in 17.48s]
[0m03:10:20.666762 [debug] [Thread-4 (]: Finished running node model.titanic.train
[0m03:10:20.667847 [debug] [Thread-6 (]: Began running node model.titanic.predict
[0m03:10:20.668561 [info ] [Thread-6 (]: 4 of 4 SKIP relation aaa_titanic_miguel_predict.predict ........................ [[33mSKIP[0m]
[0m03:10:20.669065 [debug] [Thread-6 (]: Finished running node model.titanic.predict
[0m03:10:20.669381 [debug] [Thread-13 ]: Marking all children of 'model.titanic.predict' to be skipped because of status 'skipped'. 
[0m03:10:20.670877 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:10:20.671143 [debug] [MainThread]: Connection 'seed.titanic.predict_data' was left open.
[0m03:10:20.671391 [debug] [MainThread]: On seed.titanic.predict_data: Close
[0m03:10:21.343356 [debug] [MainThread]: Connection 'seed.titanic.train_data' was left open.
[0m03:10:21.344105 [debug] [MainThread]: On seed.titanic.train_data: Close
[0m03:10:21.953057 [debug] [MainThread]: Connection 'model.titanic.train' was left open.
[0m03:10:21.953819 [debug] [MainThread]: On model.titanic.train: Close
[0m03:10:22.606271 [info ] [MainThread]: 
[0m03:10:22.607401 [info ] [MainThread]: Finished running 1 model model, 2 seeds, 1 table model in 0 hours 0 minutes and 27.92 seconds (27.92s).
[0m03:10:22.608838 [debug] [MainThread]: Command end result
[0m03:10:22.710838 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m03:10:22.712191 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m03:10:22.716187 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/migueldichoso/Downloads/Titanic/target/run_results.json
[0m03:10:22.716409 [info ] [MainThread]: 
[0m03:10:22.716657 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m03:10:22.716849 [info ] [MainThread]: 
[0m03:10:22.717064 [error] [MainThread]:   Database Error in seed predict_data (seeds/predict_data.csv)
  000904 (42000): SQL compilation error: error line 1 at position 91
  invalid identifier 'ATTRITION'
[0m03:10:22.717237 [info ] [MainThread]: 
[0m03:10:22.717417 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=1 TOTAL=4
[0m03:10:22.719234 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 29.163292, "process_in_blocks": "0", "process_kernel_time": 0.47097, "process_mem_max_rss": "188612608", "process_out_blocks": "0", "process_user_time": 2.22741}
[0m03:10:22.719551 [debug] [MainThread]: Command `dbt build` failed at 03:10:22.719488 after 29.16 seconds
[0m03:10:22.719810 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e29f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a3cbaa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091f3c50>]}
[0m03:10:22.720056 [debug] [MainThread]: Flushing usage events
[0m03:10:24.652985 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:10:34.129534 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1041e9f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104cde090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104cddbb0>]}


============================== 03:10:34.133402 | 8433377f-2172-44b6-8e91-94dd7814d473 ==============================
[0m03:10:34.133402 [info ] [MainThread]: Running with dbt=1.9.3
[0m03:10:34.133848 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/migueldichoso/Downloads/Titanic/logs', 'version_check': 'True', 'profiles_dir': '/Users/migueldichoso/Downloads/Titanic', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt build --full-refresh', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:10:34.642290 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8433377f-2172-44b6-8e91-94dd7814d473', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047faa50>]}
[0m03:10:34.677725 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8433377f-2172-44b6-8e91-94dd7814d473', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10523de80>]}
[0m03:10:34.678925 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m03:10:34.786469 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m03:10:34.857263 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m03:10:34.857544 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m03:10:34.879164 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8433377f-2172-44b6-8e91-94dd7814d473', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108baf320>]}
[0m03:10:34.918688 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m03:10:34.920774 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m03:10:34.943184 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8433377f-2172-44b6-8e91-94dd7814d473', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109227b00>]}
[0m03:10:34.943500 [info ] [MainThread]: Found 2 seeds, 2 models, 480 macros
[0m03:10:34.944856 [info ] [MainThread]: 
[0m03:10:34.945100 [info ] [MainThread]: Concurrency: 10 threads (target='titanic_dev')
[0m03:10:34.945279 [info ] [MainThread]: 
[0m03:10:34.945579 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m03:10:34.948293 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_analytics'
[0m03:10:34.949841 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_analytics'
[0m03:10:34.997390 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
[0m03:10:34.997826 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
[0m03:10:34.998053 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics"} */
show terse schemas in database analytics
    limit 10000
[0m03:10:34.998268 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics"} */
show terse schemas in database analytics
    limit 10000
[0m03:10:34.998504 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:10:34.998736 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:10:37.362011 [debug] [ThreadPool]: SQL status: SUCCESS 1758 in 2.363 seconds
[0m03:10:37.472708 [debug] [ThreadPool]: SQL status: SUCCESS 1758 in 2.474 seconds
[0m03:10:38.745147 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_aaa_titanic_miguel_predict)
[0m03:10:38.750910 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_aaa_titanic_miguel)
[0m03:10:38.752448 [debug] [ThreadPool]: Using snowflake connection "list_analytics_aaa_titanic_miguel_predict"
[0m03:10:38.753782 [debug] [ThreadPool]: Using snowflake connection "list_analytics_aaa_titanic_miguel"
[0m03:10:38.754010 [debug] [ThreadPool]: On list_analytics_aaa_titanic_miguel_predict: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics_aaa_titanic_miguel_predict"} */
show objects in analytics.aaa_titanic_miguel_predict limit 10000;
[0m03:10:38.754206 [debug] [ThreadPool]: On list_analytics_aaa_titanic_miguel: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics_aaa_titanic_miguel"} */
show objects in analytics.aaa_titanic_miguel limit 10000;
[0m03:10:39.098464 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.344 seconds
[0m03:10:39.147592 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 0.393 seconds
[0m03:10:39.151301 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8433377f-2172-44b6-8e91-94dd7814d473', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096ea4e0>]}
[0m03:10:39.156655 [debug] [Thread-1 (]: Began running node seed.titanic.predict_data
[0m03:10:39.157182 [debug] [Thread-2 (]: Began running node seed.titanic.train_data
[0m03:10:39.157791 [info ] [Thread-1 (]: 1 of 4 START seed file aaa_titanic_miguel.predict_data ......................... [RUN]
[0m03:10:39.158375 [info ] [Thread-2 (]: 2 of 4 START seed file aaa_titanic_miguel.train_data ........................... [RUN]
[0m03:10:39.159016 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_analytics_aaa_titanic_miguel_predict, now seed.titanic.predict_data)
[0m03:10:39.159471 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_analytics_aaa_titanic_miguel, now seed.titanic.train_data)
[0m03:10:39.159864 [debug] [Thread-1 (]: Began compiling node seed.titanic.predict_data
[0m03:10:39.160201 [debug] [Thread-2 (]: Began compiling node seed.titanic.train_data
[0m03:10:39.160577 [debug] [Thread-1 (]: Began executing node seed.titanic.predict_data
[0m03:10:39.160901 [debug] [Thread-2 (]: Began executing node seed.titanic.train_data
[0m03:10:39.198218 [debug] [Thread-2 (]: Applying DROP to: "ANALYTICS"."AAA_TITANIC_MIGUEL"."TRAIN_DATA"
[0m03:10:39.204898 [debug] [Thread-2 (]: Using snowflake connection "seed.titanic.train_data"
[0m03:10:39.206582 [debug] [Thread-1 (]: Applying DROP to: "ANALYTICS"."AAA_TITANIC_MIGUEL"."PREDICT_DATA"
[0m03:10:39.206817 [debug] [Thread-2 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
drop table if exists "ANALYTICS"."AAA_TITANIC_MIGUEL"."TRAIN_DATA" cascade
[0m03:10:39.207337 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.predict_data"
[0m03:10:39.207809 [debug] [Thread-1 (]: On seed.titanic.predict_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.predict_data"} */
drop table if exists "ANALYTICS"."AAA_TITANIC_MIGUEL"."PREDICT_DATA" cascade
[0m03:10:39.567489 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.360 seconds
[0m03:10:39.580570 [debug] [Thread-2 (]: Using snowflake connection "seed.titanic.train_data"
[0m03:10:39.581095 [debug] [Thread-2 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
create table analytics.aaa_titanic_miguel.train_data (customer_id integer,age integer,monthly_expenses float8,attrition text)
[0m03:10:39.586911 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.379 seconds
[0m03:10:39.589152 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.predict_data"
[0m03:10:39.589465 [debug] [Thread-1 (]: On seed.titanic.predict_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.predict_data"} */
create table analytics.aaa_titanic_miguel.predict_data (customer_id integer,age integer,monthly_expenses float8,attrition text)
[0m03:10:40.078191 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.488 seconds
[0m03:10:40.079598 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.498 seconds
[0m03:10:40.101627 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.predict_data"
[0m03:10:40.105738 [debug] [Thread-2 (]: Using snowflake connection "seed.titanic.train_data"
[0m03:10:40.106035 [debug] [Thread-1 (]: On seed.titanic.predict_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.predict_data"} */
BEGIN
[0m03:10:40.106308 [debug] [Thread-2 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
BEGIN
[0m03:10:40.462914 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.356 seconds
[0m03:10:40.476904 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.370 seconds
[0m03:10:40.476214 [debug] [Thread-2 (]: Using snowflake connection "seed.titanic.train_data"
[0m03:10:40.481427 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.predict_data"
[0m03:10:40.481793 [debug] [Thread-2 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
insert into analytics.aaa_titanic_miguel.train_data (customer_id, age, monthly_expenses, attrition) values
            (%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(...
[0m03:10:40.482134 [debug] [Thread-1 (]: On seed.titanic.predict_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.predict_data"} */
insert into analytics.aaa_titanic_miguel.predict_data (customer_id, age, monthly_expenses, attrition) values
            (%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%...
[0m03:10:41.229411 [debug] [Thread-2 (]: SQL status: SUCCESS 405 in 0.747 seconds
[0m03:10:41.231485 [debug] [Thread-2 (]: Using snowflake connection "seed.titanic.train_data"
[0m03:10:41.232871 [debug] [Thread-1 (]: SQL status: SUCCESS 200 in 0.746 seconds
[0m03:10:41.233493 [debug] [Thread-2 (]: On seed.titanic.train_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.train_data"} */
COMMIT
[0m03:10:41.234345 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.predict_data"
[0m03:10:41.235900 [debug] [Thread-1 (]: On seed.titanic.predict_data: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.predict_data"} */
COMMIT
[0m03:10:41.811071 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.574 seconds
[0m03:10:41.815525 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.titanic.predict_data"
[0m03:10:41.816114 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.581 seconds
[0m03:10:41.816695 [debug] [Thread-2 (]: Writing runtime SQL for node "seed.titanic.train_data"
[0m03:10:41.838782 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8433377f-2172-44b6-8e91-94dd7814d473', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1131113a0>]}
[0m03:10:41.839041 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8433377f-2172-44b6-8e91-94dd7814d473', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104160620>]}
[0m03:10:41.839404 [info ] [Thread-1 (]: 1 of 4 OK loaded seed file aaa_titanic_miguel.predict_data ..................... [[32mCREATE 200[0m in 2.68s]
[0m03:10:41.839797 [info ] [Thread-2 (]: 2 of 4 OK loaded seed file aaa_titanic_miguel.train_data ....................... [[32mCREATE 405[0m in 2.68s]
[0m03:10:41.840192 [debug] [Thread-1 (]: Finished running node seed.titanic.predict_data
[0m03:10:41.840481 [debug] [Thread-2 (]: Finished running node seed.titanic.train_data
[0m03:10:41.841036 [debug] [Thread-4 (]: Began running node model.titanic.train
[0m03:10:41.841374 [info ] [Thread-4 (]: 3 of 4 START python model model aaa_titanic_miguel.train ....................... [RUN]
[0m03:10:41.841680 [debug] [Thread-4 (]: Acquiring new snowflake connection 'model.titanic.train'
[0m03:10:41.841879 [debug] [Thread-4 (]: Began compiling node model.titanic.train
[0m03:10:41.858369 [debug] [Thread-4 (]: Writing injected SQL for node "model.titanic.train"
[0m03:10:41.859031 [debug] [Thread-4 (]: Began executing node model.titanic.train
[0m03:10:41.868056 [debug] [Thread-4 (]: Writing runtime python for node "model.titanic.train"
[0m03:10:41.869513 [debug] [Thread-4 (]: Using snowflake connection "model.titanic.train"
[0m03:10:41.869903 [debug] [Thread-4 (]: On model.titanic.train: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "model.titanic.train"} */
WITH train__dbt_sp AS PROCEDURE ()

RETURNS STRING
LANGUAGE PYTHON
RUNTIME_VERSION = '3.11'
PACKAGES = ('snowflake-ml-python', 'pandas', 'scikit-learn', 'snowflake-snowpark-python')



HANDLER = 'main'
EXECUTE AS CALLER
AS
$$

import sys
sys._xoptions['snowflake_partner_attribution'].append("dbtLabs_dbtPython")


        


import importlib.util
if importlib.util.find_spec("snowflake.ml") is None:
    raise ImportError("snowflake.ml is not found. Add snowflake-ml-python to package dependencies.")
from snowflake.ml.registry import Registry
import datetime
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.svm import SVC
from snowflake.ml.model import model_signature


def preprocess(df: pd.DataFrame) -> pd.DataFrame:
  df = df[["CUSTOMER_ID", "AGE", "MONTHLY_EXPENSES"]]
  df["CUSTOMER_ID"] = pd.Categorical(df["CUSTOMER_ID"])
  df["AGE"] = pd.Categorical(df["AGE"])
  df["MONTHLY_EXPENSES"] = pd.Categorical(df["MONTHLY_EXPENSES"])
  return pd.get_dummies(df, columns=["CUSTOMER_ID", "AGE", "MONTHLY_EXPENSES"])


def model(dbt, session):
  dbt.config(
    materialized="model",
    python_version="3.11",
    packages=["snowflake-ml-python", "pandas", "scikit-learn"],
  )

  dataset = dbt.ref("train_data")

  data = dataset.to_pandas()

  x = preprocess(data)
  y = data["ATTRITION"]

  imputer = SimpleImputer()
  x = imputer.fit_transform(x)

  model = SVC()
  model.fit(x, y)

  return {
    "model": model,
    "signatures": {"predict": model_signature.infer_signature(x, y)},
    "version_name": datetime.datetime.today().strftime("V%Y%m%d%s"),
    "metrics": {"r2_score": model.score(x, y)},
    "comment": f"r2_score: {model.score(x, y)}",
    "set_default": True,
  }


# This part is user provided model code
# you will need to copy the next section to run the code
# COMMAND ----------
# this part is dbt logic for get ref work, do not modify

def ref(*args, **kwargs):
    refs = {"train_data": "analytics.aaa_titanic_miguel.train_data"}
    key = '.'.join(args)
    version = kwargs.get("v") or kwargs.get("version")
    if version:
        key += f".v{version}"
    dbt_load_df_function = kwargs.get("dbt_load_df_function")
    return dbt_load_df_function(refs[key])


def source(*args, dbt_load_df_function):
    sources = {}
    key = '.'.join(args)
    return dbt_load_df_function(sources[key])


config_dict = {}


class config:
    def __init__(self, *args, **kwargs):
        pass

    @staticmethod
    def get(key, default=None):
        return config_dict.get(key, default)

class this:
    """dbt.this() or dbt.this.identifier"""
    database = "analytics"
    schema = "aaa_titanic_miguel"
    identifier = "train"
    
    def __repr__(self):
        return 'analytics.aaa_titanic_miguel.train'


class dbtObj:
    def __init__(self, load_df_function) -> None:
        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)
        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)
        self.config = config
        self.this = this()
        self.is_incremental = False

# COMMAND ----------



def main(session):
    dbt = dbtObj(session.table)
    model_dict = model(dbt, session)
    reg = Registry(
        session = session,
        database_name = dbt.this.database,
        schema_name = dbt.this.schema
    )
    set_default = model_dict.pop("set_default", False)
    assert "model_name" not in model_dict, "model_name cannot be overridden"
    assert "conda_dependencies" not in model_dict, "conda_dependencies cannot be overridden"
    mv = reg.log_model(
        **model_dict,
        model_name = "analytics.aaa_titanic_miguel.train",
        conda_dependencies = ['snowflake-ml-python', 'pandas', 'scikit-learn'],
    )
    if set_default:
        reg.get_model(dbt.this.identifier).default = mv
    return "OK"

$$
CALL train__dbt_sp();
[0m03:10:41.870319 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m03:10:57.940296 [debug] [Thread-4 (]: SQL status: SUCCESS 1 in 16.070 seconds
[0m03:10:57.942948 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8433377f-2172-44b6-8e91-94dd7814d473', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af9a270>]}
[0m03:10:57.943494 [info ] [Thread-4 (]: 3 of 4 OK created python model model aaa_titanic_miguel.train .................. [[32mSUCCESS 1[0m in 16.10s]
[0m03:10:57.943931 [debug] [Thread-4 (]: Finished running node model.titanic.train
[0m03:10:57.944529 [debug] [Thread-6 (]: Began running node model.titanic.predict
[0m03:10:57.944944 [info ] [Thread-6 (]: 4 of 4 START python table model aaa_titanic_miguel_predict.predict ............. [RUN]
[0m03:10:57.945381 [debug] [Thread-6 (]: Acquiring new snowflake connection 'model.titanic.predict'
[0m03:10:57.945642 [debug] [Thread-6 (]: Began compiling node model.titanic.predict
[0m03:10:57.948533 [debug] [Thread-6 (]: Writing injected SQL for node "model.titanic.predict"
[0m03:10:57.949176 [debug] [Thread-6 (]: Began executing node model.titanic.predict
[0m03:10:57.969230 [debug] [Thread-6 (]: Writing runtime python for node "model.titanic.predict"
[0m03:10:57.970719 [debug] [Thread-6 (]: Using snowflake connection "model.titanic.predict"
[0m03:10:57.971092 [debug] [Thread-6 (]: On model.titanic.predict: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "model.titanic.predict"} */
WITH predict__dbt_sp AS PROCEDURE ()

RETURNS STRING
LANGUAGE PYTHON
RUNTIME_VERSION = '3.11'
PACKAGES = ('snowflake-ml-python', 'pandas', 'scikit-learn', 'snowflake-snowpark-python')



HANDLER = 'main'
EXECUTE AS CALLER
AS
$$

import sys
sys._xoptions['snowflake_partner_attribution'].append("dbtLabs_dbtPython")


  
    
    
import pandas as pd
from sklearn.impute import SimpleImputer
from snowflake.ml.registry import registry


def preprocess(df: pd.DataFrame) -> pd.DataFrame:
  df = df[["CUSTOMER_ID", "AGE", "MONTHLY_EXPENSES"]]
  df["CUSTOMER_ID"] = pd.Categorical(df["CUSTOMER_ID"])
  df["AGE"] = pd.Categorical(df["AGE"])
  df["MONTHLY_EXPENSES"] = pd.Categorical(df["MONTHLY_EXPENSES"])
  return pd.get_dummies(df, columns=["CUSTOMER_ID", "AGE", "MONTHLY_EXPENSES"])


def model(dbt, session):
  dbt.config(
    materialized="table",
    python_version="3.11",
    packages=["snowflake-ml-python", "pandas", "scikit-learn"],
    schema="predict",
  )

  dataset = dbt.ref("predict_data")

  data = dataset.to_pandas()

  x = preprocess(data)

  imputer = SimpleImputer()
  x = imputer.fit_transform(x)

  reg = registry.Registry(session=session)

  model_ref = dbt.ref("train")
  mv = reg.get_model(model_ref.table_name).default
  data["PREDICTED"] = mv.run(x, function_name="PREDICT")

  return data


# This part is user provided model code
# you will need to copy the next section to run the code
# COMMAND ----------
# this part is dbt logic for get ref work, do not modify

def ref(*args, **kwargs):
    refs = {"predict_data": "analytics.aaa_titanic_miguel.predict_data", "train": "analytics.aaa_titanic_miguel.train"}
    key = '.'.join(args)
    version = kwargs.get("v") or kwargs.get("version")
    if version:
        key += f".v{version}"
    dbt_load_df_function = kwargs.get("dbt_load_df_function")
    return dbt_load_df_function(refs[key])


def source(*args, dbt_load_df_function):
    sources = {}
    key = '.'.join(args)
    return dbt_load_df_function(sources[key])


config_dict = {}


class config:
    def __init__(self, *args, **kwargs):
        pass

    @staticmethod
    def get(key, default=None):
        return config_dict.get(key, default)

class this:
    """dbt.this() or dbt.this.identifier"""
    database = "analytics"
    schema = "aaa_titanic_miguel_predict"
    identifier = "predict"
    
    def __repr__(self):
        return 'analytics.aaa_titanic_miguel_predict.predict'


class dbtObj:
    def __init__(self, load_df_function) -> None:
        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)
        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)
        self.config = config
        self.this = this()
        self.is_incremental = False

# COMMAND ----------



def materialize(session, df, target_relation):
    # make sure pandas exists
    import importlib.util
    package_name = 'pandas'
    if importlib.util.find_spec(package_name):
        import pandas
        if isinstance(df, pandas.core.frame.DataFrame):
          session.use_database(target_relation.database)
          session.use_schema(target_relation.schema)
          # session.write_pandas does not have overwrite function
          df = session.createDataFrame(df)
    
    df.write.mode("overwrite").save_as_table('analytics.aaa_titanic_miguel_predict.predict', table_type='transient')

def main(session):
    dbt = dbtObj(session.table)
    df = model(dbt, session)
    materialize(session, df, dbt.this)
    return "OK"

  
$$
CALL predict__dbt_sp();
[0m03:10:57.971425 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m03:11:04.293203 [debug] [Thread-6 (]: Snowflake adapter: Snowflake query id: 01baeb9e-0907-ba98-0007-978308d0d356
[0m03:11:04.293965 [debug] [Thread-6 (]: Snowflake adapter: Snowflake error: 100357 (P0000): Python Interpreter Error:
Traceback (most recent call last):
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py", line 527, in wrap
    return ctx.run(execute_func_with_statement_params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py", line 503, in execute_func_with_statement_params
    result = func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/model/_client/model/model_version_impl.py", line 463, in run
    return self._model_ops.invoke_method(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/model/_client/ops/model_ops.py", line 857, in invoke_method
    df = model_signature._convert_and_validate_local_data(X, signature.inputs, strict=strict_input_validation)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/model/model_signature.py", line 684, in _convert_and_validate_local_data
    df = utils.rename_pandas_df(df, features)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/model/_signatures/utils.py", line 96, in rename_pandas_df
    raise snowml_exceptions.SnowflakeMLException(
snowflake.ml._internal.exceptions.exceptions.SnowflakeMLException: ValueError('(2110) Data does not have the same number of features as signature. Signature requires 675 features, but have 407 in input data.')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "_udf_code.py", line 119, in main
    df = model(dbt, session)
         ^^^^^^^^^^^^^^^^^^^
  File "_udf_code.py", line 44, in model
    data["PREDICTED"] = mv.run(x, function_name="PREDICT")
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py", line 529, in wrap
    raise e.original_exception from e
ValueError: (2110) Data does not have the same number of features as signature. Signature requires 675 features, but have 407 in input data.
 in function PREDICT__DBT_SP with handler main
[0m03:11:04.298642 [debug] [Thread-6 (]: Database Error in model predict (models/predict.py)
  100357 (P0000): Python Interpreter Error:
  Traceback (most recent call last):
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py", line 527, in wrap
      return ctx.run(execute_func_with_statement_params)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py", line 503, in execute_func_with_statement_params
      result = func(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/model/_client/model/model_version_impl.py", line 463, in run
      return self._model_ops.invoke_method(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/model/_client/ops/model_ops.py", line 857, in invoke_method
      df = model_signature._convert_and_validate_local_data(X, signature.inputs, strict=strict_input_validation)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/model/model_signature.py", line 684, in _convert_and_validate_local_data
      df = utils.rename_pandas_df(df, features)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/model/_signatures/utils.py", line 96, in rename_pandas_df
      raise snowml_exceptions.SnowflakeMLException(
  snowflake.ml._internal.exceptions.exceptions.SnowflakeMLException: ValueError('(2110) Data does not have the same number of features as signature. Signature requires 675 features, but have 407 in input data.')
  
  The above exception was the direct cause of the following exception:
  
  Traceback (most recent call last):
    File "_udf_code.py", line 119, in main
      df = model(dbt, session)
           ^^^^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 44, in model
      data["PREDICTED"] = mv.run(x, function_name="PREDICT")
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py", line 529, in wrap
      raise e.original_exception from e
  ValueError: (2110) Data does not have the same number of features as signature. Signature requires 675 features, but have 407 in input data.
   in function PREDICT__DBT_SP with handler main
  compiled code at target/run/titanic/models/predict.py
[0m03:11:04.299276 [debug] [Thread-6 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8433377f-2172-44b6-8e91-94dd7814d473', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113397110>]}
[0m03:11:04.299895 [error] [Thread-6 (]: 4 of 4 ERROR creating python table model aaa_titanic_miguel_predict.predict .... [[31mERROR[0m in 6.35s]
[0m03:11:04.300531 [debug] [Thread-6 (]: Finished running node model.titanic.predict
[0m03:11:04.301148 [debug] [Thread-13 ]: Marking all children of 'model.titanic.predict' to be skipped because of status 'error'.  Reason: Database Error in model predict (models/predict.py)
  100357 (P0000): Python Interpreter Error:
  Traceback (most recent call last):
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py", line 527, in wrap
      return ctx.run(execute_func_with_statement_params)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py", line 503, in execute_func_with_statement_params
      result = func(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/model/_client/model/model_version_impl.py", line 463, in run
      return self._model_ops.invoke_method(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/model/_client/ops/model_ops.py", line 857, in invoke_method
      df = model_signature._convert_and_validate_local_data(X, signature.inputs, strict=strict_input_validation)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/model/model_signature.py", line 684, in _convert_and_validate_local_data
      df = utils.rename_pandas_df(df, features)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/model/_signatures/utils.py", line 96, in rename_pandas_df
      raise snowml_exceptions.SnowflakeMLException(
  snowflake.ml._internal.exceptions.exceptions.SnowflakeMLException: ValueError('(2110) Data does not have the same number of features as signature. Signature requires 675 features, but have 407 in input data.')
  
  The above exception was the direct cause of the following exception:
  
  Traceback (most recent call last):
    File "_udf_code.py", line 119, in main
      df = model(dbt, session)
           ^^^^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 44, in model
      data["PREDICTED"] = mv.run(x, function_name="PREDICT")
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py", line 529, in wrap
      raise e.original_exception from e
  ValueError: (2110) Data does not have the same number of features as signature. Signature requires 675 features, but have 407 in input data.
   in function PREDICT__DBT_SP with handler main
  compiled code at target/run/titanic/models/predict.py.
[0m03:11:04.302894 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:11:04.303178 [debug] [MainThread]: Connection 'seed.titanic.predict_data' was left open.
[0m03:11:04.303406 [debug] [MainThread]: On seed.titanic.predict_data: Close
[0m03:11:05.006013 [debug] [MainThread]: Connection 'seed.titanic.train_data' was left open.
[0m03:11:05.006725 [debug] [MainThread]: On seed.titanic.train_data: Close
[0m03:11:05.610240 [debug] [MainThread]: Connection 'model.titanic.train' was left open.
[0m03:11:05.610929 [debug] [MainThread]: On model.titanic.train: Close
[0m03:11:06.248493 [debug] [MainThread]: Connection 'model.titanic.predict' was left open.
[0m03:11:06.249395 [debug] [MainThread]: On model.titanic.predict: Close
[0m03:11:06.846450 [info ] [MainThread]: 
[0m03:11:06.847422 [info ] [MainThread]: Finished running 1 model model, 2 seeds, 1 table model in 0 hours 0 minutes and 31.90 seconds (31.90s).
[0m03:11:06.849562 [debug] [MainThread]: Command end result
[0m03:11:06.871290 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m03:11:06.873129 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m03:11:06.877672 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/migueldichoso/Downloads/Titanic/target/run_results.json
[0m03:11:06.877931 [info ] [MainThread]: 
[0m03:11:06.878200 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m03:11:06.878425 [info ] [MainThread]: 
[0m03:11:06.878771 [error] [MainThread]:   Database Error in model predict (models/predict.py)
  100357 (P0000): Python Interpreter Error:
  Traceback (most recent call last):
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py", line 527, in wrap
      return ctx.run(execute_func_with_statement_params)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py", line 503, in execute_func_with_statement_params
      result = func(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/model/_client/model/model_version_impl.py", line 463, in run
      return self._model_ops.invoke_method(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/model/_client/ops/model_ops.py", line 857, in invoke_method
      df = model_signature._convert_and_validate_local_data(X, signature.inputs, strict=strict_input_validation)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/model/model_signature.py", line 684, in _convert_and_validate_local_data
      df = utils.rename_pandas_df(df, features)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/model/_signatures/utils.py", line 96, in rename_pandas_df
      raise snowml_exceptions.SnowflakeMLException(
  snowflake.ml._internal.exceptions.exceptions.SnowflakeMLException: ValueError('(2110) Data does not have the same number of features as signature. Signature requires 675 features, but have 407 in input data.')
  
  The above exception was the direct cause of the following exception:
  
  Traceback (most recent call last):
    File "_udf_code.py", line 119, in main
      df = model(dbt, session)
           ^^^^^^^^^^^^^^^^^^^
    File "_udf_code.py", line 44, in model
      data["PREDICTED"] = mv.run(x, function_name="PREDICT")
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/usr/lib/python_udf/7a1f83f3603f2523bc9b9203a93ce7bd21a818896cca3adeca25911b887ea6af/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py", line 529, in wrap
      raise e.original_exception from e
  ValueError: (2110) Data does not have the same number of features as signature. Signature requires 675 features, but have 407 in input data.
   in function PREDICT__DBT_SP with handler main
  compiled code at target/run/titanic/models/predict.py
[0m03:11:06.879185 [info ] [MainThread]: 
[0m03:11:06.879443 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m03:11:06.881424 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 32.822266, "process_in_blocks": "0", "process_kernel_time": 0.392887, "process_mem_max_rss": "186515456", "process_out_blocks": "0", "process_user_time": 2.121596}
[0m03:11:06.881737 [debug] [MainThread]: Command `dbt build` failed at 03:11:06.881667 after 32.82 seconds
[0m03:11:06.882006 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1039772f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1041e9f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c12840>]}
[0m03:11:06.882245 [debug] [MainThread]: Flushing usage events
[0m03:11:07.749172 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:17:20.693647 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1102d6db0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112486180>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112485d60>]}


============================== 03:17:20.698182 | 04831a8a-c1e3-4321-beff-7c98cc6afaab ==============================
[0m03:17:20.698182 [info ] [MainThread]: Running with dbt=1.9.3
[0m03:17:20.698659 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/migueldichoso/Downloads/Titanic/logs', 'profiles_dir': '/Users/migueldichoso/Downloads/Titanic', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt build --full-refresh', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:17:21.362108 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '04831a8a-c1e3-4321-beff-7c98cc6afaab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11243c290>]}
[0m03:17:21.400636 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '04831a8a-c1e3-4321-beff-7c98cc6afaab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117680a70>]}
[0m03:17:21.401641 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m03:17:21.510608 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m03:17:21.585303 [debug] [MainThread]: Partial parsing enabled: 3 files deleted, 2 files added, 1 files changed.
[0m03:17:21.585715 [debug] [MainThread]: Partial parsing: added file: titanic://seeds/titanic3.csv
[0m03:17:21.585941 [debug] [MainThread]: Partial parsing: added file: titanic://models/train_model.py
[0m03:17:21.586174 [debug] [MainThread]: Partial parsing: deleted file: titanic://seeds/predict_data.csv
[0m03:17:21.586354 [debug] [MainThread]: Partial parsing: deleted file: titanic://seeds/train_data.csv
[0m03:17:21.586527 [debug] [MainThread]: Partial parsing: deleted file: titanic://models/train.py
[0m03:17:21.586718 [debug] [MainThread]: Partial parsing: updated file: titanic://models/predict.py
[0m03:17:21.796348 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.titanic.predict' (models/predict.py) depends on a node named 'sklearn_model' which was not found
[0m03:17:21.799970 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 1.1885535, "process_in_blocks": "0", "process_kernel_time": 0.366351, "process_mem_max_rss": "162103296", "process_out_blocks": "0", "process_user_time": 1.548699}
[0m03:17:21.800353 [debug] [MainThread]: Command `dbt build` failed at 03:17:21.800275 after 1.19 seconds
[0m03:17:21.800652 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d69340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11245dfa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1201decc0>]}
[0m03:17:21.800900 [debug] [MainThread]: Flushing usage events
[0m03:17:25.329140 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:17:45.442723 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103efed50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10441a180>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104419ca0>]}


============================== 03:17:45.446742 | 29e6f050-d126-4a28-bf73-35cb2e14cc8f ==============================
[0m03:17:45.446742 [info ] [MainThread]: Running with dbt=1.9.3
[0m03:17:45.447224 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/Users/migueldichoso/Downloads/Titanic', 'log_path': '/Users/migueldichoso/Downloads/Titanic/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt build --full-refresh', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m03:17:46.014557 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '29e6f050-d126-4a28-bf73-35cb2e14cc8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e2b290>]}
[0m03:17:46.048663 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '29e6f050-d126-4a28-bf73-35cb2e14cc8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103dd6a80>]}
[0m03:17:46.049746 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m03:17:46.157880 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m03:17:46.227223 [debug] [MainThread]: Partial parsing enabled: 3 files deleted, 2 files added, 1 files changed.
[0m03:17:46.227598 [debug] [MainThread]: Partial parsing: added file: titanic://seeds/titanic3.csv
[0m03:17:46.227816 [debug] [MainThread]: Partial parsing: added file: titanic://models/train_model.py
[0m03:17:46.228017 [debug] [MainThread]: Partial parsing: deleted file: titanic://seeds/train_data.csv
[0m03:17:46.228226 [debug] [MainThread]: Partial parsing: deleted file: titanic://models/train.py
[0m03:17:46.228396 [debug] [MainThread]: Partial parsing: deleted file: titanic://seeds/predict_data.csv
[0m03:17:46.228583 [debug] [MainThread]: Partial parsing: updated file: titanic://models/predict.py
[0m03:17:46.449464 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '29e6f050-d126-4a28-bf73-35cb2e14cc8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085475f0>]}
[0m03:17:46.488165 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m03:17:46.490350 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m03:17:46.513968 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '29e6f050-d126-4a28-bf73-35cb2e14cc8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10836b440>]}
[0m03:17:46.514281 [info ] [MainThread]: Found 2 models, 1 seed, 480 macros
[0m03:17:46.515466 [info ] [MainThread]: 
[0m03:17:46.515701 [info ] [MainThread]: Concurrency: 10 threads (target='titanic_dev')
[0m03:17:46.515881 [info ] [MainThread]: 
[0m03:17:46.516193 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m03:17:46.518863 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_analytics'
[0m03:17:46.562298 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
[0m03:17:46.562596 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics"} */
show terse schemas in database analytics
    limit 10000
[0m03:17:46.562793 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:17:49.459532 [debug] [ThreadPool]: SQL status: SUCCESS 1758 in 2.897 seconds
[0m03:17:51.293356 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_aaa_titanic_miguel)
[0m03:17:51.300062 [debug] [ThreadPool]: Using snowflake connection "list_analytics_aaa_titanic_miguel"
[0m03:17:51.300305 [debug] [ThreadPool]: On list_analytics_aaa_titanic_miguel: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "connection_name": "list_analytics_aaa_titanic_miguel"} */
show objects in analytics.aaa_titanic_miguel limit 10000;
[0m03:17:51.726795 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 0.426 seconds
[0m03:17:51.731455 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '29e6f050-d126-4a28-bf73-35cb2e14cc8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108421dc0>]}
[0m03:17:51.737149 [debug] [Thread-1 (]: Began running node seed.titanic.titanic3
[0m03:17:51.737719 [info ] [Thread-1 (]: 1 of 3 START seed file aaa_titanic_miguel.titanic3 ............................. [RUN]
[0m03:17:51.738167 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_analytics_aaa_titanic_miguel, now seed.titanic.titanic3)
[0m03:17:51.738511 [debug] [Thread-1 (]: Began compiling node seed.titanic.titanic3
[0m03:17:51.738852 [debug] [Thread-1 (]: Began executing node seed.titanic.titanic3
[0m03:17:51.800982 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.titanic3"
[0m03:17:51.801328 [debug] [Thread-1 (]: On seed.titanic.titanic3: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.titanic3"} */
create table analytics.aaa_titanic_miguel.titanic3 (pclass integer,survived integer,name text,sex text,age float8,sibsp integer,parch integer,ticket text,fare float8,cabin text,embarked text,boat text,body integer,home_dest text)
[0m03:17:52.277879 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.476 seconds
[0m03:17:52.327856 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.titanic3"
[0m03:17:52.328202 [debug] [Thread-1 (]: On seed.titanic.titanic3: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.titanic3"} */
BEGIN
[0m03:17:52.719426 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.391 seconds
[0m03:17:52.868670 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.titanic3"
[0m03:17:52.869082 [debug] [Thread-1 (]: On seed.titanic.titanic3: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.titanic3"} */
insert into analytics.aaa_titanic_miguel.titanic3 (pclass, survived, name, sex, age, sibsp, parch, ticket, fare, cabin, embarked, boat, body, home_dest) values
            (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%...
[0m03:17:54.704611 [debug] [Thread-1 (]: SQL status: SUCCESS 1309 in 1.835 seconds
[0m03:17:54.706248 [debug] [Thread-1 (]: Using snowflake connection "seed.titanic.titanic3"
[0m03:17:54.706638 [debug] [Thread-1 (]: On seed.titanic.titanic3: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "seed.titanic.titanic3"} */
COMMIT
[0m03:17:55.322401 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.615 seconds
[0m03:17:55.333585 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.titanic.titanic3"
[0m03:17:55.356026 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e6f050-d126-4a28-bf73-35cb2e14cc8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1026fa030>]}
[0m03:17:55.356419 [info ] [Thread-1 (]: 1 of 3 OK loaded seed file aaa_titanic_miguel.titanic3 ......................... [[32mCREATE 1309[0m in 3.62s]
[0m03:17:55.356817 [debug] [Thread-1 (]: Finished running node seed.titanic.titanic3
[0m03:17:55.357351 [debug] [Thread-3 (]: Began running node model.titanic.train_model
[0m03:17:55.357724 [info ] [Thread-3 (]: 2 of 3 START python model model aaa_titanic_miguel.train_model ................. [RUN]
[0m03:17:55.358046 [debug] [Thread-3 (]: Acquiring new snowflake connection 'model.titanic.train_model'
[0m03:17:55.358239 [debug] [Thread-3 (]: Began compiling node model.titanic.train_model
[0m03:17:55.375473 [debug] [Thread-3 (]: Writing injected SQL for node "model.titanic.train_model"
[0m03:17:55.376112 [debug] [Thread-3 (]: Began executing node model.titanic.train_model
[0m03:17:55.384353 [debug] [Thread-3 (]: Writing runtime python for node "model.titanic.train_model"
[0m03:17:55.385683 [debug] [Thread-3 (]: Using snowflake connection "model.titanic.train_model"
[0m03:17:55.386043 [debug] [Thread-3 (]: On model.titanic.train_model: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "model.titanic.train_model"} */
WITH train_model__dbt_sp AS PROCEDURE ()

RETURNS STRING
LANGUAGE PYTHON
RUNTIME_VERSION = '3.11'
PACKAGES = ('snowflake-ml-python', 'pandas', 'scikit-learn', 'snowflake-snowpark-python')



HANDLER = 'main'
EXECUTE AS CALLER
AS
$$

import sys
sys._xoptions['snowflake_partner_attribution'].append("dbtLabs_dbtPython")


        


import importlib.util
if importlib.util.find_spec("snowflake.ml") is None:
    raise ImportError("snowflake.ml is not found. Add snowflake-ml-python to package dependencies.")
from snowflake.ml.registry import Registry
import datetime
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.svm import SVC
from snowflake.ml.model import model_signature


def preprocess(df: pd.DataFrame) -> pd.DataFrame:
  df = df[["PCLASS", "SEX", "AGE", "SIBSP", "PARCH", "FARE", "EMBARKED"]]
  df["PCLASS"] = pd.Categorical(df["PCLASS"], categories=[1, 2, 3])
  df["SEX"] = pd.Categorical(df["SEX"], categories=["male", "female"])
  df["EMBARKED"] = pd.Categorical(df["EMBARKED"], categories=["C", "Q", "S"])
  return pd.get_dummies(df, columns=["PCLASS", "SEX", "EMBARKED"])


def model(dbt, session):
  dbt.config(
    materialized="model",
    python_version="3.11",
    packages=["snowflake-ml-python", "pandas", "scikit-learn"],
  )

  dataset = dbt.ref("titanic3")

  data = dataset.to_pandas()

  x = preprocess(data)
  y = data["SURVIVED"]

  imputer = SimpleImputer()
  x = imputer.fit_transform(x)

  model = SVC()
  model.fit(x, y)

  return {
    "model": model,
    "signatures": {"predict": model_signature.infer_signature(x, y)},
    "version_name": datetime.datetime.today().strftime("V%Y%m%d"),
    "metrics": {"r2_score": model.score(x, y)},
    "comment": f"r2_score: {model.score(x, y)}",
    "set_default": True,
  }


# This part is user provided model code
# you will need to copy the next section to run the code
# COMMAND ----------
# this part is dbt logic for get ref work, do not modify

def ref(*args, **kwargs):
    refs = {"titanic3": "analytics.aaa_titanic_miguel.titanic3"}
    key = '.'.join(args)
    version = kwargs.get("v") or kwargs.get("version")
    if version:
        key += f".v{version}"
    dbt_load_df_function = kwargs.get("dbt_load_df_function")
    return dbt_load_df_function(refs[key])


def source(*args, dbt_load_df_function):
    sources = {}
    key = '.'.join(args)
    return dbt_load_df_function(sources[key])


config_dict = {}


class config:
    def __init__(self, *args, **kwargs):
        pass

    @staticmethod
    def get(key, default=None):
        return config_dict.get(key, default)

class this:
    """dbt.this() or dbt.this.identifier"""
    database = "analytics"
    schema = "aaa_titanic_miguel"
    identifier = "train_model"
    
    def __repr__(self):
        return 'analytics.aaa_titanic_miguel.train_model'


class dbtObj:
    def __init__(self, load_df_function) -> None:
        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)
        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)
        self.config = config
        self.this = this()
        self.is_incremental = False

# COMMAND ----------



def main(session):
    dbt = dbtObj(session.table)
    model_dict = model(dbt, session)
    reg = Registry(
        session = session,
        database_name = dbt.this.database,
        schema_name = dbt.this.schema
    )
    set_default = model_dict.pop("set_default", False)
    assert "model_name" not in model_dict, "model_name cannot be overridden"
    assert "conda_dependencies" not in model_dict, "conda_dependencies cannot be overridden"
    mv = reg.log_model(
        **model_dict,
        model_name = "analytics.aaa_titanic_miguel.train_model",
        conda_dependencies = ['snowflake-ml-python', 'pandas', 'scikit-learn'],
    )
    if set_default:
        reg.get_model(dbt.this.identifier).default = mv
    return "OK"

$$
CALL train_model__dbt_sp();
[0m03:17:55.386382 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m03:18:40.124415 [debug] [Thread-3 (]: SQL status: SUCCESS 1 in 44.737 seconds
[0m03:18:40.131268 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e6f050-d126-4a28-bf73-35cb2e14cc8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a7ec440>]}
[0m03:18:40.132302 [info ] [Thread-3 (]: 2 of 3 OK created python model model aaa_titanic_miguel.train_model ............ [[32mSUCCESS 1[0m in 44.77s]
[0m03:18:40.133000 [debug] [Thread-3 (]: Finished running node model.titanic.train_model
[0m03:18:40.133995 [debug] [Thread-5 (]: Began running node model.titanic.predict
[0m03:18:40.134490 [info ] [Thread-5 (]: 3 of 3 START python table model aaa_titanic_miguel.predict ..................... [RUN]
[0m03:18:40.134964 [debug] [Thread-5 (]: Acquiring new snowflake connection 'model.titanic.predict'
[0m03:18:40.135276 [debug] [Thread-5 (]: Began compiling node model.titanic.predict
[0m03:18:40.139762 [debug] [Thread-5 (]: Writing injected SQL for node "model.titanic.predict"
[0m03:18:40.141626 [debug] [Thread-5 (]: Began executing node model.titanic.predict
[0m03:18:40.164253 [debug] [Thread-5 (]: Writing runtime python for node "model.titanic.predict"
[0m03:18:40.165816 [debug] [Thread-5 (]: Using snowflake connection "model.titanic.predict"
[0m03:18:40.166179 [debug] [Thread-5 (]: On model.titanic.predict: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "titanic", "target_name": "titanic_dev", "node_id": "model.titanic.predict"} */
WITH predict__dbt_sp AS PROCEDURE ()

RETURNS STRING
LANGUAGE PYTHON
RUNTIME_VERSION = '3.11'
PACKAGES = ('snowflake-ml-python', 'pandas', 'scikit-learn', 'snowflake-snowpark-python')



HANDLER = 'main'
EXECUTE AS CALLER
AS
$$

import sys
sys._xoptions['snowflake_partner_attribution'].append("dbtLabs_dbtPython")


  
    
    
import pandas as pd
from sklearn.impute import SimpleImputer
from snowflake.ml.registry import registry


def preprocess(df: pd.DataFrame) -> pd.DataFrame:
  df = df[["PCLASS", "SEX", "AGE", "SIBSP", "PARCH", "FARE", "EMBARKED"]]
  df["PCLASS"] = pd.Categorical(df["PCLASS"], categories=[1, 2, 3])
  df["SEX"] = pd.Categorical(df["SEX"], categories=["male", "female"])
  df["EMBARKED"] = pd.Categorical(df["EMBARKED"], categories=["C", "Q", "S"])
  return pd.get_dummies(df, columns=["PCLASS", "SEX", "EMBARKED"])


def model(dbt, session):
  dbt.config(
    materialized="table",
    python_version="3.11",
    packages=["snowflake-ml-python", "pandas", "scikit-learn"],
  )

  dataset = dbt.ref("titanic3")

  data = dataset.to_pandas()

  x = preprocess(data)

  imputer = SimpleImputer()
  x = imputer.fit_transform(x)

  reg = registry.Registry(session=session)

  model_ref = dbt.ref("train_model")
  mv = reg.get_model(model_ref.table_name).default
  data["PREDICTED"] = mv.run(x, function_name="PREDICT")

  return data


# This part is user provided model code
# you will need to copy the next section to run the code
# COMMAND ----------
# this part is dbt logic for get ref work, do not modify

def ref(*args, **kwargs):
    refs = {"titanic3": "analytics.aaa_titanic_miguel.titanic3", "train_model": "analytics.aaa_titanic_miguel.train_model"}
    key = '.'.join(args)
    version = kwargs.get("v") or kwargs.get("version")
    if version:
        key += f".v{version}"
    dbt_load_df_function = kwargs.get("dbt_load_df_function")
    return dbt_load_df_function(refs[key])


def source(*args, dbt_load_df_function):
    sources = {}
    key = '.'.join(args)
    return dbt_load_df_function(sources[key])


config_dict = {}


class config:
    def __init__(self, *args, **kwargs):
        pass

    @staticmethod
    def get(key, default=None):
        return config_dict.get(key, default)

class this:
    """dbt.this() or dbt.this.identifier"""
    database = "analytics"
    schema = "aaa_titanic_miguel"
    identifier = "predict"
    
    def __repr__(self):
        return 'analytics.aaa_titanic_miguel.predict'


class dbtObj:
    def __init__(self, load_df_function) -> None:
        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)
        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)
        self.config = config
        self.this = this()
        self.is_incremental = False

# COMMAND ----------



def materialize(session, df, target_relation):
    # make sure pandas exists
    import importlib.util
    package_name = 'pandas'
    if importlib.util.find_spec(package_name):
        import pandas
        if isinstance(df, pandas.core.frame.DataFrame):
          session.use_database(target_relation.database)
          session.use_schema(target_relation.schema)
          # session.write_pandas does not have overwrite function
          df = session.createDataFrame(df)
    
    df.write.mode("overwrite").save_as_table('analytics.aaa_titanic_miguel.predict', table_type='transient')

def main(session):
    dbt = dbtObj(session.table)
    df = model(dbt, session)
    materialize(session, df, dbt.this)
    return "OK"

  
$$
CALL predict__dbt_sp();
[0m03:18:40.166522 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m03:18:58.010498 [debug] [Thread-5 (]: SQL status: SUCCESS 1 in 17.844 seconds
[0m03:18:58.014457 [debug] [Thread-5 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e6f050-d126-4a28-bf73-35cb2e14cc8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a78a390>]}
[0m03:18:58.015044 [info ] [Thread-5 (]: 3 of 3 OK created python table model aaa_titanic_miguel.predict ................ [[32mSUCCESS 1[0m in 17.88s]
[0m03:18:58.015460 [debug] [Thread-5 (]: Finished running node model.titanic.predict
[0m03:18:58.016613 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:18:58.017051 [debug] [MainThread]: Connection 'seed.titanic.titanic3' was left open.
[0m03:18:58.017298 [debug] [MainThread]: On seed.titanic.titanic3: Close
[0m03:18:58.620727 [debug] [MainThread]: Connection 'model.titanic.train_model' was left open.
[0m03:18:58.621916 [debug] [MainThread]: On model.titanic.train_model: Close
[0m03:18:59.296110 [debug] [MainThread]: Connection 'model.titanic.predict' was left open.
[0m03:18:59.297298 [debug] [MainThread]: On model.titanic.predict: Close
[0m03:18:59.967312 [info ] [MainThread]: 
[0m03:18:59.968399 [info ] [MainThread]: Finished running 1 model model, 1 seed, 1 table model in 0 hours 1 minutes and 13.45 seconds (73.45s).
[0m03:18:59.969943 [debug] [MainThread]: Command end result
[0m03:19:00.073062 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/migueldichoso/Downloads/Titanic/target/manifest.json
[0m03:19:00.075095 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/migueldichoso/Downloads/Titanic/target/semantic_manifest.json
[0m03:19:00.079504 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/migueldichoso/Downloads/Titanic/target/run_results.json
[0m03:19:00.079754 [info ] [MainThread]: 
[0m03:19:00.080147 [info ] [MainThread]: [32mCompleted successfully[0m
[0m03:19:00.080468 [info ] [MainThread]: 
[0m03:19:00.080683 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m03:19:00.082791 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 74.71287, "process_in_blocks": "0", "process_kernel_time": 0.395771, "process_mem_max_rss": "189939712", "process_out_blocks": "0", "process_user_time": 2.407717}
[0m03:19:00.083122 [debug] [MainThread]: Command `dbt build` succeeded at 03:19:00.083064 after 74.71 seconds
[0m03:19:00.083385 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1084b8980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e2b290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e52720>]}
[0m03:19:00.083634 [debug] [MainThread]: Flushing usage events
[0m03:19:01.882336 [debug] [MainThread]: An error was encountered while trying to flush usage events
