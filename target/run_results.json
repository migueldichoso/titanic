{"metadata": {"dbt_schema_version": "https://schemas.getdbt.com/dbt/run-results/v6.json", "dbt_version": "1.9.3", "generated_at": "2025-03-10T19:18:59.968823Z", "invocation_id": "29e6f050-d126-4a28-bf73-35cb2e14cc8f", "env": {}}, "results": [{"status": "success", "timing": [{"name": "compile", "started_at": "2025-03-10T19:17:51.738746Z", "completed_at": "2025-03-10T19:17:51.738762Z"}, {"name": "execute", "started_at": "2025-03-10T19:17:51.739073Z", "completed_at": "2025-03-10T19:17:55.354724Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 3.6167759895324707, "adapter_response": {"_message": "CREATE 1309", "code": "CREATE", "rows_affected": 1309}, "message": "CREATE 1309", "failures": null, "unique_id": "seed.titanic.titanic3", "compiled": null, "compiled_code": null, "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-03-10T19:17:55.358373Z", "completed_at": "2025-03-10T19:17:55.376031Z"}, {"name": "execute", "started_at": "2025-03-10T19:17:55.376282Z", "completed_at": "2025-03-10T19:18:40.130794Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 44.77306008338928, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01baeba5-0907-ba98-0007-978308d0d4ea"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.titanic.train_model", "compiled": true, "compiled_code": "import datetime\nimport pandas as pd\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.svm import SVC\nfrom snowflake.ml.model import model_signature\n\n\ndef preprocess(df: pd.DataFrame) -> pd.DataFrame:\n  df = df[[\"PCLASS\", \"SEX\", \"AGE\", \"SIBSP\", \"PARCH\", \"FARE\", \"EMBARKED\"]]\n  df[\"PCLASS\"] = pd.Categorical(df[\"PCLASS\"], categories=[1, 2, 3])\n  df[\"SEX\"] = pd.Categorical(df[\"SEX\"], categories=[\"male\", \"female\"])\n  df[\"EMBARKED\"] = pd.Categorical(df[\"EMBARKED\"], categories=[\"C\", \"Q\", \"S\"])\n  return pd.get_dummies(df, columns=[\"PCLASS\", \"SEX\", \"EMBARKED\"])\n\n\ndef model(dbt, session):\n  dbt.config(\n    materialized=\"model\",\n    python_version=\"3.11\",\n    packages=[\"snowflake-ml-python\", \"pandas\", \"scikit-learn\"],\n  )\n\n  dataset = dbt.ref(\"titanic3\")\n\n  data = dataset.to_pandas()\n\n  x = preprocess(data)\n  y = data[\"SURVIVED\"]\n\n  imputer = SimpleImputer()\n  x = imputer.fit_transform(x)\n\n  model = SVC()\n  model.fit(x, y)\n\n  return {\n    \"model\": model,\n    \"signatures\": {\"predict\": model_signature.infer_signature(x, y)},\n    \"version_name\": datetime.datetime.today().strftime(\"V%Y%m%d\"),\n    \"metrics\": {\"r2_score\": model.score(x, y)},\n    \"comment\": f\"r2_score: {model.score(x, y)}\",\n    \"set_default\": True,\n  }\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {\"titanic3\": \"analytics.aaa_titanic_miguel.titanic3\"}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"analytics\"\n    schema = \"aaa_titanic_miguel\"\n    identifier = \"train_model\"\n    \n    def __repr__(self):\n        return 'analytics.aaa_titanic_miguel.train_model'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "analytics.aaa_titanic_miguel.train_model", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-03-10T19:18:40.135502Z", "completed_at": "2025-03-10T19:18:40.141508Z"}, {"name": "execute", "started_at": "2025-03-10T19:18:40.141896Z", "completed_at": "2025-03-10T19:18:58.014154Z"}], "thread_id": "Thread-5 (worker)", "execution_time": 17.87949800491333, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01baeba6-0907-ba98-0007-978308d0d636"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.titanic.predict", "compiled": true, "compiled_code": "import pandas as pd\nfrom sklearn.impute import SimpleImputer\nfrom snowflake.ml.registry import registry\n\n\ndef preprocess(df: pd.DataFrame) -> pd.DataFrame:\n  df = df[[\"PCLASS\", \"SEX\", \"AGE\", \"SIBSP\", \"PARCH\", \"FARE\", \"EMBARKED\"]]\n  df[\"PCLASS\"] = pd.Categorical(df[\"PCLASS\"], categories=[1, 2, 3])\n  df[\"SEX\"] = pd.Categorical(df[\"SEX\"], categories=[\"male\", \"female\"])\n  df[\"EMBARKED\"] = pd.Categorical(df[\"EMBARKED\"], categories=[\"C\", \"Q\", \"S\"])\n  return pd.get_dummies(df, columns=[\"PCLASS\", \"SEX\", \"EMBARKED\"])\n\n\ndef model(dbt, session):\n  dbt.config(\n    materialized=\"table\",\n    python_version=\"3.11\",\n    packages=[\"snowflake-ml-python\", \"pandas\", \"scikit-learn\"],\n  )\n\n  dataset = dbt.ref(\"titanic3\")\n\n  data = dataset.to_pandas()\n\n  x = preprocess(data)\n\n  imputer = SimpleImputer()\n  x = imputer.fit_transform(x)\n\n  reg = registry.Registry(session=session)\n\n  model_ref = dbt.ref(\"train_model\")\n  mv = reg.get_model(model_ref.table_name).default\n  data[\"PREDICTED\"] = mv.run(x, function_name=\"PREDICT\")\n\n  return data\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {\"titanic3\": \"analytics.aaa_titanic_miguel.titanic3\", \"train_model\": \"analytics.aaa_titanic_miguel.train_model\"}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"analytics\"\n    schema = \"aaa_titanic_miguel\"\n    identifier = \"predict\"\n    \n    def __repr__(self):\n        return 'analytics.aaa_titanic_miguel.predict'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "analytics.aaa_titanic_miguel.predict", "batch_results": null}], "elapsed_time": 73.45097303390503, "args": {"select": [], "resource_types": [], "which": "build", "defer": false, "export_saved_queries": false, "quiet": false, "introspect": true, "state_modified_compare_more_unrendered_values": false, "invocation_command": "dbt build --full-refresh", "exclude_resource_types": [], "print": true, "printer_width": 80, "send_anonymous_usage_stats": true, "profiles_dir": "/Users/migueldichoso/Downloads/Titanic", "write_json": true, "require_resource_names_without_spaces": false, "log_format_file": "debug", "log_path": "/Users/migueldichoso/Downloads/Titanic/logs", "require_nested_cumulative_type_params": false, "exclude": [], "partial_parse_file_diff": true, "require_yaml_configuration_for_mf_time_spines": false, "source_freshness_run_project_hooks": false, "include_saved_query": false, "require_batched_execution_for_custom_microbatch_strategy": false, "version_check": true, "log_file_max_bytes": 10485760, "populate_cache": true, "cache_selected_only": false, "indirect_selection": "eager", "require_explicit_package_overrides_for_builtin_materializations": true, "show_resource_report": false, "use_colors": true, "log_level": "info", "warn_error_options": {"include": [], "exclude": []}, "state_modified_compare_vars": false, "empty": false, "macro_debugging": false, "favor_state": false, "static_parser": true, "strict_mode": false, "use_colors_file": true, "show": false, "partial_parse": true, "log_level_file": "debug", "full_refresh": true, "project_dir": "/Users/migueldichoso/Downloads/Titanic", "log_format": "default", "vars": {}, "skip_nodes_if_on_run_start_fails": false}}